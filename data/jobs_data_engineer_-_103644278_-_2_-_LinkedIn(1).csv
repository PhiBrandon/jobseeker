job_title,company_name,location,job_link,job_id,job_description
Core Infrastructure Engineer - Networking,Kraken Digital Asset Exchange,European Union (Remote),https://www.linkedin.com/jobs/view/3756657176/?eBP=CwEAAAGMRJcq2sj0p6p-JEgEIiwClkHKAQ18I7-9vJQV2yB039dpxn2_OTr58K-k868lGkSQoIHi6_VNhJkjs9dWxfPnePHyp35axjDFmjMIcdm4FE03N22hqj80M_dL-sZlAbMvzxmuu6PCTtRf2pHAJKmtbzHo3-x5JaCstFIJOn-mcnfFIl1ZNvLP1wT87dmVZSq1PGKK_EvZ1BjIDVn2rL4e8eaZG_ccUZ1_n0DFcLjAb-Tv6kcElDHpFdhItk7bbPj8jaHi35t398f-vpt89Ow0aIgJ4oJ_UR5uaBvAp0p5CB8BrYYkh_rJoDUorxKnqgu7dkviiUHRAGfPdaPnN50QE_NPjBlzX44j22CIX27TXwqFcZ1rr8LUjj8YUxl3Mv9n5X4Bgx0&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=5ZFYN1rBxDpZG7wXsA%2B03g%3D%3D&trk=flagship3_search_srp_jobs,3756657176,"About the job
            
 
Building the Future of Crypto Our Krakenites are a world-class team with crypto conviction, united by our desire to discover and unlock the potential of crypto and blockchain technology.What makes us different?Kraken is a mission-focused company rooted in crypto values. As a Krakenite, you’ll join us on our mission to accelerate the global adoption of crypto, so that everyone can achieve financial freedom and inclusion. For over a decade, Kraken’s focus on our mission and crypto ethos has attracted many of the most talented crypto experts in the world.Before you apply, please read the Kraken Culture page to learn more about our internal culture, values, and mission.As a fully remote company, we have Krakenites in 60+ countries who speak over 50 languages. Krakenites are industry pioneers who develop premium crypto products for experienced traders, institutions, and newcomers to the space. Kraken is committed to industry-leading security, crypto education, and world-class client support through our products like Kraken Pro, Kraken NFT, and Kraken Futures.Become a Krakenite and build the future of crypto!Proof of workThe teamIf you thrive in a challenging, fun and fast-paced environment, the Core Infrastructure Engineer at Kraken is for you! Not only is this role a strategic hands-on role that is critical to the continuing success of Kraken; you will join a highly dedicated team that is responsible for managing the entire network and compute infrastructure for one of the leading cryptocurrency exchanges in the world. We are looking for a dynamic and innovative self-starter with the ability to think “outside of the box” to solve complex problems in a sustainable way.Find our more about Core Infrastructure Engineering in our latest engineering blogpost!This role is fully remote. We prefer candidates in European Timezones, to cover current needs.The opportunity Design, implement, manage, and defend a “zero trust”, defense-in-depth networkImplement and evolve enterprise network access controlsManage and deploy ""infrastructure as code""Write good quality policies, procedures, and technical documentationCoordinate with internal development teams and other stakeholders to ensure network security principles are ""built-in"" from the beginningWork with Engineering and IT Security teams to ensure that product features are securely deployed and monitoredMonitor and maintain all physical infrastructure (network, security, and compute), cloud data center environments, remote office locations, and respond to critical network problems to maximize service uptimeAssist in various projects with network related requirementsMentor and evangelize security practices through cross-functional work with internal stakeholders and teamsAssume on-call responsibilities and duties per the scheduleTravel as needed to support physical datacenter and office locations
Skills You Should HODL 5+ years of network engineering background including offensive/defensive securityDeep experience in public (AWS or Azure or Google), private and/or hybrid cloud infrastructureExperience with network security management tools and techniquesFamiliarity with security testing tools (performance and threat-based)Proficient in network and security design, implementation, and administration leveraging industry standard platforms from vendors such as: Palo Alto Networks, Cisco, Juniper, and ArubaExperience with Switching (Capacity Planning & VLAN’s), Routing (OSPF, EIGRP, BGP, ECMP, PBF), WAN Technologies (MPLS, VPLS, VPN), public cloud networking, and Security (IPS, RBAC, etc.)Previous experience monitoring and management of intrusion detection systems and firewall devicesDemonstrated experience researching, building and implementing defensive security systems that are used against internal and external attack vectorsExcellent communication skills: demonstrated ability to explain complex technical issues to both technical and non-technical audiencesExcellent analytical and problem-solving skillsAbility to perform well under pressure, high attention to detailStrong desire / interest in learning new technologyHighly motivated and passionate about infrastructure engineering and securityThis role requires the ability to travel. For this reason, a valid passport will be mandatory
Location Tagging: #EUKraken is powered by people from around the world and we celebrate all Krakenites for their diverse talents, backgrounds, contributions and unique perspectives. We hire strictly based on merit, meaning we seek out the candidates with the right abilities, knowledge, and skills considered the most suitable for the job. We encourage you to apply for roles where you don't fully meet the listed requirements, especially if you're passionate or knowledgable about crypto!As an equal opportunity employer, we don’t tolerate discrimination or harassment of any kind. Whether that’s based on race, ethnicity, age, gender identity, citizenship, religion, sexual orientation, disability, pregnancy, veteran status or any other protected characteristic as outlined by federal, state or local laws.Stay in the knowFollow us on TwitterLearn on the Kraken BlogConnect on LinkedIn"
Junior Data Engineer,HireMeFast LLC - Career Accelerator - Land A Job,"Milwaukee, WI (Remote)",https://www.linkedin.com/jobs/view/3780155059/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=GK0rgt27wp5tzMFzErJ37A%3D%3D&trk=flagship3_search_srp_jobs,3780155059,"About the job
            
 
This is a remote position. Job Title: Junior Data Engineer Employment Type: Full-Time Salary: $64,000 - $76,000 per annum Experience Required:  Minimum 1 year of project experience How to Apply: visit hiremefast.net  to learn more & apply.About us: HireMeFast is a leading staffing and recruitment agency specializing in connecting businesses with top-tier talent across various industries. Our mission is to bridge the gap between exceptional candidates and organizations needing their skills, expertise, and unique qualities. Our team of experienced and dedicated recruitment specialists utilizes innovative sourcing strategies, and a vast network to identify and attract top talent. We conduct comprehensive procedures to ensure that only the most qualified candidates are presented to our clients.Position SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include: Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness 
Characteristics of this role: Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. 
Required Qualifications 2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation 
Qualifications Knowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Databricks, and Azure Synapse. 
EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experienceWhy HireMeFast LLC?At HireMeFast, we understand that finding the right individuals to join your team is crucial for success and growth of your organization. We are committed to streamlining the hiring process for our clients, ensuring they have access to a diverse pool of highly qualified candidates who are a perfect fit for their specific needs."
Data Engineer,Otter Products,"Fort Collins, CO (Remote)",https://www.linkedin.com/jobs/view/3766728302/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=RZT%2FPZGNcVBv13J4bFpZ0Q%3D%3D&trk=flagship3_search_srp_jobs,3766728302,"About the job
            
 
Overview Otter Products is currently recruiting for a Data Engineer to join our Data team! You can be based in our Fort Collins, CO office with flexibility to work a portion of your time remotely, or 100% Remote in the U.S.The Data Engineer applies professional experience, concepts, and company objectives toward building and operationalizing the minimally inclusive data necessary for the enterprise data initiatives following industry standard practices and tools. The bulk of the Data Engineer's work would be in designing, managing and optimizing data pipelines, then moving these data pipelines effectively into production for key data and analytics consumers like business/data analysts, data scientists or other stakeholder that needs curated data for data and analytics use cases across the enterprise. The Data Engineer also ensures compliance with data governance and data security requirements while creating, improving and operationalizing these integrated and reusable data pipelines to enable faster data access, integrated data reuse and vastly improved time-to-solution for data and analytics initiatives. Additionally, the Data Engineer will be expected to collaborate with other data team members and data consumers working on the models and algorithms developed by them toward optimization for data quality, security, and governance to put them into production leading to potentially large productivity gains. About Otter Products Otter Products, we grow to give. From our founder's garage in 1998 to the global technology leader we are today, Otter Products continues to drive growth through innovation.Through our industry-leading brands - OtterBox, Liviri and OtterCares - we provide our partners the number-one selling and most trusted products in our categories. Our philanthropic spirit is the foundation on which we foster our partner relationships, allowing us to grow and to give - together.By way of our charitable arm, the OtterCares Foundation, we support our communities and invest in our future through education that inspires kids to change the world.And even as our global community of Otters continues to grow, our founder's core values are still at the heart of everything we do. We measure our success by our ability to give back to our communities and strengthen opportunities for all.For more information visit otterproducts.com Responsibilities  Complete analysis, design and development of BI solutions using Azure SQL ServerFamiliarity with Data Warehouse conceptsExperience coding the extraction, transformation, and loading (ETL) processesDatabase development primarily in SSIS, Data Factory and SQLPartner with the business to determine end user database/reporting needs and requirementsGenerate ad hoc reports using Power BI or SSRSCollaborate with other developers to create and implement best approach solution(s)Troubleshoot Azure tools, systems, and softwareReview queries for performance issues, making changes as neededCollaborate with team to performance-tune Azure application as necessaryAssist with the analysis and extraction of relevant information from large amounts of historical business data to feed data science initiativesParticipate and support the design and documentation of processes for large scale data analyses, model development, model validation and model implementationSupport and maintain a positive safety culture by following all safety policies and procedures and actively contributing to a safe working environmentOther duties as required
 Qualifications  Bachelor's degree required. Degree in Computer Science or Mathematics preferredMinimum of four years of experience in an IT or analytical role required. Experience in database development, report writing and/or statistics preferred.
 EEO Otter Products, LLC is an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, age, marital status, pregnancy, sex, sexual orientation, gender, gender identity or expression, national origin, disability, veteran status, or any other characteristic or status protected by law. For US Based Roles Only - Compensation Range Minimum USD $90,000.00/Yr. For US Based Roles Only - Compensation Range Maximum USD $120,000.00/Yr. Additional Total Rewards Profit Sharing Program Eligible, Benefits Eligible - Full Time- check out otterproducts.com/careers/why for more info"
Data Engineer,"ISC (Integrated Specialty Coverages, LLC)","Carlsbad, CA (Remote)",https://www.linkedin.com/jobs/view/3778293528/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=e315feS7SbJXPKluOL9pIw%3D%3D&trk=flagship3_search_srp_jobs,3778293528,"About the job
            
 
About Integrated Specialty CoveragesIntegrated Specialty Coverages LLC (ISC) is a growth stage technology and data-driven insurance company leading innovation in the market.Backed by one of the leading private equity firms, KKR, and led by a forward-thinking management team, ISC is combining the worlds of insurance and technology to create an Insurtech powerhouse. As a leading online distributor of insurance products for a range of industries and ""Main Street USA"", we are looking for the right people to help us in our mission of achieving exponential growth. We strive to be the number one place to go for brokers and agents to source insurance. To accomplish this, we're building a digitally focused team that deeply understands the intersection between user experience, data, and AI/ML to optimize the way we engage with our customers and partners.Job SummaryThe Data Engineer role will be the technical liaison between multiple groups including a data science team, the engineering team, product management, and business stakeholders. You do not need any insurance knowledge prior, however, you must quickly dive deep into the insurance world and ask questions to become a subject matter expert. You will be responsible for building a data platform to facilitate the data science team. You must be a self-starter that can build out features such as a data pipeline from scratch. There will be support from both engineering and data science for any buildout.Job Responsibilities Create and maintain optimal data pipeline architecture. Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using AWS technologies, SQL, and Python. Work with stakeholders including the Executive, Product, Data Science, and Engineering teams to assist with data-related technical issues and support their data infrastructure needs. Work with data science and analytics teams to strive for greater functionality in our data systems. 
Minimum Qualifications: Advanced working SQL knowledge and experience working with relational databases, strong query authoring (SQL) as well as working familiarity with a variety of databases (Snowflake, Redshift, MySQL, MSSQL, etc.)Experience building and optimizing data pipelines, architecture and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Build processes supporting data transformation, data structures, metadata, dependency, and workload management. A successful history of transforming, processing and extracting value from large disconnected, datasets from a variety of data sources (Flat files, Excel, databases, etc.)Strong analytic skills related to working with unstructured datasets. Strong project management and organizational skills. Experience supporting and working with cross-functional teams in a dynamic environment. Ability to mentor/guide/collaborate with other team members. 
We are looking for a candidate with 3-5 years of experience in a Data Engineer role. They should also have experience using the following software/tools: Experience with relational and MPP databases, including Snowflake and MySQL. Experience developing software in an agile environment from the requirements stage to production. Experience with version control: gitExperience with container technologies: DockerExperience with data pipeline and workflow management tools: Airflow, Jenkins, AWS Glue, Azkaban, Luigi, etc. Experience with AWS cloud services: EC2, ECS, Batch, S3, EMR, RDS, RedshiftExperience with other cloud services: Snowflake, AirflowExperience with object-oriented/object function scripting languages: Python, Java, C++, etc. Experience with data modeling and data warehouse designExperience with data visualization tools (PowerBI, QuickSight)
The starting annual pay scale for this position is listed below. Actual starting pay will be based on factors such as skills, qualifications, training, and experience. In addition, the company offers comprehensive benefits including medical, dental and vision insurance, 401(k) plan with match, paid time off, and other benefits.ISC's salary ranges are determined by role and level. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations and could be higher or lower based on a multitude of factors, including job-related skills, experience, and relevant education or training.National Pay Range$100,000—$110,000 USDBenefits of Working at ISC Competitive vacation and flexible working arrangementsComprehensive and inclusive health benefitsA variety of professional development and mentorship opportunitiesChoice of technology whether at home or in the office
ISC's Ownership Behaviors Do the Right Thing *Be Relentless. Pursue Excellence. *Personal Responsibility & Own OutcomesTry Fast. Learn Fast. Fail Fast. Think Big. *Build Extraordinary Owners & Join Forces *Grit & Determination
Applicants with disabilities may contact ISC HR department via e-mail, and other means to request and arrange accommodation. If you need assistance to accommodate a disability, you may request accommodation at any time. Please contact ISC at HR@ISCMGA.com.ISC believes in creating long-term relationships by being responsive and relevant and by consistently delivering value to our community of customers. Specifically, with our employees, we focus on attracting, developing, and retaining the best talent for our business, challenging our people, demonstrating a ""can-do"" attitude, and fostering a collaborative and mutually supportive environment. ISC is an equal opportunity employer and a participant in the US federal E-Verify program (US).Diversity creates a healthier atmosphere: All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, gender, gender identity, sexual orientation, marital status, medical condition, genetic information, mental or physical disability, military or veteran status, or any other characteristic protected by local, state, or Federal law."
ENTRY LEVEL DATA ENGINEER (REMOTE),SynergisticIT,"Jacksonville, FL (Remote)",https://www.linkedin.com/jobs/view/3767587909/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=qddFbj5Z3mAQHmr2PGh9Fg%3D%3D&trk=flagship3_search_srp_jobs,3767587909,"About the job
            
 
SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you needSynergisticIT understands the complex nature of the job market and how difficult it can be to secure a position, especially for fresh graduates. Therefore, we assist and help tech-savvies to convert their passions into professions. We go above and beyond to keep you working in your niche.As we focus on long-term success, we provide complete career development solutions. From job search to upskilling portfolio and interview preparation, we can guide you at every step of your career.SynergisticIT spares no efforts to connect you with a large network of tech giants, including Google, Apple, PayPal, Dell, Cisco, Client, etc. Presently, we are actively looking for ENTRY LEVEL DATA ENGINEER a driven mindset. Get the right opportunity and gain experience in building web-centric solutions on Java.Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or anyone looking to make their career in IT IndustryWe also assist in filing for STEM extension and H1b and Green card filing.Candidates who are serious about their future in the IT Industry and have set big goals for themselves.Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill Enhancement Programs if the candidates are missing skills or experience which our clients need with great outcomesCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancementCandidates Who Lack ExperienceHave had a break in careersLack Technical Competencycandidates who want to get employed and make a career in the Tech Industry Please Also Check The Below Linkshttps://www.synergisticit.com/candidate-outcomes/https://www.synergisticit.com/java-track/https://www.synergisticit.com/data-science-track/https://www.synergisticit.com/which-is-the-best-option-for-tech-job-seekers-staffing-companies-consulting-companies-bootcamps-or-synergisticit/https://www.synergisticit.com/contact-us/If the skills are not a match candidates can opt for Skill enhancement. Or their resume can be sent out to clients to see if responses are achievableREQUIRED SKILLS For Java/Software Programmers Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices and REST API's experienceExcellent written and verbal communication skills
For data Science/Machine learningRequired Skills Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, Python, data visualization toolsExcellent written and verbal communication skills
Preferred skills: NLP, Text mining, Tableau, Time series analysisTechnical skills are required by clients for selection even if its Junior or entry level position each additional Technical skill helps a candidate's resume to be picked by clients over other job seekers.Clients hire candidates with the right technical skills which they need and reject candidates who lack the required technical skills.No third party candidates or c2c candidatesPlease apply to the postingNo phone calls please. Shortlisted candidates would be reached out"
Data Engineer,Gauntlet,Los Angeles Metropolitan Area (Remote),https://www.linkedin.com/jobs/view/3765636920/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=DjriKD3bf8mHM7tarLiCAg%3D%3D&trk=flagship3_search_srp_jobs,3765636920,"About the job
            
 
Gauntlet is DeFi’s risk manager. We drive capital efficiency while maintaining economic safety for some of the largest crypto protocols with our simulations. Gauntlet manages risk and incentives for over $9 Billion in assets.Gauntlet continuously publishes cutting-edge research, making us the most cited peer-reviewed articles in the DeFi industry. We’re a Series B company with :60 employees operating remote-first with a home base in New York City.Gauntlet’s mission is to help make blockchain protocols and smart contracts safer and more trustworthy for users. Building decentralized systems creates new challenges for protocol developers, smart contract developers, and asset holders that are not seen in traditional development and investing.Gauntlet is building a blockchain simulation and testing platform that leverages battle-tested techniques from other industries to emulate interactions in crypto networks. Simulation provides transparency and greatly reduces the cost of experimentation so that teams can rapidly design, launch, and scale new decentralized systems.Responsibilities Design, build, and maintain robust scalable ETL pipelines that ingest data from DeFi protocols, blockchain networks, and various data sourcesContribute to making our data platform world-classCollaborate with stakeholders to understand the data requirements and provide necessary supportImplement quality control measures to ensure data integrity and qualityActively participate in code and design reviews, providing constructive feedback to peers and maintaining high coding standardsKeep up-to-date with the latest industry trends, technologies, and best practices to ensure the continuous improvement of data platformContribute to the creation of technical documentation and user guidesTroubleshoot, diagnose, and resolve software defects, ensuring optimal system performance and reliability
Qualifications 5+ years of professional engineering experienceProficient in writing code in Python and SQLHands-on experience with OLAP database such as BigQueryExperience with modern data transformation tools such as DBTExperience with workflow orchestration tools such as Dagster and AirflowExperience with distributed data processing frameworksStrong communication skills and the ability to work collaboratively in a distributed team environment
Bonus Points Experience working in the crypto industry is a plus but not requiredEnthusiasm for the space, especially DeFi, is very much desiredSmart contract development experience (e.g. Solidity)Experience with building machine learning models at scalePublished or presented research in the space
Benefits and Perks Remote first - work from anywhere in the US & CAN!Regular in-person company retreats and cross-country ""office visit"" perk100% paid medical, dental and vision premiums for employeesLaptop, monitor, keyboard and mouse setup provided$1,000 WFH stipendMonthly reimbursement for home internet, phone, and cellular dataUnlimited vacation100% paid parental leave of 12 weeksFertility benefitsOpportunity for incentive compensation
Please note at this time our hiring is reserved for potential employees who are able to work within the contiguous United States and Canada. Should you need alternative accommodations, please note that in your application.The national pay range for this role is $150,000 - $180,000 base plus additional On Target Earnings potential by level and equity in the company. Our salary ranges are based on paying competitively for a company of our size and industry, and are one part of many compensation, benefits and other reward opportunities we provide. Individual pay rate decisions are based on a number of factors, including qualifications for the role, experience level, skill set, and balancing internal equity relative to peers at the company."
Staff Scala Developer - 100% Remote,Signify Technology,United States (Remote),https://www.linkedin.com/jobs/view/3759037297/?eBP=CwEAAAGMRJcq2l3RSKSIupdH9SD65cgHe4-JaVe5En0x_NMaMhckUJ8f1bEBRlN79gPI2jmabHwULRgkdFFAmtIwl-4UIWo7fpSbG4m2Vw9Ujtm97yKBlVK7SJCwo5WoSYrhtecf-5SgbVfRsFBism4pDmY7n-dceetsmNWg_ElrJnCCKCu_485Lq1hDBa3UfYvy-fSAprbFU3vfwDQc4JF7mERXCkODqFsUrmoKtJi8ZOPKjJPts7jiqrVmQgbKWADA2d9NNBdKd3BM9yO3JqNCVCNs3zxtUmoQXxnrzgknLSHGUDLMkGF_y7rOhjStn_zX8nduFKO3C_muJq6ElAxSED3iMDXJbqOBTAJHjfllE8ZrvYlbTI82iedLxDIdDWa76PbdAxVXjQA&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=EHo%2B8lc6vhrf3XY3rWqpwA%3D%3D&trk=flagship3_search_srp_jobs,3759037297,"About the job
            
 
Lead Scala Developers - ZIO 12 month Contract to Hire100% Remote (United States)Compensation: $100 - $130 per hourOur client, an established name in the streaming industry, have asked us to partner with them exclusively on hiring additional Staff Software Developers to join one of our client's established team of experienced Functional Scala Developers.You will be working on a greenfield development project of our client's primary customer facing streaming platform which will replace their existing platform and be rolled out globally.This will be a 12 month contract into hire position working 100% remotely.Candidates will ideally be located within EST or if not, willing to work on that schedule.About you: Expert using Scala within ZIO
Expediated interview 2 step interview process.(No abstract or academic live coding puzzles) Please note we are unable to offer employer sponsorship and will not consider applications from third parties."
Staff Front End Software Engineer,Esusu,United States (Remote),https://www.linkedin.com/jobs/view/3768803346/?eBP=CwEAAAGMRJcq2oZa1RkhGaKDnLzdq6ojb5ezKCib7LXOSx-1ODv9mbgvH_NvAXnIsy4MPnP2gjpaYEOZV4f5JTOAarLkiAEON4h-uyiIyfbS_clmjijCOIVnlfv46ayEXuLycTDyD38l0Tda0BzK3ayTa6aRjYG62ybF8uUOmWjehpyP5M8ulDYewtG-dfoUDY5sGOaJGrHApF7a5l_wDEgRdoHOQ3cOXcCct_Vq12L5dvIgbRl_C9PTqm8epN6K_5MsfqT9gyVI8YKZWuhRKKUlkDCWzRACxwTCeE6tMTmcO1qubsXFknbxrdQS4ST-ywYRhMl7N5CGYJ-rE4KwqUtznc7veql13dtk&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=UYnt3vl58iL0WrgO57sPlQ%3D%3D&trk=flagship3_search_srp_jobs,3768803346,"About the job
            
 
Democratize Access To Credit Together we’ll dismantle barriers to housing for working families and use data to eliminate the racial wealth gap. The ability to build credit from rental payments has the potential to give over 45 million renters with little to no credit a pathway into the financial system. Those individuals then stand to save over $200,000 in reduced lifetime interest payments, build home equity by qualifying for mortgages, and build wealth by passing job screening requirements. The transformational impact of this cannot be understated. Engineering Team We are building a team of changemakers. It is not enough to have the intention to do good - Esusu engineers translate intent into action. We believe that accomplishing our ambitious goals cannot be done by lone heroes. Lasting change requires work by synergistic teams, and we look for Engineers who are highly skilled at collaboration.The ChallengeWe are seeking an experienced Staff Front-end Software Engineer with React, TypeScript, and related technologies expertise to play a pivotal role in the future growth of our company. You will be responsible for providing front-end guidance for an agile team of mission-driven and talented front-end and back-end engineers.Our back-end is microservice based, hosted in AWS and mainly written in Go. Our data infrastructure has historically been on MongoDB, but we also have numerous PostgreSQL databases and we are evolving a data lake based on Snowflake. Our front-ends are currently React apps written in Typescript. We are continuously innovating, and always open to new solutions. Because Esusu is a financial services company, we are obsessive about every aspect of security. We are Test-Driven-Development enthusiasts, and we are evolving towards a DevOps environment where your team is responsible for the full spectrum of development, testing, deployment, and maintenance, including working with product and operations teams to create customer-focused solutions. Even though we are 100% remote, Esusu’s culture is intensely collaborative.You will be working on our next generation consumer facing apps, designing and building new features/functionality that will benefit millions of people. You will help set our future generation front-end framework and best practices. These products will drive the future growth of our company, and you will be pivotal in their development. This will require you to strip problems down to their essential elements, then conceive simple, elegant solutions –always planning for scale, always thinking from a customer and product-oriented perspective.This role will report to the company’s Consumer Products Engineering Manager.What You Will DeliverYou and your team will create a suite of consumer applications that will help millions of people in their financial journey and keep a roof over their heads.You will lead the evolution of the front end of our consumer web app.You will collaborate with engineers, product managers and user experience (UX) designers to design and develop modern, consistent, fast, responsive user interfaces using leading UX design patterns and best practices.You will mentor other developers on the team in their work.You will help maintain existing web apps, including testing, fixing bugs, troubleshooting, adding new features, and maintaining documentation.You will design and develop new custom components to meet project requirements.You will interface with product and business stakeholders to help to develop the product roadmap of our consumer facing services.Core CompetenciesSuperb programming and software development skills –You can independently devise and implement solutions to problems with minimal explanation needed.Strong communication skills –You can efficiently translate between technical and non-technical audiences and have strong writing skills.High standards –Your work is of the highest quality and you continue to raise the bar within your immediate team and our organization.Balance velocity with long-term goals –You balance thinking big with delivering the right thing in an agile and speedy manner.Heart of a teacher –You are a capable mentor and able to inspire and empower others on your team.Basic QualificationsVery Strong Experience with front end web technologies.Strong experience developing web applications with React or React Native.Superb communication, design, and technical writing skills - you can independently devise and implement solutions to problems with minimal explanation needed.Experience with TDD practices and testing tools such as Jest, Mocha, JUnit, Cucumber, Selenium, or Playwright.Experience creating solutions in an Agile environment.Experience working in a DevOps environment (we are on AWS).Experience working in a CI/CD environment.Experience in app instrumentation and analyzing and utilizing the results, particularly concerning usability and engagement.Above and BeyondExperience building visualization-intensive applications, using tools such as D3.js.Familiarity with back-end technologies including Nodejs, Go, Python, SQL, AWS Lambda, infrastructure as code etc.Experience in a FinTech or PropTech startupExperience working with globally distributed teamsExperience in SOC2 certified organizationsBenefitsCompetitive Salary - for Series B startup - $170,000-190,000 annualRestricted Stock Units (RSU)Full Medical, Dental, Vision InsuranceFitness/Gym Stipend401K PlanPaid Parental LeaveRemote Work Environment - we are 100% virtual, spread across 5 continents.Flexible PTO PolicyMission driven company with strong cultureThis job is eligible only for the following states: Alabama, Arizona, California, Colorado, Connecticut, Florida, Georgia, Hawaii, Idaho, Illinois, Indiana, Iowa, Kansas, Massachusetts, Maine, Maryland, Michigan, Missouri, Minnesota, Montana, New Hampshire, New Jersey, New Mexico, New York, North Carolina, Ohio, Oklahoma, Oregon, Pennsylvania, Tennessee, Texas, Utah, Vermont, Virginia, Washington, and West Virginia. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.© Esusu Inc. All rights reserved, Esusu is proud to be an equal opportunity workplace. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate on the basis of race, religion, color, gender identity, sexual orientation, age, disability, veteran status, or other applicable legally protected characteristics. We encourage people of different backgrounds, experiences, abilities, and perspectives to apply."
Entry-Level Data Scientist Engineer   - US/Canada Only,Phoenix Recruitment LLC,"Denver, CO (Remote)",https://www.linkedin.com/jobs/view/3780149992/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=dkd%2B3sLdch57%2FiijkPio2w%3D%3D&trk=flagship3_search_srp_jobs,3780149992,"About the job
            
 
This is a remote position.Entry-Level Data Scientist Engineer - US/Canada Only, 1 year of project experienceEmployment Type: Full-timeBase Salary: $63K-$73KPhoenix Recruitment offers a variety of recruiting services to assist both employers and employees. They specialize in marketing open positions, recruiting, and helping employers to find qualified candidates across various industries. Phoenix Recruitment has expertise in streamlining the hiring process. They can help ensure that the process is efficient, well organized, and compliant with relevant regulations.Skills and Abilities: Strong knowledge of R or Python for data analysis and modeling. Proficiency in statistical programs such as R, SAS, MATLAB, or Python. Familiarity with spreadsheets (VBA) and database applications (Access, Oracle, SQL, or equivalent technology). Basic understanding of SQL, Javascript, XML, JSON, and HTML. Ability to learn new methods quickly and work under deadlines. Excellent teamwork and communication skills. Strong analytical and problem-solving abilities. Basic understanding of SQL, Javascript, XML, JSON, and HTML. 
Preferred: Knowledge of actuarial concepts and life, health, and/or annuity products. Experience with statistical modeling techniques such as GLM, Decision Trees, Time Series, Regression, etc. Familiarity with Microsoft DeployR. Exposure to insurance risk analysis. Basic experience in computational finance, econometrics, statistics, and math. Knowledge of SQL and VBA. Familiarity with R or Python for predictive modeling 
Why Phoenix Recruitment LLC?Phoenix Recruitment often has an extensive network of employers and candidates. This network allows them to tap into a pool of qualified candidates and connect them with suitable job opportunities. They can also leverage their connections to help employers find the right talent efficiently. Outsourcing the recruitment process to a specialized agency can save your time and resources, avoid delays, reduce administrative burdens, and increase the chances of finding the right fit for your organization."
Data Engineer,Shipwell,"Austin, TX (Remote)",https://www.linkedin.com/jobs/view/3756146639/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=H%2FMPYn9N9ic5E7joTqWhIw%3D%3D&trk=flagship3_search_srp_jobs,3756146639,"About the job
            
 
About ShipwellAt Shipwell, we empower supply chain efficiency and service effectiveness at scale. The Shipwell platform includes capabilities previously out of most shippers' technical reach and affordability today. Our solution combines everything shippers need, from transportation management and visibility to procurement, in a comprehensive, easy-to-use platform. It will adapt and scale as market and business demand change, allowing shippers to operate, manage, and optimize the shipping process seamlessly. Industry experts have recognized Shipwell's traction in the market and have differentiated Shipwell as a leader in the logistics industry. Awards include Gartner Magic Quadrant for TMS 2023, 2022, 2021, Food Logistics' 2022 Top Software & Technology Providers, and FreightWaves' FreightTech 2022 and 2021 Awards for Innovation and Disruption in Freight Industry. Shipwell was also named the fourth fastest-growing company in North America on the 2021, 2022, and 2023 Deloitte Technology Fast 500 and Forbes 2020 Next Billion-Dollar Startup.Our CultureShipwell is a fast-paced, high-energy start-up that strives to build the future of shipping every day. Diversity of thought and cross-department collaboration is very important to us. We deliver open, honest, careful communication and work as hard as we play. We create & deliver solutions that are revolutionizing the industry, which brings excitement and purpose to our work. If you are looking for a place that will help you tap into your best work-self and give you hands-on experience building something big, then we invite you to come and build the future of shipping with us!About The RoleAs a Data Engineer, you will contribute to the design, development, and maintenance of data pipelines. Your responsibilities will encompass extracting, transforming, and loading (ETL) data from various sources, developing and executing data integrity standards, and optimizing performance. You will collaborate closely with cross-functional teams and contribute to the development of scalable and efficient data architectures. This role provides a dynamic opportunity to leverage your expertise in data engineering and learn more about the data infrastructure at Shipwell. This will enable you to drive insights and support data-driven decision-making within our organization.What we're looking for: Experience working with large-scale data model refactoring for better performance, interpretability, and maintainabilityExperience designing and implementing data models and analytics reports in a cloud environmentProven track record of implementing data engineering best practices in all aspects of the data pipeline, i.e. ETL, data integrity, and monitoringDemonstrable proficiency in Python, SQL, and DBT. Experience with Looker is a plusExperience with version control tools (GitHub, GitLab) and Agile methodologies. Bachelor's Degree in a quantitative field such as Physics, Engineering, Computer Science, or demonstrated equivalent quantitative experience. Excellent communication skills to effectively collaborate with different teams within the data org
What you'll do when you get here: Collaborate closely with our engineering, analytics, and data science teams as we take our data infrastructure to the next levelRight at the start you will be creating Looker dashboards for our customers, implementing DBT in our data pipelines, and creating monitoring wherever our data is usedYou will own all of the data processes you createYou will become the expert on our data infrastructure and make critical decisions in our path forwardYou will have the opportunity to grow your skill set and take part in projects at the forefront of GenAI, ML, and data science in the logistics industry
Why Shipwell: Enjoy working remotely with the added perk of a home office reimbursementUnlimited Paid Time Off (PTO)A robust healthcare package that includes medical, dental & vision benefits, short-term and long-term disability, AD&S coverage, and flexible/health savings accounts40K program where Shipwell matches up to 4%A yearly learning and development budgetSubsidized internet, cell phone, fitness, and educational reimbursementsVirtual team-building events where fun and connection take center stage Join a vibrant, inclusive workplace shaped by friendly, talented individualsReceive a technology package including a MacBook ProEmployee Recognition Program to celebrate and incentivize hard work and success!
The Salary Range for this role is between $90,000 - $130,000/year. Compensation is based on a number of factors including market location, job-related knowledge, skills, and experience.Shipwell is an equal opportunity employer and welcomes all qualified applicants regardless of race, ethnicity, religion, gender, gender identity, sexual orientation, disability status, protected veteran status, or any other characteristic protected by law. We celebrate diversity and believe that experience comes in different forms. Diversity in our team makes for better problem-solving, more creative thinking, and ultimately a better product and company culture.Even more important than your resume is a clear demonstration of impact, dedication, and the ability to thrive in a fast-paced and collaborative environment. Shipwell strives to have an inclusive work environment; so if you are hard-working & good at what you do then please come as you are. We want you to contribute, grow, & learn at Shipwell.We are looking forward to adding new perspectives to our team!For more information about Shipwell visit shipwell.com, or connect with us on Twitter @shipwell, LinkedIn, and Facebook.com/Shipwellinc"
Data Engineer -Remote,"RIT Solutions, Inc.","Denver, CO (Remote)",https://www.linkedin.com/jobs/view/3768007496/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=IG9IRsil07xNXDvrbw2TuQ%3D%3D&trk=flagship3_search_srp_jobs,3768007496,"About the job
            
 
Duration: 6+ months CTHMust have a valid LinkedIn profileRequired Skills  3-6 years of experience (no more than 6 years) Start up environment experience Python, SQL, and DBT"
Entry Level Data Engineer (Remote),SynergisticIT,"Savannah, GA (Remote)",https://www.linkedin.com/jobs/view/3767597153/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=ORiZaPFIsQc7kifgaghNwQ%3D%3D&trk=flagship3_search_srp_jobs,3767597153,"About the job
            
 
The Job Market is Challenging due to almost 300,000 Tech Layoffs since October 2022 due to which thousands of laid off Techies are competing with existing Jobseekers. Entry level Job seekers struggle to get responses to their applications forget about getting client interviews. As the Saying goes ""when the Going gets tough the Tough get going” Candidates who want to make a tech career they need to differentiate themselves by ensuring they have exceptional skills and technologies to be noticed by clients.Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.All Positions are open for all visas and US citizensWe are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$'s and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs. Clients now post covid can also hire remote workers which increases even more competition for jobseekers.We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, PayPal, western union, Client, visa, Walmart labs etc. to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in IT IndustryWe assist in filing for STEM extension and also for H1b and Green card filing to Candidates We also offer optionally Skill and technology enhancement programs for candidates who are either missing skills or are lacking Industry/Client experience with Projects and skills. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. If they are qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients. Shortlisting and selection is totally based on clients discretion not ours.please check the below links to see success outcomes of our candidateshttps://www.synergisticit.com/candidate-outcomes/We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023https://youtu.be/Rfn8Y0gnfL8?si=p2V4KFv5HukJXTrnhttps://youtu.be/-HkNN1ag6Zk?si=1NRfgsvL_HJMVb6Qhttps://www.youtube.com/watch?v=OAFOhcGy9Z8https://www.youtube.com/watch?v=EmO7NrWHkLMhttps://www.youtube.com/watch?v=NVBU9RYZ6UIhttps://www.youtube.com/watch?v=Yy74yvjatVgFor preparing for interviews please visit https://www.synergisticit.com/interview-questions/We are looking for the right matching candidates for our clientsPlease apply via the job postingREQUIRED SKILLS For Java /Full Stack/Software Programmer Bachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleProject work on the skillsKnowledge of Core Java, JavaScript, C++ or software programmingSpring boot, Microservices, Docker, Jenkins and REST API's experienceExcellent written and verbal communication skills
For data Science/Machine learning PositionsRequired Skills Bachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITProject work on the technologies neededHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, SAS, Python, Computer Vision, data visualization toolsExcellent written and verbal communication skills
Preferred skills: NLP, Text mining, Tableau, PowerBI, TensorFlowIf you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates"
Data Engineer (Remote),Cascade Debt,United States (Remote),https://www.linkedin.com/jobs/view/3755336571/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=4Xx4Px9sacyprSRPhO%2B4mQ%3D%3D&trk=flagship3_search_srp_jobs,3755336571,"About the job
            
 
Do you want to work in a small team where you can make a real difference in a company? Would you embrace the challenge of building a high impact platform that is used globally? Then we want to speak with you!About CascadeCascade is a fintech startup backed by Canadian and US investors that empowers companies to grow by democratizing access to institutional debt. We are building tools that modernize how companies raise and manage debt, lowering the barriers to entry to the $7 trillion specialty finance and alternative credit market for companies around the world. Founded just last year, we are gearing up for our next phase of technical development and are seeking a talented Data Engineer to lead the way.About The RoleAs a Data Engineer you’ll be an early member of a growing team building a pioneering platform in the debt infrastructure space. You will design, build, and launch efficient, scalable, and reliable data pipelines to move and transform data .What You’ll Do  Building databases, data lakes and data ingestion pipelines to integrate customer databases and datasets to our systems  Ingesting financial datasets from external customers, then u pdating and maintaining accurate and complete data mappings to ensure that our product s are displaying high quality data  M onitoring and alerting across our data pipelines in order to make sure that our data ingests are reliable and correct  Translat ing business goals and stakeholder requirements into new data flows and deliver analytical insights ensuring that the data flows create real business value continuously 
Skills And Experience  2 + years experience in a data engineering or data analyst role  E xperience with relational SQL and NoSQL databases, including PostgreSQL , MySQL, MariaDB, MongoDB, Bigtable, etc.  E xperience working with ETL technologies , such as Databricks, Fivetran , or dbt  Proficiency in writing SQL queries and knowledge of analytical data warehouses such as RedShift, BigQuery , and Snowflake  Some experience with CI/CD automation such as GitHub Actions  Developing APIs and integrating with 3rd party APIs  Bonus: experience in fintech / SaaS / credit analysis 
People Who Thrive At Cascade Are  Self-starters, who take the initiative to tackle challenges in a remote work environment  Good communicators, who can operate without ego to discuss, learn, grow, and help others do the same  Passionate about creating great digital experiences for users  Problem solvers who are not satisfied with the status quo 
Benefits Remote: we are a remote-first company and are very flexible on hours as long as things get done Home-office: there’s a $1000 USD home office allowance to set yourself up Equity: we expect you to have an owner-mentality, and have the equity plan to match Benefits: health, dental, vision, and more Perks: we offer free lunches weekly and off-site trips Job satisfaction: we offer autonomy, ample opportunities for mastery, and an opportunity to make a difference for companies around the world"
Data Engineer,Anika Systems,"Leesburg, VA (Remote)",https://www.linkedin.com/jobs/view/3766103708/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=cuppQtLIdpAZqAuixSZ32Q%3D%3D&trk=flagship3_search_srp_jobs,3766103708,"About the job
            
 
Anika Systems is a fast growing, woman-owned small business that specializes in providing innovative IT solutions for federal government agencies. Our expertise lies in accelerating delivery in Data and Analytics, Intelligent Automation, Application Development, and IT Modernization. We are currently expanding our Federal team and are seeking a passionate and talented Data Engineer. This opportunity is 100% remote.Must be a U.S. Citizen with the ability to obtain and maintain a government suitability clearanceResponsibilities Designs, develops, builds, analyzes, evaluates, and installs database management systems to include database modeling and design, relational database architecture, metadata, and repository creation and configuration management.Defines and oversees database organizations, standards, controls, procedures, and documentation. Provides technical consulting in the definition, design, and creation of a database environment.Advises applications development staff and users on data-based solutions to business problems, data architectures, database management system facilities and capabilities, and the operation and tuning of databases.Designs and implements databases with respect to access methods, access time, batch processes, device allocation, validation checks, organization, protection and security, documentation, and statistical methods.Uses data mapping, data mining, and data transformational analysis tools to design and develop databases.Determines data storage and optimum storage requirements.Prepares system requirements, source analysis, and process analyses and designs throughout the database implementation.
Required Skills And Experience BA/BS and 1 year of relevant experienceExperience with DataBricks, SQL, PythonApplications development experience with data-based solutions to business problems, data architectures, database management system facilities and capabilities, and the operation and tuning of databases.Excellent communication skills (both oral and written) with process-oriented organizational skills to ensure project success
Desired Skills And Experience Demonstrated successful development experience with the full life cycle of government database management systems including database modeling and design, relational database architecture, metadata and repository creation, and configuration management.
Powered by JazzHRTlKWIorucJ"
Entry Level Software Engineer - Data Backend Engineer (Remote - Canada),Yelp,United States (Remote),https://www.linkedin.com/jobs/view/3752881757/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=fxvTFBElWeCrjvilzqYiIw%3D%3D&trk=flagship3_search_srp_jobs,3752881757,"About the job
            
 
Yelp engineering culture is driven by our values: we’re a cooperative team that values individual authenticity and encourages creative solutions to problems. All new engineers deploy working code their first week, and we strive to broaden individual impact with support from managers, mentors, and teams. At the end of the day, we’re all about helping our users, growing as engineers, and having fun in a collaborative environment. Interested in exploring data and finding innovative ways to collect it, curate it, and make it easily accessible for others to use? How about doing that at an enormous scale? Yelp’s datasets contain billions of interactions between users and local businesses around the globe. If working with our vast amount of data sounds exciting, come and join us!The Marketplace Data Observability team is responsible for managing, governing, and monitoring all of Yelp’s Ads data to protect our revenue stream and also support offline analysis that aids in making long term company decisions. We build tools that help us to better understand our data quality, and we strive to uncover data issues before they impact our consumers.As a Data Backend Engineer on this team, you will be responsible for building elegant and scalable data products that serve critical, up-to-date, structured information to support different types of analytics within Yelp. As a core contributor to our growing data modeling and data warehousing engineering efforts, you will help design and own mission-critical data flow pipelines and datastores to enable decisions including effective A/B testing and company investments. This opportunity is fully remote and does not require you to be located in any particular area in Canada. We welcome applicants from throughout Canada. We’d love to have you apply, even if you don’t feel you meet every single requirement in this posting. At Yelp, we’re looking for great people, not just those who simply check off all the boxes.  Build systems that can effectively store and crunch terabytes of data.Design and develop data models for efficient data storage, retrieval, and reporting.Create and maintain conceptual, logical, and physical data models using industry-standard modeling tools.Collaborate with cross-functional teams, including engineers, data analysts, business analysts, and data scientists, to understand data requirements and translate them into effective data models.Participate in data integration efforts, including ETL processes and data migration.Stay up-to-date with industry best practices, emerging technologies, and trends related to data warehousing.Support on-call rotations as needed to operate the team.
  Understanding of high performing and scalable data systems.Experience in building and orchestrating ETL pipelines.Experience with Data Lake or Data Warehouse landscape.A hunger for tracking down root causes and fixing them in systematic ways.Ability to communicate effectively to technical and non-technical cohorts alike. Exposure to some of the following technologies: Python, AWS Redshift, AWS Athena / Apache Presto, Big Data technologies (e.g S3, Hadoop, Hive, Spark, Flink, Kafka etc), NoSQL systems like Cassandra, DBT."
Remote Opportunity: Quantexa Data Engineer,SPAR Information Systems LLC,United States (Remote),https://www.linkedin.com/jobs/view/3680073191/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=2BCFtMnhgLQPfSo0rttHIA%3D%3D&trk=flagship3_search_srp_jobs,3680073191,"About the job
            
 
Hello All, Hope you are doing great!! Please go through the job descriptions and let me know your interest. Role: Quantexa Data engineer  Location: Remote Duration: Long Term Contract Job Description: 1. End to End usage of Quantexa including guiding our client team on how to use from both front end and data ingestion Reason they are asking for Certification 2. Resolve Entity issues with data 3. Knowledge of Scala and Hive which requires coding experience using parquet 4. Advanced SQL knowledge requiring writing SQL queries 5. Experience having worked with GCP data lake 6. Quantexa certification requiredThanks & Regards,Satnam SinghDirect: 201 623 3660Email : Satnam.singh@sparinfosys.com"
Data Engineer,Catalist,"Washington, DC (Remote)",https://www.linkedin.com/jobs/view/3744951279/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=GCYrVMiSgKtcUGLgYv%2FP6A%3D%3D&trk=flagship3_search_srp_jobs,3744951279,"About the job
            
 
For over 17 years, Catalist has been a leader in civic data and data science innovation. Our mission is to provide progressive organizations with the data, software, and services needed to better identify, understand, and communicate with the people they need to engage and mobilize. Our clients include the largest, most influential organizations in the U.S. active in civic engagement, advocacy, and political campaigns.Catalist is home to a dedicated, creative team of technologists, data scientists, and campaign experts committed to using our talents and technology to nurture a vibrant and growing progressive community.As a Data Engineer at Catalist, you will work closely with the Analytics and Technology departments to design, build, support, and maintain various data pipelines and processes with an end goal of providing data and intelligence to the progressive community. This role primarily involves translating data architecture designs into functional processes, code, and systems.The ideal candidate will be a highly motivated individual with excellent technical skills, a strong desire to learn new skills, and an interest in progressive politics. Catalist values creativity and problem-solving. Our work is on the cutting edge of data-driven politics, and your support will help Democratic candidates and progressive organizations conduct successful advocacy and electoral campaigns.This position reports to the Deputy Chief Data Officer. The Data Engineer is a part of a growing Data team that supports all underlying work at Catalist.This position is included in our CWA bargaining unit.Principle Duties & Responsibilities Develop scalable, production processes, code, and systems for data ingest, transformation, modeling, and reporting across a variety of platformsTranslate mock-ups and designs into functional processes, code, and systemsCreate architecture designs when neededProvide quality assurance and testing on processes, code, systems, and productsBecome an internal subject matter expert on various datasets and support other Catalist departments/teams on usage of those datasetsExecute ad-hoc data and database maintenance tasks as requiredProject manage cross-departmental efforts, with direct responsibility for stakeholder engagement, management, and execution of technical elements
Requirements BS or BA in a technical field, or relevant experience1-2 years of experience working with SQL databasesExperience with data cleaning or ETL processesExperience with distributed computing systems and/or distributed datastores (particularly the Hadoop ecosystem)Experience managing projectsFamiliarity with Catalist data, progressive politics, voter files, and/or commercial dataBackground check required
Preferred Skills & Abilities Willingness to be a problem solver and produce results in a fast paced environmentAbility to be creative and personable, and articulate ideas clearlyExperience working with SQL databasesProficiency with Python or another object-oriented programming language (R, Java, Scala, etc…)Experience working in cloud environments (AWS, GCP, etc.)Experience working in command line environments such as BashExperience with a version control tool such as git or github
BenefitsMedical, Dental, Vision, Prescription DrugCatalist offers Medical, Dental, Vision, and Prescription Drug coverage for eligible staff and their eligible dependents. Catalist’s Medical plan is a comprehensive PPO program including Prescription Drug coverage with 85% of the premium paid by Catalist. Dental and Vision coverage is provided at no cost to employees.Group Term Life Insurance and Long-Term & Short-Term Disability CoverageGroup Term Life Insurance and Long-Term and Short-Term Disability coverage is available for eligible staff. These benefits are provided at no cost to Catalist employees.401(k) Safe Harbor PlanA 401(k) Safe Harbor Plan is available to eligible staff with a 3% contribution from Catalist from the date of hire. Employees may contribute pre-tax or post-tax from their salary up to the legal limits set forth by the IRS.Medical and Dependent Care Flexible Spending Accounts (FSAs)Catalist offers an FSA Program that gives eligible staff the ability to pay out-of-pocket medical/dental/vision/child care expenses from pre-tax earnings.Transit BenefitsCatalist also makes available a Transit benefit FSA program to eligible employees using pre-tax contributions with a company match.Professional Development and Remote Work ExpensesEligible employees may be reimbursed up to $750 each year for professional development / education and remote work expenses.Student Loan PayDown or SaveUpCatalist offers a Student Loan PayDown and College SaveUp benefit for eligible staff.Vacation, Personal Leave, Sick Leave BenefitsCatalist offers generous vacation benefits to all eligible staff. Eligible employees also receive:  14 Paid Holidays Personal Days Sick Leave Parental Leave
Hybrid Office/Remote WorkCertain positions at Catalist are eligible for Office/Remote Hybrid or full Remote status."
"Data Engineer (Associate Consultant), June 2024",UDig,"Nashville, TN (Remote)",https://www.linkedin.com/jobs/view/3716039960/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=ipnILYcX%2F%2BiycJaullk23Q%3D%3D&trk=flagship3_search_srp_jobs,3716039960,"About the job
            
 
Can UDig It? UDig designs, builds, and implements technology solutions that deliver on business objectives. People join our team because they are excited to have an impact on the future of our organization, passionate about delivering meaningful results, and energized by solving complex problems. Oh, and they like working with other driven, smart, and authentic people!UDig is proud to be recognized as a ""Best Places to Work"" in Virginia and Tennessee. We're committed to fostering a transparent environment where leadership is accessible, professional development opportunities are abundant, and you are empowered to achieve your career goals. You'll collaborate, develop deep relationships with teammates, and accelerate your success while having fun!If you're graduating in May 2024 and excited by the idea of impacting organizations by building data solutions to achieve business goals, you should consider joining our growing technology team.How Things Go DownAs a new, entry-level teammate, you'll take part in our ""Breaking Ground"" training program designed to help you quickly get up-to-speed on UDig's delivery approach within a project team. The program covers: UDig delivery process and methodologies such as gathering requirements and delivering projects using agileTechnical guidance and instruction on the best practices from Data leaders at UDigDelivering executive and technical presentationsCoaching to prepare you to for success on your first client project at UDig
A typical day might entail: Project standups and check-insDesign and development of data pipelines, BI reports, and morePlanning and participating in project demosContributing to internal UDig projectsCareer and job growth through UDig-provided trainingCreating long-lasting friendships with teammates through fun activities as well as your projects (including social events, winning a prize for guessing the weight of pumpkin, or sharing experience on cool tech side projects)
UDig believes it is important for Associate Consultants going through our Breaking Ground program to reside in one of our major markets (Richmond, VA or Nashville, TN metro area) for at least the first year of employment.Want to learn more? Hear directly from our teammates by checking out our 'A Day in the Life' blog series: https://www.udig.com/digging-in/breaking-ground-2023/Sound Interesting? Here's the Technical PieceBelow are a few boxes you should be able to check if you're interested: Don't check every box? Go ahead and apply! 1+ year of experience with relational database management systems such as Microsoft SQL Server, MySQL, or OracleUnderstanding of the full lifecycle of design, development, and implementation of data solutions including architecture design, development, testingSome experience in ETL development or reporting is a plusAbility to present technical ideas and high-level concepts and solutions to internal and external team members with varying degrees of technical knowledgeBachelor's Degree in in computer science, information technology, or any science or business disciplineAbility to take your work seriously but also seriously enjoy a good time with your UDig colleagues
What's in It For You? At UDig, you will build your career alongside talented and experienced developers while gaining experience and having fun! We provide continuous challenges and professional development opportunities. Additionally, we offer:  Competitive salary, merit reviews, and career advancement pathsFlexible, hybrid environmentIndividual $1500 Training BudgetRegular team building and social activities (virtual and/or in-person)Transparent culture with strong communication and access to leadershipGreat benefits like Generous Paid Time Off, company holidays, and parental leaveMultiple Single and Family Health Insurance plans to choose fromDental & Vision coverageShort-Term and Long-Term disabilityOptional accident and critical illness coverageMatching 401(k)and more!"
Data Engineer  - Need candidates from Texas ( REMOTE ),Pulivarthi Group (PG),United States (Remote),https://www.linkedin.com/jobs/view/3770685212/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=shDowmWVbX%2F5CRlsJjEcnw%3D%3D&trk=flagship3_search_srp_jobs,3770685212,"About the job
            
 
Follow us on Linkedin: https://www.linkedin.com/company/pulivarthigroup/Pulivarthi Group LLC is a Global Staffing & IT Technology Solutions company, with our prime focus of providing world class solutions to our customers with the right talent. We combine the expertise of our team and the culture of your company to help you with the solution that is affordable and innovative using high quality standards and technologies.We’ve served some of the largest healthcare, financial services, and government entities in the U.S. Data Engineer - FT only - Azure SQL with data lakes experience
Data Engineer -the resource requirement for this Data Engineer role needed more clarification.Our customer is requesting a resource who knows Azure CI/CD (Continuous Integration / Continuous Deployment) to build and integrate their DevOps pipeline.Once the DevOps pipelines are mapped, they need the Data Engineer to connect to all the Data Sources, primarily their Data Lake.The Customer (based in Houston) is interested in a resource in a time zone not too far removed from the Central Time Zone to allow real time collaboration."
Data Engineer,Team Remotely Inc,"Denver, CO (Remote)",https://www.linkedin.com/jobs/view/3779588500/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=8%2FGH6BbM0qobQFBbdHUk%2Bg%3D%3D&trk=flagship3_search_srp_jobs,3779588500,"About the job
            
 
This is a remote position. Data Engineer (US/Canada Residents Only, 1 year experience, remote)Team Remotely Inc. is a staffing and recruitment agency that offers a comprehensive solution for talent acquisition, including sourcing, vetting, pay rolling, and managing talent. Whether you need contract staffing, direct hire, direct sourcing, talent pools, or diversity initiatives, our model can support your hiring strategy. Hiring Type: Full-Time Base Salary: $57K-$68K Per Annum. How to Apply: Please visit teamremotely.com to learn more & apply.Responsibilities Designing user interface changes for web-based DB applications. Reviewing application requirements and interface designs. Developing and implementing highly responsive user interface components using react concepts. Writing application interface codes using JavaScript following react.js workflows. Troubleshooting interface software and debugging application codes. Developing and implementing front-end architecture to support user interface concepts. Monitoring and improving front-end performance. 
Qualifications And Experience Bachelor’s degree in computer science, information technology, or a similar field. Previous experience working as a react.js developer. In-depth knowledge of JavaScript, CSS, HTML, jQuery, and front-end languages. Knowledge of REACT tools including React.js, Webpack, Enzyme, Redux, and Flux. Experience with user interface design. Knowledge of performance testing frameworks, including Mocha and Jest. Experience with browser-based debugging and performance testing software. Troubleshooting skills. Project management skills. Problem-solving skills. Verbal communication skills. 
 Why work with Team Remotely?Team Remotely Inc. is a staffing platform offering a seamless experience for employers and candidates. Employers can post job openings and specify their requirements, while candidates can create profiles and upload resumes.The team of Team Remotely continuously learns and adapts based on previous successful placements, constantly improving its matching capabilities. This ensures that the recommendations provided by Team Remotely are tailored and accurate, increasing the likelihood of a successful match between employers and candidates. By providing intelligent and data-driven solutions, they strive to enhance the efficiency and effectiveness of the hiring process, ultimately helping companies find the best talent and individuals find their dream jobs."
Data Engineer,Leafwell,"Miami, FL (Remote)",https://www.linkedin.com/jobs/view/3667433581/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=8GTKYH8SAN%2FpNICAWy0MdA%3D%3D&trk=flagship3_search_srp_jobs,3667433581,"About the job
            
 
DescriptionWho is LeafwellLeafwell is a rapidly growing technology and data company that set out to increase access, education, and research into cannabis and to advance its application as medicine.An exciting opportunity for a Data Engineer to join our growing team has arisen.What To Expect As a Data Engineer At LeafwellAs a Data Engineer at Leafwell, you will be in charge of creating and orchestrating the Leafwell data pipeline, which means gathering data, creating & automating data transformations and producing actionable insights for Leafwell’s internal stakeholders. You will support critical testing and rollout of new data features. The Data Engineer will build and maintain systems that inform Leafwell’s business stakeholders about Key Performance Indicators (KPIs) and suggest data-driven strategies to optimize those metrics.Essential Duties And ResponsibilitiesThe Data Engineer will perform the following responsibilities: Acquire, assemble, transform and analyze dataCreate, manage and orchestrate the data pipeline and it’s infrastructurePresent findings, trends, and suggested optimizationsIdentify new opportunities and threats to the company's business modelUpdate and revise reports, queries, and analytic procedures as necessaryDesign and implement tracking so that optimization efforts can be measuredIdentify inefficiencies in data processes and automate where appropriateWrite and update international SOPs and internal documentationSupport IT systems management with testing, validation, and user supportProactively identify initiatives for data-related improvements
Why LeafwellAt Leafwell, we are passionate about our work and seek out employees who contribute the same level of dedication and enthusiasm. We are only as good as the people we hire, so we aim to be the best employer in order to attract the top talent in the industry.Do we have your Interest?RequirementsOur Ideal CandidateOur Ideal Candidate Will Possess The Following Bachelor's degree in Computer Science, Mathematics, Economics, Information Systems, or another quantitative field3-5 years of relevant professional experience in Data Engineering / AnalyticsAdvance working knowledge and experience in SQL and relational databasesStrong data management abilities, including data analysis, standardization, cleansing, querying, and consolidation of dataData visualization experience (e.g Tableau, Looker, etc.)Exercises self-reliance, initiative, and leadership while keeping stakeholders properly informed and involvedReliably manage numerous duties during a workday, necessitating interactions with people located across the worldTechnically competent, with the ability to quickly learn new processes and programs, and utilize various software applicationsExcellent communication and interpersonal skills; ability to work with and appeal to a wide variety of personalities and professional tendencies
Bonus Points If You Have Experience In The Following Cannabis knowledge; industry experience is a plusUsed Data Orchestration tools like Dagster or AirflowUsed dbt or comparable data transformation softwareGitPython or R programmingAmazon Web ServicesPostgreSQL and RedShiftCRM productsData Visualization in MetabaseEffective project management skills and comfort utilizing a project management platform in collaboration with other team membersData Science projects
Benefits HighlightsOur benefits include, but are not limited to: Remote first - Most of our employees are 100% remote. Positions requiring travel enjoy a hybrid environment. Rapid Growth - Our company is rapidly expanding, and our employees are advancing with us!Training and Development - We foster a culture of learning. We encourage our employees to take part in educational, training, and development opportunities.
Leafwell is dedicated to bringing together people from diverse cultures and perspectives. We work hard to provide a welcoming atmosphere where everyone may flourish, have a sense of belonging, and collaborate effectively. As an equal opportunity employer, we do not tolerate any illegal discrimination against job applicants based on their race, color, religion, veteran status, sex, parental status, gender identity or expression, transgender status, sexual orientation, national origin, age, disability, or genetic information. We are committed to going above and above in creating diversity within our firm and follow the regulations upheld by the EEOC."
Data Engineer,SnapX.ai,"Dallas, TX (Remote)",https://www.linkedin.com/jobs/view/3780166756/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=tCydVjrNQ4xpi5kONUNF5Q%3D%3D&trk=flagship3_search_srp_jobs,3780166756,"About the job
            
 
Dear Partner, Good morning,greetings from Snaprecruit LLC!Submission you please review the below role,If you are available.  MUST HAVE:e-commerce(retail) experience  5-7 years experience with Python
 Experience working with Google BigQuery and SQL

Desired Skills and Experience
                IT"
Data Engineer,ZAG Technical Services,United States (Remote),https://www.linkedin.com/jobs/view/3771403464/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=DyjjfmDOVybBlJAubQ0ZAA%3D%3D&trk=flagship3_search_srp_jobs,3771403464,"About the job
            
 
We are looking for a tech savvy Data Engineer to contribute to the building, operating, and scaling of next generation data platforms and tools that will power data-driven analytics capabilities throughout the ZAG products and services portfolio, spanning areas such as business intelligence, reporting, and data analytics.The ideal team member is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. Must be comfortable supporting the data needs of multiple clients and teams, systems, and products within the modernization of ecosystems. The right-fit person will be excited by the prospect of optimizing or even re-designing data processes to support next generation of advanced analytics capabilities, which in-turn translates to implementing strategic enhancements to maintain competitive advantage in the industry.The successful team member will leverage their proficiency to… Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Build the analytics processes required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, Data Management and cloud based ‘big data’ technologies.Build analytics tools that utilize technologies to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.Collaborate with client teams to identify and solution regional and local requirements within the context of the standard global business model for enterprise analytics.Participates in meetings, discussions, strategy sessions where changes, improvements, and enhancements are proposed, evaluated, and approved. 
The exceptional team member will have or demonstrate progressive experiences in…  Bachelor’s degree or higher in Computer Science or related fieldExperience working with BI and data warehousing toolsExperience working with enterprise data, where security is paramount and data governance is criticalAbility to work independently and in a team environment, and effectively engage all levels of the organizationUnderstanding of distributed systems driving large-scale data processing and analytics with a successful history of manipulating, processing, and extracting value from large, disconnected datasets.Ability to communicate effectively (listening, presenting, and questioning)Strong organizational, written, and communication skills
About ZAGZAG Technical Services empowers our clients’ success through intelligent business solutions that increase employee productivity, network security and team collaboration. We aim to ensure that our client’s IT investments drive ROI, provide a competitive advantage and help businesses grow. We do this by living our core set of values: Integrity Foremost, Client-Centered, Accountable Always, Teamwork Throughout, and Exceptional is the Goal.What ZAG Has To Offer Competitive compensation package Benefits including medical, dental, vision, 401K and life insurance 
ZAG Technical Services is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all of our employees.ZAG Technical Services is an E-Verify participant and will provide the Social Security Administration (SSA) and, if necessary, the Department of Homeland Security (DHS), with information from each new employee’s Form I-9 to confirm work authorization."
Data Engineer,theSkimm,"New York, NY (Remote)",https://www.linkedin.com/jobs/view/3754572564/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=Kbg8OSkBZF4LkUzoubh2Tg%3D%3D&trk=flagship3_search_srp_jobs,3754572564,"About the job
            
 
theSkimm'We're hiring a Data Engineer.About Our Team And What We'll Build TogetherWe're looking for an experienced Data Engineer and mentor to join theSkimm's Tech team. Our mission is to enable our partners across theSkimm, from Editorial and Audio to Marketing and Advertising, to achieve their goals with the best systems and processes we can offer. We build tools throughout the stack, share knowledge across departments, and learn quickly so we can take best advantage of what's coming.As we grow, we're looking for a Data Engineer who will help solidify and expand our pipelines and maintain our data warehouse. Our business is run on detailed analysis of how our products perform with our members, which features they love and which can be improved, and which product and marketing campaigns are bringing in the best quality users. You'll be responsible for working alongside analysts, product, marketing, and other teams to define new data collection components and measurement schemes that support each new product and feature.How You'll Contribute To Our Mission Create and maintain data pipelines to provide insights and drive business decisionsEstablish theSkimm's data warehousing strategy (ex. Kimball, Data Vault, etc.)Maintain theSkimm's data infrastructure on our AWS accountsCollaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization. Write unit/integration tests, contributes to engineering wiki, and documents workImplement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it
You're ready for this! Here's a bit more about what we're looking for 3+ years of industry experience measuring product performance and user behaviorExperience working with a variety of data management technologies, including RedShift, Kinesis/Kafka, Glue, Spark, Postgres, Airflow, dbt, and others. Experience implementing BI reporting tools such as LookerExperience interfacing with engineers, product managers and analysts to understand data needsKnowledge of a variety of measurement beacons, SDKs, APIs including Google Analytics, Amplitude, Braze, email service providersA commitment to building secure, resilient, fault-tolerant architectures, with clear documentation and procedures in place for supportA focus on accuracy and detail as you build, ensuring data pipelines produce clear, predictable resultsAbility to thrive in a dynamic, fast-paced, collaborative, and high-growth environmentFacility in presenting and discussing the trade-offs in employing different engineering solutions to a problem, valuing pragmatism over idealismAn empathetic leadership style that encourages open communication and trustUnderstanding of the typical metrics a subscription and advertising-supported business needs to measure successExperience with ML techniques as applied to behavioral segmentation or anomaly identification is a plusFamiliarity using developer tools that increase productivity and facilitate the development of resilient code (eg. Docker, CircleCI, Serverless) is a plusFamiliarity and enthusiasm for theSkimm: a passion for our audience and mission is a plus
The expected annual base salary for this role is $125,000-$135,000. We'll consider a variety of factors when determining the offered base salary including an evaluation of a candidate's skills, abilities, experience, location, market demands, and internal parity.Why our employees love working hereWe are mission driven and values driven:We are collectively building an impactful brand to empower generations of informed, confident women. Our vision is for every woman to have the info they need to navigate a complex world and the decisions in it. Every role has a purpose and allows us to provide useful information succinctly and contextualized. We tee her up to take action - whichever action is right for her, wherever she is.We are values driven at every point - how we work, the way we work and our culture come straight from our core values. Each of us supports this incredible brand and takes part in its continued growth, fulfilling the needs of our audience each and every day.We put you and your personal lives first - we have a generous benefits policy that demonstrates we are listening to what our employees need: Unlimited vacation policy and generous holiday observancesEncouraged time off on your birthday and Skimm'versary A hybrid working model with flexibility for remote workComprehensive insurance plans and commuter benefitsAuto-enrollment into an Empower 401(k) plan starting on your first day and employer contribution available after one year of employment Rewards for every work anniversaryOne month paid sabbatical after your five year Skimm'versary as a full-time employee
We support our parents at all points on their journey:  18 weeks of paid parental leave (adoption, fostering and surrogacy included)Bereavement leave for pregnancy lossPhased return to work schedule availabilityFlexibility based on parental schedulesAccess to family building and fertility benefitsFlexible and broad-scale child support program
Your well being is our priority:  We honor Sacred Time in our workplaceWe have aligned company ""time off"" during the summer to truly allow for us all to break from our work at the same timeWe offer fitness membership reimbursementOne Medical Membership is included with our benefits
We have a vibrant, collaborative, and supportive culture (we celebrate and have fun!): Weekly company updates led by our executive teamEmployee Resource GroupsAnnual employee award ceremony to celebrate individual accomplishmentsClubs and activities designed to meet other employees like book clubs, new hire buddy programs, off-sites, and wellness focused classesNumerous culture events that enable our workforce, in the office and remote, to connect and have fun
Your career and development are a priority:  Annual learning and development stipendLEAD@theSkimm, our leadership development programDEI initiatives to ensure we are the best partners and colleagues to each otherCareer development guidance and planning
And more… Competitive salary and equity packagesThe opportunity to be part of a values-driven, hardworking, and diverse group of people building a media company that makes it easier to live smarter
Our story, Skimm'dWe are a digital media company, dedicated to succinctly giving women the information they need to make confident decisions. We make it easier to live smarter.At our core, we are writers, editors, producers, designers, marketers, engineers, analysts, sellers, creatives, and strategists all working together to achieve this goal.Every day we're breaking down the news, trends, policies, and politics that impact women so that they can navigate their daily lives and futures – from managing their paychecks to casting their ballots – with confidence. We provide our dedicated audience of millions with reliable, non-partisan, information, informing and empowering them while fitting into their daily routines.Since disrupting the media landscape and defining a new category a decade ago, we have become a trusted source for our audience of millions by seamlessly integrating into their existing routines, fundamentally changing the way they consume news and make decisions. Today theSkimm ecosystem includes the Daily Skimm, the Daily Skimm: Weekend, Skimm Money and Skimm Your Life newsletters, B2B marketer's newsletter The SKM Report, ""9 to 5ish with theSkimm"" podcast, theSkimm mobile app. We also house Skimm Studios which creates innovative in-house video and audio content, and our in-house creative agency SKM Lab, which conceptualizes, develops, and produces innovative solutions and content for brands to engage with generations of informed women. Our first book, How to Skimm Your Life debuted at #1 on The New York Times Best Seller list. Through Skimm Impact, our purpose-driven platform, we are proud to support get-out-the-vote efforts with Skimm Your Ballot, which has spurred more than two million voting-related actions across the last four election cycles. We have mobilized hundreds of companies to join our #ShowUsYourLeave movement, which has created transparency and pushed for progress for Paid Family Leave in the U.S. And we're empowering women to take agency of their lives and control of their futures through our State of Women initiative, grounded in a study conducted by The Harris Poll.Come join us!"
Data Engineer,Lynx Analytics,"San Francisco, CA (Remote)",https://www.linkedin.com/jobs/view/3641777500/?eBP=JOB_SEARCH_ORGANIC&refId=Yl0fj3JHOQuAJZVhed8Kzg%3D%3D&trackingId=3mZu5EV6q7dMaUchD%2Fzgeg%3D%3D&trk=flagship3_search_srp_jobs,3641777500,"About the job
            
 
Company OverviewLynx Analytics was founded in 2010 by a group of INSEAD students and professors with a strong research background in graph analytics. Several of our founders since then became professors and faculty directors of analytics centers at leading US universities. Our founding purpose? To apply graph theory to simplify and solve complex, real-world business problems.Our mission has evolved over the years, and we currently offer a range of cutting edge data analytics and AI solutions to help companies transform their operations and optimise their commercial performance. Back then, graph theory was mostly the purview of social networking sites. We wanted to expand this technology and help companies leverage their communities to unlock greater growth.Lynx has offices in Singapore, US, Hong Kong, Hungary, and operations in several other countries such as Canada, Germany, Indonesia. We work with some of the world's largest companies and are constantly looking to expand our knowledge base and geographical footprint. Lynx Analytics' technology is deployed with various Clients internationally and has significant growth potential.We have a diverse and inclusive global team comprising Professors, PhDs, MSc's, and MBAs from Ivy Leagues, INSEAD and NUS with a broad spectrum of experience in start-ups and blue-chip companies (Google, Databricks, ZS, Abbvie, Amgen, Vodafone, Morgan Stanley, Palantir, Katana Graph to name but a few). It is the combination of our industry insight and experience, scalable proprietary technology, and highly qualified people that drives our compelling value proposition.We are looking for ambitious, innovative, empathetic and relentless team players to explore the career opportunities that we offer as we continue to scale our operations.Key ResponsibilitiesA Data Engineer's responsibility is to implement and deploy data analysis pipelines at various clients of Lynx Analytics. This includes participating in the activities below: Understand deeply the business problem that we are trying to solve by our analytical solutionThrough continuous consultations with employees of our client, discover the client's existing data sources that are relevant to the problem we try to solve. This includes discussions with client IT, data owners, future business users, etc. Working together with the IT teams of the client, define the technical architecture for the analytical solution that we are to deploy for the client. Implement the data ingestion subsystem: this is the system responsible for moving all the necessary data sources to a single location where the actual analysis will happen. Implement the data analysis pipelines. Integrate the results into business UIs developed by Lynx or pre-existing client software systems
Requirements Relevant tertiary qualification, preferably at Masters level or above, in Engineering or another relevant discipline with strong academic resultsStrong programming skillsExperience in GCP, Airflow and SparkSolid experience in Python and SQLGood problem-solving skillsGood communication skills
DESIRABLE Experience in Big DataA minimum of 3 years of experience in Data Science or AnalyticsIndustry experience in working for a big enterprise (like our clients)
What We Offer Opportunity to work on creating innovative, leading-edge data science pipelines using our state of the art, in-house built big graph toolWork closely with the developers of the (big graph) tool you will be building uponBe a member of a very strong team with mathematicians, ex-Googlers, Ivy League professors, MBA alumni and telecommunications industry expertsStartup atmosphere"
Entry Level Data Engineer (Remote),SynergisticIT,"Augusta, GA (Remote)",https://www.linkedin.com/jobs/view/3767593225/?eBP=JOB_SEARCH_ORGANIC&refId=t9HE8VvUb%2BJaHM%2Brfs1tnA%3D%3D&trackingId=BBVyQzOjuLLUvcYfYJMTtQ%3D%3D&trk=flagship3_search_srp_jobs,3767593225,"About the job
            
 
The Job Market is Challenging due to almost 300,000 Tech Layoffs since October 2022 due to which thousands of laid off Techies are competing with existing Jobseekers. Entry level Job seekers struggle to get responses to their applications forget about getting client interviews. As the Saying goes ""when the Going gets tough the Tough get going” Candidates who want to make a tech career they need to differentiate themselves by ensuring they have exceptional skills and technologies to be noticed by clients.Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.All Positions are open for all visas and US citizensWe are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$'s and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs. Clients now post covid can also hire remote workers which increases even more competition for jobseekers.We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, PayPal, western union, Client, visa, Walmart labs etc. to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in IT IndustryWe assist in filing for STEM extension and also for H1b and Green card filing to Candidates We also offer optionally Skill and technology enhancement programs for candidates who are either missing skills or are lacking Industry/Client experience with Projects and skills. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. If they are qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients. Shortlisting and selection is totally based on clients discretion not ours.please check the below links to see success outcomes of our candidateshttps://www.synergisticit.com/candidate-outcomes/We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023https://youtu.be/Rfn8Y0gnfL8?si=p2V4KFv5HukJXTrnhttps://youtu.be/-HkNN1ag6Zk?si=1NRfgsvL_HJMVb6Qhttps://www.youtube.com/watch?v=OAFOhcGy9Z8https://www.youtube.com/watch?v=EmO7NrWHkLMhttps://www.youtube.com/watch?v=NVBU9RYZ6UIhttps://www.youtube.com/watch?v=Yy74yvjatVgFor preparing for interviews please visit https://www.synergisticit.com/interview-questions/We are looking for the right matching candidates for our clientsPlease apply via the job postingREQUIRED SKILLS For Java /Full Stack/Software Programmer Bachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT Highly motivated, self-learner, and technically inquisitive Experience in programming language Java and understanding of the software development life cycle Project work on the skills Knowledge of Core Java, JavaScript, C++ or software programming Spring boot, Microservices, Docker, Jenkins and REST API's experience Excellent written and verbal communication skills 
For data Science/Machine learning PositionsRequired Skills Bachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT Project work on the technologies needed Highly motivated, self-learner, and technically inquisitive Experience in programming language Java and understanding of the software development life cycle Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools Excellent written and verbal communication skills 
Preferred skills: NLP, Text mining, Tableau, PowerBI, TensorFlowIf you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates"
GSA Data Engineer,Nike,"Beaverton, OR (Remote)",https://www.linkedin.com/jobs/view/3693334852/?eBP=JOB_SEARCH_ORGANIC&refId=t9HE8VvUb%2BJaHM%2Brfs1tnA%3D%3D&trackingId=UZZUQDg5G3RhO9LWMh2EtQ%3D%3D&trk=flagship3_search_srp_jobs,3693334852,"About the job
            
 
Work options: RemoteTitle: GSA Data EngineerLocation: Remote, USDuration: 1 Year ContractJob Duties Engineer data solutions in support of Sustainability reporting and analytics initiativesEngage with product owner, analysts, visualization developers, and business partners to understand capability requirements, and to develop and support data solutions based on product backlog priorities 
SkillsPreference will be shown to candidates who can provide a link to their open-source code portfolio (a link to your profile on github.com, bitbucket.com, gitlab.com, or another public VCS is sufficient)Required Technical CompetenciesCandidates should have demonstrated, in a professional capacity, all of the competencies listed for each of the following three subject areas:General Purpose Python Programming Python has been your primary coding language (daily use) for at least 3 yearsYou have authored distributable Python packages (packages that can be built, installed, and distributed using setup tools, pip, and twine)You have a solid understanding of how pip dependency resolution worksYou are proficient in authoring and automating unit and integration tests for Python packages using (minimally) unit tests, pytest, and toxYou are meticulous about code quality, including readability, know your PEP8 guidelines inside and out, and are capable of authoring code which will pass validation by commonly used static analysis tools including mypy and flake8 Database Design and SQLYou are proficient in authoring readable, well-structured, SQL SELECT statements using ISO/ANSI-standard SQLYou have hands-on professional experience in data warehouse design and modeling, including authoring DDL statements. Version Control and CI/CDYou have experience with trunk-based development (feature branching) using git for version control, with fully automated deployments (CI/CD).
Database Design and SQL You are proficient in authoring readable, well-structured, SQL SELECT statements using ISO/ANSI-standard SQLYou have hands-on professional experience in data warehouse design and modeling, including authoring DDL statements. Version Control and CI/CDYou have experience with trunk-based development (feature branching) using git for version control, with fully automated deployments (CI/CD).
Desired Technical Competencies General Purpose Python Programming You have a deep understanding of Python’s standard library and python internals. You understand python memory management, how CPython implements built-in data structures, and which data structures are best suited for different scenariosYou understand and can compare/contrast CPython’s built-in concurrency models, when to use each, and what obstacles might prevent the use of each mechanism
Database Design, SQL, and Object Relational Models You are adept at performance-tuning SQL queries for both OLAP and OLTP databasesYou understand and are prepared to discuss how and when/where to utilize more esoteric and/or modern SQL features such as window functions and common table expressions.You understand and are prepared to discuss the performance implications of columnar vs relational databases.You have hands-on experience in managing database schema migrations (ideally using SQLAlchemy’s ORM + Alembic). 
Version Control and CI/CD  You have experience with trunk-based development (feature branching) using git for version control, with fully automated deployments (CI/CD)
Cloud Infrastructure and Amazon Web Services  You have hands-on experience using boto3 to interact with Amazon Web Services’ resource APIs, particularly Amazon S3 (Simple Storage Service).You have hands-on experience authoring unit and integration tests utilizing local stack to emulate AWS resources.You have hands-on experience using HashiCorp Terraform to manage cloud infrastructure.You have hands-on experience developing serverless ASGI applications using AWS lambda and AWS API Gateway 
Web API Server and Client Development You have experience planning and executing the design and development of web APIs using a modern Python ASGI framework (preferably FastAPI).You have authored, validated, and maintained OpenAPI documents describing your web APIs accurately.You have experience developing and testing Python web API client libraries based on an OpenAPI document.
Distributed Computing and Apache Spark You have experience using Apache Spark for the ingestion and manipulation of data sets that are too large to process efficiently in memory.You have hands-on experience translating algorithms and procedures designed by topical subject matter experts, having varying levels of engineering experience, into well-designed data pipelines.You have experience configuring and tuning Spark clusters to optimize use of computing resources for varying workloads.You understand and can discuss: when and why to use distributed computing frameworks, such as Apache Spark, versus alternate concurrency models such as asyncio or multiprocessing. 
Database Design, SQL, and Object Relational Models You have experience modeling databases using SQLAlchemy’s ORM framework.You have experience managing database versions and schema migrations using SQLAlchemy with Alembic. 
Required Soft SkillsCandidates should have demonstrated, in a professional capacity, all or most of the following skills: You are proficient in communicating effectively and efficiently within a hybrid remote/in-person team structure:You are meticulous about managing your calendar to accurately reflect your free/busy hoursYou respect and seek to learn digital communications etiquette—including region-specific, industry-specific, and organization-specific etiquetteYou proactively initiate constructive discussions while curating and targeting your communications with respect for your colleagues’ time and schedulesYou are adept at discovering and navigating the complex bureaucratic resources of a large organization."
Remote Work - Need Azure Fabric Data Engineer,Steneral Consulting,United States (Remote),https://www.linkedin.com/jobs/view/3759325599/?eBP=JOB_SEARCH_ORGANIC&refId=t9HE8VvUb%2BJaHM%2Brfs1tnA%3D%3D&trackingId=cgMuPKJcUsFw36JHdbs8ow%3D%3D&trk=flagship3_search_srp_jobs,3759325599,"About the job
            
 
The client is placing heavy emphasis on Microsoft and Azure Fabric experienceInformation Management Engineer – Take the identified information management sources and assist migration to the Client Data Lake, Azure Fabric. The engineer will transform information management (de-dup, clean and enrich).Take the identified data sources and bring them into our Data Lake, Azure Fabric. Once the data is in, the engineer will need to be able to transform data (de-dup, clean and enrich the data). We are focused on using a medallion data model for data architecture. The tools we are working with are: Delta Parquet files, python, spark, notebooks, T-SQL, Fabric lakehouse/warehouse, Dataflows Gen2, Data Pipelines, Direct Lake, shortcuts, ADF."
Data Engineer - Remote | WFH,Get It Recruit - Information Technology,"Cedar Park, TX (Remote)",https://www.linkedin.com/jobs/view/3775426204/?eBP=JOB_SEARCH_ORGANIC&refId=t9HE8VvUb%2BJaHM%2Brfs1tnA%3D%3D&trackingId=frcAedTbwqUPmCwVpUZ9%2BQ%3D%3D&trk=flagship3_search_srp_jobs,3775426204,"About the job
            
 
We are a dynamic and innovative company looking for a talented individual to join our team as a Data Engineer. In this role, you'll play a crucial part in supporting our Data and Process Governance Policies and Standards, contributing to the optimization of workflows and data processing to deliver impactful insights to the shop floor. If you're passionate about data engineering, visualization, and maintaining a technical foundation, we'd love to hear from you.ResponsibilitiesCollaborate with cross-functional teams to implement and support Data and Process Governance Policies and Standards.Foster a strong business insight mindset to enable data visualizations that enhance decision-making.Maintain the technical foundation of data visualizations and optimize workflows through knowledge of industry-standard applications and database theory.Drive the interconnectivity between industrial automation data, MIS, and the data warehouse.Implement an end-to-end vision for the flow of production field data through the organization.Merge new systems or methods with existing data structures.Partner with Supply Chain to define, document, implement, and maintain business processes and data workflows.Develop and implement data visualizations and reporting solutions based on user needs and feedback.Collaborate with engineers and developers to create insightful data reports for business.Work closely with the manager, regional automation, or process engineers, depending on the site.RequirementsProven experience managing complex projects and collaborating with cross-functional teams.Strong knowledge of data governance concepts and implementation.Expertise in data access management, change management, and data historian/time series data.Proficiency in SQL, MSSQL, TSQL, and data modeling for maintaining data integrity between multiple schemas.Experience with ETL processes, with knowledge of Denodo/data virtualization being preferred.Proficiency in Python and query optimization.Hands-on experience working with big data sets.Familiarity with Tableau Server/Desktop/Prep setup and dashboard building.Strong data cleaning and wrangling skills.Initiative-driven, self-motivated, results-oriented, and able to work independently.Effective communication skills, both written and verbal, as this is a client-facing role.EducationBachelors would be a plus but not required; associates with relevant experience are welcome.Join our team and contribute to transforming the way we utilize data! This is a remote position, offering a collaborative and innovative work environment. We look forward to receiving your application.Employment Type: Full-Time"
Data Engineer - Remote | WFH,Get It Recruit - Information Technology,"Cleveland, OH (Remote)",https://www.linkedin.com/jobs/view/3765609897/?eBP=JOB_SEARCH_ORGANIC&refId=t9HE8VvUb%2BJaHM%2Brfs1tnA%3D%3D&trackingId=nEy9SPNFXNyFPtDjQnBptQ%3D%3D&trk=flagship3_search_srp_jobs,3765609897,"About the job
            
 
Join an innovative team at a leading company in the engineering and manufacturing industry, where we are committed to leveraging data for continuous improvement and operational excellence. This hybrid position allows you to enjoy the flexibility of remote work on Mondays and Fridays.Why Join UsAt our company, we prioritize your well-being and professional growth. We offer a comprehensive benefits package, including excellent health benefits, a 6% 401(k) match, generous paid vacation and sick time, 12 paid holidays, and more.Role OverviewAs a Data Engineer, you will play a pivotal role in transforming raw data into actionable insights, driving improvements in engineering and manufacturing processes, enhancing product quality, and optimizing operational efficiency. Collaborate with dynamic cross-functional teams to extract, analyze, and visualize data, influencing strategic decisions through your valuable insights.Key ResponsibilitiesData Collection and Integration:Gather, clean, and integrate data from diverse sources, including production databases, sensor data, and external datasets.Data AnalysisConduct exploratory data analysis to identify patterns, trends, and anomalies.Perform statistical analysis and hypothesis testing to derive meaningful insights.Data VisualizationCreate informative and visually appealing dashboards and reports using tools like Tableau, Power BI, or Python libraries.Predictive ModelingDevelop predictive models to forecast manufacturing performance, quality, and operational outcomes.Root Cause AnalysisInvestigate production issues and quality concerns by analyzing data to identify root causes and recommend corrective actions.Performance MonitoringEstablish and maintain key performance indicators (KPIs) to track manufacturing and engineering metrics.Generate regular reports to communicate performance trends to stakeholders.Cross-functional CollaborationCollaborate with engineering, manufacturing, and quality assurance teams to understand their data needs and provide analytical support.Continuous ImprovementSuggest process improvements and optimizations based on data analysis.Data Security And ComplianceEnsure data security and compliance with relevant regulations, such as GDPR or industry-specific standards.Infrastructure And DevelopmentBuild and maintain the infrastructure for collecting, storing, and processing data.Design, develop, and manage data pipelines, ETL processes, and data warehouses.Required ExperienceProven experience as a Sr. Data Analyst and/or Data Engineer in an engineering or manufacturing environment.Proficiency in data analysis tools and programming languages, such as Python, R, SQL, and Excel.Strong data visualization skills with tools like Tableau or Power BI.Excellent knowledge of statistical analysis and machine learning techniques.Ability to communicate complex findings and insights effectively to both technical and non-technical stakeholders.Strong problem-solving skills and attention to detail.Familiarity with manufacturing processes and quality control is a plus.Experience with enterprise ERPs (SAP S4HANA, Oracle EBS), CRMs (Salesforce, Hubspot), and IoT.Proficient in working with cloud computing platforms including AWS, GCP, and Azure.Expertise in configuring and optimizing cloud-based data solutions for scalability, reliability, and performance.Bachelor's Degree in Data Science, Statistics, Engineering, or Computer Science Required.Apply Now and be part of a team shaping the future of data-driven innovation in engineering and manufacturing!Employment Type: Full-Time"
Junior Data Backend Engineer (Clickstream Analytics) (Remote - Ireland),Yelp,United States (Remote),https://www.linkedin.com/jobs/view/3773569103/?eBP=JOB_SEARCH_ORGANIC&refId=t9HE8VvUb%2BJaHM%2Brfs1tnA%3D%3D&trackingId=N9Q3dv75et83zmlOKNYS2A%3D%3D&trk=flagship3_search_srp_jobs,3773569103,"About the job
            
 
Interested in exploring data and finding innovative ways to collect it, curate it, and make it easily accessible for others to use? How about doing that at an enormous scale? Yelp’s datasets contain billions of interactions between users and local businesses around the globe. If working with our vast amount of data sounds exciting, come and join us!The Clickstream Analytics team is responsible for creating, managing, governing, and monitoring some key user journey metrics to support our product teams and also support offline analysis that aids in making long term company decisions. We also build tools that help us to better understand our data quality, and we strive to uncover data issues before they impact our consumers.As a Data Backend Engineer on this team, you will be responsible for building elegant and scalable data products that serve critical, up-to-date, structured information to support different types of analytics within Yelp. As a core contributor to our growing data modeling and data warehousing engineering efforts, you will help design and own mission-critical data flow pipelines and datastores to enable decisions including effective A/B testing and company investments.Yelp engineering culture is driven by our values: we’re a cooperative team that values individual authenticity and encourages creative solutions to problems. All new engineers deploy working code their first week, and we strive to broaden individual impact with support from managers, mentors, and teams. At the end of the day, we’re all about helping our users, growing as engineers, and having fun in a collaborative environment. This opportunity requires you to be located in the Republic of Ireland. We’d love to have you apply, even if you don’t feel you meet every single requirement in this posting. At Yelp, we’re looking for great people, not just those who simply check off all the boxes.  Build systems that can effectively store and crunch terabytes of data.Design and develop data models for efficient data storage, retrieval, and reporting.Create and maintain conceptual, logical, and physical data models using industry-standard modeling tools.Collaborate with cross-functional teams, including engineers, data analysts, business analysts, and data scientists, to understand data requirements and translate them into effective data models.Participate in data integration efforts, including ETL processes and data migration.Stay up-to-date with industry best practices, emerging technologies, and trends related to data warehousing.Support on-call rotations as needed to operate the team.
  Understanding of high performing and scalable data systems.Experience in building and orchestrating ETL pipelines.Experience with Data Lake or Data Warehouse landscape.A hunger for tracking down root causes and fixing them in systematic ways.Ability to communicate effectively to technical and non-technical cohorts alike.Exposure to some of the following technologies: Python, AWS Redshift, AWS Athena / Apache Presto, Big Data technologies (e.g S3, Hadoop, Hive, Spark, Flink, Kafka etc), DBT."
"Data Engineer Seattle, WA (remote)","Conch Technologies, Inc",United States (Remote),https://www.linkedin.com/jobs/view/3765052211/?eBP=JOB_SEARCH_ORGANIC&refId=t9HE8VvUb%2BJaHM%2Brfs1tnA%3D%3D&trackingId=E%2BqQ02qFR%2BkcntJAHA5E0Q%3D%3D&trk=flagship3_search_srp_jobs,3765052211,"About the job
            
 
Hi,Greetings from Conch Technologies IncData Engineering Lead – With Databricks and Unity CatalogLocation – Seattle, WA (remote)Duration – 12 monthsNeed: Design and implement data architecture and strategy, leveraging technologies such as Databricks, Unity Catalog, Privacera, and Collibra.As a Data Engineering Lead, you will play a pivotal role in defining and executing technical deliverables while assessing complexities and levels of effort. You'll engage with both vendor and internal teams to resolve technical challenges and ensure seamless collaboration. Your leadership will extend to planning and prioritization with the SCRUM master, facilitating effective coordination between onsite and offshore teams, and driving feature prioritization through collaboration with product managers.Key Responsibilities  Lead the definition and breakdown of technical deliverables, assessing complexities and levels of effort. Collaborate with vendor and internal teams to address technical issues. Drive planning and prioritization in conjunction with the SCRUM master. Coordinate with onsite and offshore teams for timely project delivery. Collaborate with product managers to prioritize features, communicate with stakeholders, and clarify requirements. Collect and manage user-reported issues, ensuring prompt resolution and communication. Define comprehensive test plans, oversee their execution, and document results.
--With Regards,Nagesh GMobile: 408-381-5645Desk: 901-313-3066Email: nagesh@conchtech.com Web: www.conchtech.com"
Data engineer with Python,FinTech LLC,United States (Remote),https://www.linkedin.com/jobs/view/3726513634/?eBP=JOB_SEARCH_ORGANIC&refId=t9HE8VvUb%2BJaHM%2Brfs1tnA%3D%3D&trackingId=Iy0PcqGmu2AYaOSEM9ps2w%3D%3D&trk=flagship3_search_srp_jobs,3726513634,"About the job
            
 
About Client:The client provides information technology (IT) services, including business outsourcing, infrastructure technology, and application services. The application service offered by the company includes application development, maintenance, and support. The markets served by the company are financial services and insurance, healthcare, manufacturing, government, transportation, communications, and consumer and retail industries.Rate Range: $65-$70/hr On C2C without benefitsSalary Range: $125K - $130K with benefits Job Description: Full stack data engineer, working with any tech stack and data.Python Must.Django, bash, Pandas.
Responsibilities:  Analysing and translating business needs into long-term solution data models.Evaluating existing data systems.Experience with SQL Server is requiredExperience with MongoDB, Teradata, coding capabilities is highly preferred Working with the development team to create conceptual data models and data flows.Developing best practices for data coding to ensure consistency within the system.Reviewing modifications of existing systems for cross-compatibility.
Required Skill SetS:  PythonBashDjangoMongoDBTeradata
 About ApTask:Join ApTask, a global leader in workforce solutions and talent acquisition services, as we shape the future of work. We offer a comprehensive suite of offerings, including staffing and recruitment services, managed services, IT consulting, and project management, providing unparalleled opportunities for professional growth and development. As a member of our dynamic team, you'll have the chance to connect businesses with top-tier professionals, optimize workforce performance, and drive success for our clients across diverse industries. If you are passionate about excellence, collaboration, and innovation, and aspire to make a meaningful impact in the world of work, come join us at ApTask and be a part of our mission to empower organizations to thrive.Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview.Candidate Data Collection Disclaimer:At ApTask, we prioritize safeguarding your privacy. As part of our recruitment process, certain Personally Identifiable Information (PII) may be requested by our clients for verification and application purposes. Rest assured, we strictly adhere to confidentiality standards and comply with all relevant data protection laws. Please note that we only collect the necessary information as specified by each client and do not request sensitive details during the initial stages of recruitment.If you have any concerns or queries about your personal information, please feel free to contact ourrecruitment team at businessexcellence@aptask.com ."
Data Engineer,Garner Health,"Dallas, TX (Remote)",https://www.linkedin.com/jobs/view/3779646857/?eBP=JOB_SEARCH_ORGANIC&refId=t9HE8VvUb%2BJaHM%2Brfs1tnA%3D%3D&trackingId=Os6RtMx0N1ZyDHP%2BlCe4Sg%3D%3D&trk=flagship3_search_srp_jobs,3779646857,"About the job
            
 
Garner's mission is to transform the healthcare economy, delivering high quality and affordable care for all. By helping employers restructure their healthcare benefit to provide clear incentives and data-driven insights, we direct employees to higher quality and lower cost healthcare providers. The result is that patients get better health outcomes while doctors are rewarded for practicing well, not performing more procedures. We are backed by top-tier venture capital firms, are growing rapidly and looking to expand our team.We are looking for a Data Engineer to support our technical teams by ensuring ease of access to data within our organization. The ideal candidate for this role will have strong technical skills, including Python, SQL, and AWS as well as a desire to be a hands-on contributor to building out a data platform from the ground up.Main Responsibilities: Build the data pipelines that power our businessCollaborate across disciplines to high-quality datasetsProtect our users' privacy and security through best practicesSupport data pipelines in production
Our Tools:Python, AWS, Snowflake, dbt, Terraform, PostgresThe ideal candidate has: 2+ years of experience building data pipelines in a fast-paced environmentStrong Python knowledgeExperience with Big Data technologies such as Snowflake, RedShift, BigQuery, or DataBricksAbility to think in principles and frameworks to understand and decompose abstract problemsAn aptitude to learn new technologies and tools quickly
Why You Should Join Our Team: You are mission-driven and want to work at a company that can change the healthcare systemYou want to be on a small, fast-paced team that nimbly moves to meet new challengesYou love ideating on new features and working with data to find new insightsYou're excited about researching and working with the latest tools and technologies
The target salary range for this position is $100,000 - $145,000. Individual compensation for this role will depend on a variety of factors including qualifications, skills and applicable laws. In addition to base compensation this role is eligible to participate in our equity incentive and competitive benefits plans.Garner Health is proud to be an Equal Employment Opportunity employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views or activity, or other applicable legally protected characteristics.Garner Health is committed to providing accommodations for qualified individuals with disabilities in our recruiting process. If you need assistance or an accommodation due to a disability, you may contact us at talent@getgarner.com."
Senior AI/ML Engineer,Kraken Digital Asset Exchange,NAMER (Remote),https://www.linkedin.com/jobs/view/3756652785/?eBP=CwEAAAGMRJcviG1DQ3YnzjTfZHj1eawwPsP3_E79jXX7sTJJZl5Zx101faZPa49_R_qwRUlmFK-rT9NWagCvaVOPiag0_NE8bi7FCVEuTf4QvcXz_25RFH_E4sb-3QCH4l3Lj0Nv5ePUTVLucIFN_50e9-EOl4WZbqKnRHnOp1oV57YhmaCGXuatMPKYi-99jD7VJposUHFJ_3AGk2_d9RwWRGv4saLDusgpf3ilAiSlB5SgPcUQo8dnyY1e5odOneOrOYNWDSkSmdK54DszsrDOLcAYYyKNEX3idKEXVuO66JyzG90rlp6C-Wzgt5QH0WNg4JIwiZmr3CDjBtwe4GT3ONe2OeuQxE1E7Q2axtoCR7hiTNjeHccO6czXxZCVQ9rBELD9glGKY9E&refId=t9HE8VvUb%2BJaHM%2Brfs1tnA%3D%3D&trackingId=rf81eWm%2ByH8o1VOPLPpPmw%3D%3D&trk=flagship3_search_srp_jobs,3756652785,"About the job
            
 
Building the Future of Crypto Our Krakenites are a world-class team with crypto conviction, united by our desire to discover and unlock the potential of crypto and blockchain technology.What makes us different?Kraken is a mission-focused company rooted in crypto values. As a Krakenite, you’ll join us on our mission to accelerate the global adoption of crypto, so that everyone can achieve financial freedom and inclusion. For over a decade, Kraken’s focus on our mission and crypto ethos has attracted many of the most talented crypto experts in the world.Before you apply, please read the Kraken Culture page to learn more about our internal culture, values, and mission.As a fully remote company, we have Krakenites in 60+ countries who speak over 50 languages. Krakenites are industry pioneers who develop premium crypto products for experienced traders, institutions, and newcomers to the space. Kraken is committed to industry-leading security, crypto education, and world-class client support through our products like Kraken Pro, Kraken NFT, and Kraken Futures.Become a Krakenite and build the future of crypto!Proof of workThe teamKraken is looking for an experienced Machine Learning engineer to join our AI/ML Team in the centralized Data organization. In this role you will be applying cutting edge AI/ML technology to solving the most complex and exciting problems in the quickly growing and evolving crypto industry. We are looking for an extremely strong communicator and team-player, who is able to break down large complex problems into smaller more manageable problems-to-solve. You will take initiative to identify business problems, explore different ways to resolve issues, and systematically find the most efficient and effective way to deliver business impact.The Opportunity Design, implement and deploy Machine Learning solutions to solve complex problems and deliver real business value ie. revenue, engagement and customer satisfaction.Collaborate with data scientists, software engineers and business partners to identify AI/ML opportunities for improving operation scalability and efficiency.Develop production-grade ML models to power personalized customer experience, content recommendation, fraud detection/prevention and more.Monitor and improve model performance via data enhancement, feature engineering, experimentation and online/offline evaluation.Stay up-to-date with the latest in machine learning and artificial intelligence, and influence AI/ML for the Crypto industry.Mentor junior engineers, fostering a culture of continuous learning and improvement.
Skills You Should HODL Expertise in building, deploying, measuring, and maintaining machine learning models to address real-world problems.Thorough understanding of software development lifecycle, DevOps (build, continuous integration, deployment tools) and best practices.Strong programming skills in Python, Scala, Go, Rust or other languages.Excellent written and verbal communication skills and interpersonal skills.Experience with MLOps platforms, such as Kubeflow or MLFlow.Experience with ML frameworks, such as scikit-learn, Tensorflow, PyTorch.Experience with Big Data tools – Spark, S3, Athena/Trino.Experience with GenAI tools, such as Langchain, LlamaIndex, and open source Vector DBs.Advanced degree in Computer Science, Machine Learning or related field.A minimum of 5 years experience in AI/ML engineering, with a track record of handling increasingly complex projects.
Location Tagging: #US #EUKraken is powered by people from around the world and we celebrate all Krakenites for their diverse talents, backgrounds, contributions and unique perspectives. We hire strictly based on merit, meaning we seek out the candidates with the right abilities, knowledge, and skills considered the most suitable for the job. We encourage you to apply for roles where you don't fully meet the listed requirements, especially if you're passionate or knowledgable about crypto!As an equal opportunity employer, we don’t tolerate discrimination or harassment of any kind. Whether that’s based on race, ethnicity, age, gender identity, citizenship, religion, sexual orientation, disability, pregnancy, veteran status or any other protected characteristic as outlined by federal, state or local laws.Stay in the knowFollow us on TwitterLearn on the Kraken BlogConnect on LinkedIn"
Entry Level Data Scientist/Engineer - Remote,SynergisticIT,"Tampa, FL (Remote)",https://www.linkedin.com/jobs/view/3767597086/?eBP=JOB_SEARCH_ORGANIC&refId=t9HE8VvUb%2BJaHM%2Brfs1tnA%3D%3D&trackingId=4ZrrZ%2FC2i7uYreyLjBnYzQ%3D%3D&trk=flagship3_search_srp_jobs,3767597086,"About the job
            
 
The Job Market is Challenging due to almost 300,000 Tech Layoffs since October 2022 due to which thousands of laid off Techies are competing with existing Jobseekers. Entry level Job seekers struggle to get responses to their applications forget about getting client interviews. As the Saying goes “when the Going gets tough the Tough get going” Candidates who want to make a tech career they need to differentiate themselves by ensuring they have exceptional skills and technologies to be noticed by clients.Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don’t focus on getting you a Job we make careers.All Positions are open for all visas and US citizensWe are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$’s and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs. Clients now post covid can also hire remote workers which increases even more competition for jobseekers.We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000’s of candidates get jobs at technology clients like apple, google, Paypal, western union, bank of america, visa, walmart labs etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in IT IndustryWe assist in filing for STEM extension and also for H1b and Green card filing to Candidates We also offer optionally Skill and technology enhancement programs for candidates who are either missing skills or are lacking Industry/Client experience with Projects and skills. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. If they are qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients. Shortlisting and selection is totally based on clients discretion not ours.Please check the below links to see success outcomes of our candidateshttps://www.synergisticit.com/candidate-outcomes/We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023Oracle CloudWorld Event (OCW) Las Vegas 2023/ 2022 | SynergisticIT - YouTubehttps://youtu.be/-HkNN1ag6Zkhttps://youtu.be/Rfn8Y0gnfL8https://www.youtube.com/watch?v=OAFOhcGy9Z8https://www.youtube.com/watch?v=EmO7NrWHkLMhttps://www.youtube.com/watch?v=NVBU9RYZ6UIhttps://www.youtube.com/watch?v=Yy74yvjatVgFor preparing for interviews please visit https://www.synergisticit.com/interview-questions/We are looking for the right matching candidates for our clientsPlease apply via the job postingREQUIRED SKILLS For Java /Full Stack/Software Programmer Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleProject work on the skillsKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices, Docker, Jenkins and REST API's experienceExcellent written and verbal communication skills
For data Science/Machine learning PositionsRequired Skills Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITProject work on the technologies neededHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, SAS, Python, Computer Vision, data visualization toolsExcellent written and verbal communication skills
Preferred skills: NLP, Text mining, Tableau, PowerBI, TensorflowIf you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates"
Data Engineer (Remote),SPAR Information Systems LLC,United States (Remote),https://www.linkedin.com/jobs/view/3647808248/?eBP=JOB_SEARCH_ORGANIC&refId=t9HE8VvUb%2BJaHM%2Brfs1tnA%3D%3D&trackingId=Kjz4gzNMLqKSCgMriKnUXA%3D%3D&trk=flagship3_search_srp_jobs,3647808248,"About the job
            
 
Role: Data Engineer Location: 100% RemoteDuration: Full TimeRequirements4+ years' experience developing data centric applicationsKnowledge on Scala, DataBricks4+ years' experience creating data transformation and validation logicStrong understanding of streaming and batch data processing best practices.Advanced knowledge of data formats (JSON, XML, Parquet, etc.) and data modeling practices.Data modelling experience shaping and transforming data into third normal form and dimensional models.Advanced understanding of best practices for structuring and organizing Data Lake file systems for large volumes of data.SkillsNumber of years' experienceRating out of 5Developing data centric appsScala and DatabricksCreating data transformation and validation logicData formats (JSON, XML, Parquet)Data ModelingData Lake file systemsThanks & Regards,Arvind Kumar BindPH Number:- 469-750-0607Email : Arvind.B@sparinfosys.com"
Data Science Engineer - Freelance,Fantasy,"San Francisco, CA (Remote)",https://www.linkedin.com/jobs/view/3755004059/?eBP=JOB_SEARCH_ORGANIC&refId=t9HE8VvUb%2BJaHM%2Brfs1tnA%3D%3D&trackingId=BnHhsxJlb3kjxFsJg9r%2BsA%3D%3D&trk=flagship3_search_srp_jobs,3755004059,"About the job
            
 
This role may sit anywhere as long as the individual is willing to work North America hours.Realize the unimaginedFantasy is a digital product and innovation company. We realize the unimagined for the world’s most ambitious organizations. Founded in 1999, our global reputation is based on our teams’ unique ability to think beyond the ordinary and launch ground-breaking products and services. We believe that our phenomenal team is the core reason for our success, our growth, and our thriving culture.The RoleAs a Data Science Engineer, your primary responsibility will be to build out exciting new AI-driven tools that our clients will love and use every day. Collaborating with the best design and research teams in the world, and world class client teams, your work will not only drive the future of Fantasy, but influence the future of the industry. Your work will frequently be on the bleeding edge of AI, incorporating the latest innovations in LLMs, machine learning, and data science.Responsibilities Prototype and build cutting edge, proof-of-concept AI productsCollaborate with product managers, designers, researchers, and executives to create successful and compelling solutionsWork with a large and globally distributed teamSolve challenging cutting-edge problems, using state-of-the-art techniques, services, and best practicesEvaluate and integrate new machine learning frameworks and tools, ensuring that Fantasy is always at the forefront of ML, LLMs, and Generative AIActively contribute to continuous improvement of AI at Fantasy, through educational presentations and thought partnership with internal teams
Experience / Key Personal Qualities Bachelor’s or Master’s degree in Data Science, Computer Science, Statistics, or a related fieldFluent in Python, C++, and Java3+ years of experience designing and building machine learning platforms and servicesDemonstrable expertise in LLMs, including fine-tuning and pre-trainingExperience with LLM specific packages and services (e.g. LangChain, vector databases)Experience with AI frameworks and libraries (e.g., TensorFlow, PyTorch, scikit-learn)Strong communication skills to convey complex concepts to non-technical stakeholdersFront end experience a plusData harvesting / scraping experience a plusExperience in design-related fields or understanding of design processes is a plusAbility to work collaboratively in a cross-functional team environment
Fantasy EOEFantasy is an Equal Opportunity Employer. Since 1999, diversity has been vital to our success and ability to create products and services used and loved by millions of people all over the world. We are committed to continually fostering a diverse, equitable, and inclusive workplace."
Data Engineer II - Remote,Net Health,"Alpharetta, GA (Remote)",https://www.linkedin.com/jobs/view/3779194501/?eBP=JOB_SEARCH_ORGANIC&refId=t9HE8VvUb%2BJaHM%2Brfs1tnA%3D%3D&trackingId=nvEXWYCx9j%2BUZbr3B8cIpA%3D%3D&trk=flagship3_search_srp_jobs,3779194501,"About the job
            
 
Job DetailsDescriptionAbout Net HealthBelong. Thrive. Make a Difference.Are you looking for a meaningful and satisfying career where you have endless opportunities to grow and be financially rewarded? Net Health may be the perfect place for you.A high-growth and profitable company, we help caregivers harness data for human health. We also honor and respect the needs of our Net Health family and staff, which is why we offer a work-from-anywhere environment and unlimited PTO. Our welcoming and collaborative culture paired with progressive benefits makes Net Health the ultimate career home!As a leading-edge SaaS company in healthcare, we deliver solutions that help patients get better, faster, and live more fulfilling lives. Our software and predictive analytics cover the continuum of care, from hospital-to-home, across various medical specialties. Come join us and start the next chapter of your exciting career while helping others to live better lives.World-Class Benefits That Reflect Our World-Class Culture.Click Here to Learn More!:#WorkFromAnywhere #UnlimitedPTO #ComprehensiveBenefitsPackage #EmployeeResourceGroups #CasualDressCode #PrioritizedEmployeeWellness #DiversityAndInclusion #AVoice #NewHireSupport #CareerDevelopment #EducationalAssistance #EmployeeReferralBonus #ProgressiveParentalLeaveJob OverviewDesigns, models, documents, and guides the logical and conceptual relationship of data and database changes for complex applications. Analyzes needs and requirements of existing and proposed systems, and develops technical, structural, and organizational specifications. May also develop, implement, and maintain data systems to meet designs, models and specifications. This person will analyze client production issues and create SQL statements to fix the issue.Responsibilities And Duties Will work with development wen new features or changes happen to the schemaCreate and maintain internal procedures and documentation around reusable SQL scripts or new additions to the data schema due to newly deployed features and functionalityAssist support with triaging complex client issuesProvide ad-hoc reportsAnalyze data to spot anomalies, trend and correlate similar data setsAnalyze large, complex datasets to drive actionable insights and recommendationsEvaluate failures, defects, systemic problems and hardwareConfer with clients to identify problems, replicate the problems, and troubleshoot for root causeParticipate in Agile/Scrum process to refine, prioritize, and build solutions to meet customer needsCreate and maintain internal procedures and documentation around reusable SQL scripts or new additions to the data schema due to newly deployed features and functionalityPerform other related duties as required and assigned
Qualifications Bachelor’s degree or equivalent experience2-4 years of relevant experience
Required Software Experience MS Excel or Google Spreadsheets2-4 years SQL (both DML and DDL)Exposure to 1-2 relational Database Systems (Postgres, Oracle, SQl Server, Snowflake, RedShift, BigQuery etc.)2-4 years Data Visualization, Analysis, or reporting1-2 years with at least 1 scripting language (Javascript, Python, PHP, Bash, Powershell)0-2 years building and maintaining an enterprise Data Warehouse
Note: This job description is not intended to be all-inclusive. Employee may perform other related duties as requested to meet the ongoing needs of the organization.Colorado Pay Law: If you are a Colorado resident and this role is available in Colorado or remote, you may be eligible to receive additional information about the compensation and benefits for this role, which we will provide upon request. Please send an email to Recruiting@NetHealth.comIf you are a CA, CT, CO, IL, MD, NV, RI, WA or NY City resident and this role is available in one of those locales or remote, you may be eligible to receive additional information about the compensation and benefits for this role, which we will provide upon request. Please send an email to Recruiting@NetHealth.com"
Data Engineer,uConnect,"Cambridge, MA (Remote)",https://www.linkedin.com/jobs/view/3726901108/?eBP=JOB_SEARCH_ORGANIC&refId=t9HE8VvUb%2BJaHM%2Brfs1tnA%3D%3D&trackingId=34NYHf%2B%2ByGp0NvLkYQXNzg%3D%3D&trk=flagship3_search_srp_jobs,3726901108,"About the job
            
 
uConnect is on a mission to help more people realize their potential by improving access to career resources and services - early in their lives and throughout their careers. Initially focused on the post-secondary higher education market, uConnect's All-In-One Virtual Career Center is used by schools like UCLA, MIT, and Baton Rouge Community College to radically increase student and alumni engagement with career services, and integrate career planning into the student experience, before, during and after college.We are committed to lowering barriers to opportunity for students and recent graduates from all backgrounds. Our customers are some of the most dedicated and capable career services professionals in the world and our software helps them be even more successful in their mission of helping students.We have created a working environment that is fun and collaborative and puts people first. We have a physical office in Cambridge, MA but operate as a remote-first organization, encouraging mobility for all employees, and to work from their chosen environment. uConnect is backed by leading education technology investors including Growth Street Partners, Strada Education and LearnLaunch.Summary:uConnect is dedicated to unleashing the full potential of data to drive innovation and impact in our industry. We are currently seeking a skilled Data Engineer to join our dynamic team and lead our data strategy to new heights. As a Data Engineer at uConnect, you'll be at the forefront, demonstrating the ROI of our products to both existing and prospective customers. You'll spearhead initiatives related to analytics tooling, guide scoping conversations, and contribute significantly to data programming. Your role is pivotal in ensuring seamless data flow between diverse teams and tools while upholding regulatory and ethical compliance in our data practices.Why We Need You:Data is at the core of our business strategy, and we require a dedicated owner. If you resonate with any of the following profiles, we want to hear from you: Experienced data engineer or analyst with programming skillsA startup enthusiast or someone seeking a cross-functional and self-directed roleSenior software or DevOps engineer with a passion for data engineeringAdvanced data analyst with a knack for programming
Primary Responsibilities:In this role, you will have a direct impact on our data-driven journey by: Discussing business objectives with stakeholdersCollaborating with product managers to collect and prioritize data collection needsBuilding data pipelines and an event-driven analytics modelCreating data visualizations and dashboardsUnderstanding and adhering to trust and safety constraintsOwning and iterating on our data systems in collaboration with the engineering teamResearching and evaluating potential vendorsValidating project outcomes across teamsEmpowering teams across uConnect to meet their data needsManaging and optimizing student product engagement dataDeveloping a strategic data roadmap aligning long-term plans with day-to-day decisions
Secondary Responsibilities: Conducting code reviews for other engineersResearching tools, techniques, and regulatory issuesWriting internal documentation about data availability, data modeling, and graph interpretationConsulting API documentation from vendors to evaluate data flow possibilitiesTesting new data workflows between first- and third-party tools and demonstrating proof-of-concept workEnsuring data security and compliance by enforcing access controls, encryption, monitoring, and regulatory adherence
A Typical Day:Your daily routine will be diverse and engaging, involving: Active participation in daily engineering standup meetingsCollaborative discussions with stakeholders and peers to prioritize data needsHands-on programming for data pipelines and code reviewsIn-depth research on data tools, techniques, and regulatory requirementsDocumentation of critical insights on data availability, modeling, and visualizationConsultation of API documentation to evaluate data flow possibilitiesRigorous testing of new data workflows and showcasing proof-of-concept resultsCrafting compelling data visualizations within dashboards
Required Skills, Background & Experiences:Required Skills: Proven experience in data engineering, including data pipeline development, ETL processes, and data warehousingStrong self-management and team leadership abilitiesProficiency in Python, Javascript, and/or PHP being idealMid-to-advanced level SQL skills in any flavorSound statistical analysis skills for meaningful data interpretationA knack for creating precise data visualizationsStrong communication skillsWorking remotely with a cross-functional team and collaborating with other engineers
Preferred Skills, Background & Experiences: Familiarity with BigQuery or similar data toolsExposure to Google AnalyticsStrong aptitude for self-directed learning and growthExperience in auditing application-level security with product engineersProficiency in code validation using test automationHands-on experience in DevOps/CI pipeline managementFamiliarity with event-driven frameworks like WordPressKnowledge of data collection policies and regulatory constraints
Why You Should Join Us:At uConnect, you will have the opportunity to: Contribute to our mission and make a meaningful impactLead and own data systems from discussions to deliveryGrow personally as an individual contributorShape the future of data collection and utilization in our organization
How to Apply:If you're ready to be part of a team that's transforming the way we use data and meet the requirements outlined above, we invite you to apply now. Help us shape the future of data at uConnect. Together, we'll achieve remarkable results!EEO StatementEqual Opportunity EmployeruConnect is proud to be an equal opportunity employer and is committed to maintaining a diverse and inclusive work environment. All qualified applicants will receive considerations for employment without regard to race, color, religion, sex, age, disability, marital status, familial status, sexual orientation, pregnancy, genetic information, gender identity, gender expression, national origin, ancestry, citizenship status, veteran status, and any other legally protected status under federal, state, or local anti-discrimination laws.View The EEO is the Law poster and its supplement.uConnect participates in E-Verify. View the E-Verify posters here.Disability AccommodationFor individuals with disabilities that need additional assistance at any point in the application and interview process, please contact our Manager of People Operations, Karen Lewis at karen.lewis@gouconnect.com.Annual salary range: $120K - $140K. Commensurate with experience."
Data Engineer -remote,"RIT Solutions, Inc.","Dallas, TX (Remote)",https://www.linkedin.com/jobs/view/3768004842/?eBP=JOB_SEARCH_ORGANIC&refId=t9HE8VvUb%2BJaHM%2Brfs1tnA%3D%3D&trackingId=OkPGBxNhCCzXt2M41efKgA%3D%3D&trk=flagship3_search_srp_jobs,3768004842,"About the job
            
 
100% remote*CANDIDATES CANNOT LIVE IN - VT, RI, NY, NJ, NH, MI, ME, MA, DE, CO, CT, CA, and AZ*LinkedIn profile requiredPosition SummaryThe Senior Data Engineer for the Azure infrastructure will be responsible for the day to day operations of a large data warehouse, and will work closely with the business, product team, and the technical staff to ensure alignment to goals and objectives. Utilizing experience with Big Data, this position will drive consensus on designs of stable, reliable and effective dynamic ETL pipelines leveraging Azure Synapse Analytics Pipelines.Essential Job Functions Drive consensus on designs of stable, reliable and effective dynamic ETL pipelines leveraging Azure Synapse Analytics Pipelines.Perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.Design, implement, and document data load processes from disparate data sources into Azure Synapse Pipelines.Work with Continuous Integration/Delivery using Azure DevOps and Github.Provide data management, monitoring, troubleshooting and support to client successCreate various triggers to automate the pipeline in Azure Synapse Analytics Pipelines.Tune SQL queries in Azure SQL DB, Azure Synapse and solve complex data challenges and deliver insights that help our customers achieve their goals.Self-organize as part of a small-size scrum team and apply data engineering skills.Follows industry best practices and meets company's security and performance and requirements
Knowledge, Skills and Abilities Minimum three (3) years' experience with MS SQL/T-SQLMinimum three (3) years' experience with Azure SQLMinimum three (3) years' experience with Apache Spark (PySpark)Minimum of three (3) years' experience with Azure Data Factory or Azure Synapse building dynamic ETL pipelinesMinimum three (3) years' experience building dynamic Spark notebooks in Azure Synapse Spark or Azure DatabricksMinimum three (3) years' experience with PythonMinimum two (2) years' experience with a public cloud (AWS, Microsoft Azure, Google Cloud)Experience working with parquet, json , delta, avro and csv filesIn-depth understanding of data management (e.g. permissions, recovery, security and monitoring)Experience with Data Warehouse ArchitectureStrong analytic skills related to working with structured, semi-structured and unstructured datasets.Excellent analytical and organization skills requiredAbility to understand user requirementsClient service mindsetExcellent verbal and written communication skillsExcellent problem solving skillsFamiliarity with Agile frameworks a plus
Education and Experience Bachelor's degree in related discipline or combination of equivalent education and experience7-10 years of experience in similar field"
Data Engineer II - Remote,Net Health,"St Augustine, FL (Remote)",https://www.linkedin.com/jobs/view/3779194500/?eBP=JOB_SEARCH_ORGANIC&refId=t9HE8VvUb%2BJaHM%2Brfs1tnA%3D%3D&trackingId=WG%2FSOq9yCKnOu3mM%2F2lleQ%3D%3D&trk=flagship3_search_srp_jobs,3779194500,"About the job
            
 
Job DetailsDescriptionAbout Net HealthBelong. Thrive. Make a Difference.Are you looking for a meaningful and satisfying career where you have endless opportunities to grow and be financially rewarded? Net Health may be the perfect place for you.A high-growth and profitable company, we help caregivers harness data for human health. We also honor and respect the needs of our Net Health family and staff, which is why we offer a work-from-anywhere environment and unlimited PTO. Our welcoming and collaborative culture paired with progressive benefits makes Net Health the ultimate career home!As a leading-edge SaaS company in healthcare, we deliver solutions that help patients get better, faster, and live more fulfilling lives. Our software and predictive analytics cover the continuum of care, from hospital-to-home, across various medical specialties. Come join us and start the next chapter of your exciting career while helping others to live better lives.World-Class Benefits That Reflect Our World-Class Culture.Click Here to Learn More!:#WorkFromAnywhere #UnlimitedPTO #ComprehensiveBenefitsPackage #EmployeeResourceGroups #CasualDressCode #PrioritizedEmployeeWellness #DiversityAndInclusion #AVoice #NewHireSupport #CareerDevelopment #EducationalAssistance #EmployeeReferralBonus #ProgressiveParentalLeaveJob OverviewDesigns, models, documents, and guides the logical and conceptual relationship of data and database changes for complex applications. Analyzes needs and requirements of existing and proposed systems, and develops technical, structural, and organizational specifications. May also develop, implement, and maintain data systems to meet designs, models and specifications. This person will analyze client production issues and create SQL statements to fix the issue.Responsibilities And Duties Will work with development wen new features or changes happen to the schemaCreate and maintain internal procedures and documentation around reusable SQL scripts or new additions to the data schema due to newly deployed features and functionalityAssist support with triaging complex client issuesProvide ad-hoc reportsAnalyze data to spot anomalies, trend and correlate similar data setsAnalyze large, complex datasets to drive actionable insights and recommendationsEvaluate failures, defects, systemic problems and hardwareConfer with clients to identify problems, replicate the problems, and troubleshoot for root causeParticipate in Agile/Scrum process to refine, prioritize, and build solutions to meet customer needsCreate and maintain internal procedures and documentation around reusable SQL scripts or new additions to the data schema due to newly deployed features and functionalityPerform other related duties as required and assigned
Qualifications Bachelor’s degree or equivalent experience2-4 years of relevant experience
Required Software Experience MS Excel or Google Spreadsheets2-4 years SQL (both DML and DDL)Exposure to 1-2 relational Database Systems (Postgres, Oracle, SQl Server, Snowflake, RedShift, BigQuery etc.)2-4 years Data Visualization, Analysis, or reporting1-2 years with at least 1 scripting language (Javascript, Python, PHP, Bash, Powershell)0-2 years building and maintaining an enterprise Data Warehouse
Note: This job description is not intended to be all-inclusive. Employee may perform other related duties as requested to meet the ongoing needs of the organization.Colorado Pay Law: If you are a Colorado resident and this role is available in Colorado or remote, you may be eligible to receive additional information about the compensation and benefits for this role, which we will provide upon request. Please send an email to Recruiting@NetHealth.comIf you are a CA, CT, CO, IL, MD, NV, RI, WA or NY City resident and this role is available in one of those locales or remote, you may be eligible to receive additional information about the compensation and benefits for this role, which we will provide upon request. Please send an email to Recruiting@NetHealth.com"
Data Engineer,Analytica,"Washington, DC (Remote)",https://www.linkedin.com/jobs/view/3664083944/?eBP=JOB_SEARCH_ORGANIC&refId=t9HE8VvUb%2BJaHM%2Brfs1tnA%3D%3D&trackingId=td7rdu4CB8ejZug%2FJ%2B%2FOLw%3D%3D&trk=flagship3_search_srp_jobs,3664083944,"About the job
            
 
Analytica is seeking a remoteData Engineerto support one or more dynamic, long-term federal government enterprise big-data programs. The company works as a trusted advisor to U.S. federal government clients in health, civilian, and national security missions.The ideal candidate will be comfortable as a key member of a multi-disciplinary team working in an Agile environment to producebig data analytics solutions.Analytica has been recognized byInc. Magazineas one of the 250 fastest-growing US small businesses for three consecutive years.We work with U.S. government clients to build data-driven products and cultures that make an impact on our daily lives. Analytica offers competitive compensation with opportunities for bonuses, employer paid health care, unlimited training funds, and a 401k match.Requirements (may include, but not limited to): Collaborate with client stakeholders and technical employees to optimize data collection, storage, and usage to maximize the value of information within the organization.Research, design, build, optimize and maintain efficient and reliable data systems, data pipelines, and models.Align closely with operating user requirements on data science, architecture, governance, infrastructure, and security to apply standards and optimize production environments and practices.Translate business needs into data architecture solutions, designing and implementing in production environments within supported data systems.Implement data orchestration pipelines, data sourcing, cleansing, augmentation, and quality control processes within supported data systems.Deploy applications to production in partnership with business units.Develop, test, and integrate new data features and functionality as defined by the product owners and business teamsWork with a multi-disciplinary team of analysts, data engineers, data scientists, developers, and data consumers in a fast-paced Agile environment
Qualifications: Bachelor’s degree in Computer Science, Engineering, Science, or related field.5+ years of data engineering and data warehousing experience3+ years of experience building cloud-data pipeline solutions for data ingestion, data storage, real-time processing, and analyticsExperience working within Agile development environment, DevOps, and using version control platforms, e.g., GitHub)Have domain knowledge of standard data methodologies (DMBOK, NIST, etc.). Team player and the ability to work effectively within a group as well as self-motivated with minimal supervisionExcellent problem solving, collaboration, and communication skillsAWS verifiable certification is strongly preferred US Citizen with the ability to secure a US Federal Clearance
AboutAnalytica:Analytica is a leading consulting and information technology solutions provider to public sector organizations supporting health, civilian, and national security missions. Founded in 2009 and headquartered in Bethesda, MD, the company is an established8(a) small businessthat hasbeen recognized byInc. Magazineeach of the past three years as one of the 250 fastest-growingcompanies in theU.S. Analytica specializes in providing software and systems engineering, information management, analytics & visualization, agile project management, and management consulting services.The Software Engineering Institute (SEI) appraises the companyatCMMI® Maturity Level 3and is anISO 9001:2008 certifiedprovider.As a federal contractor, Analytica is required to verify that all employees are fully vaccinated against COVID-19. If you receive an offer and are unable to get vaccinated for religious or medical reasons, you may request a reasonable accommodation."
Data Engineer,Care.com,"Austin, TX (Remote)",https://www.linkedin.com/jobs/view/3765031801/?eBP=JOB_SEARCH_ORGANIC&refId=t9HE8VvUb%2BJaHM%2Brfs1tnA%3D%3D&trackingId=wSyaXPVtWIgnMO3Ah7lOjA%3D%3D&trk=flagship3_search_srp_jobs,3765031801,"About the job
            
 
About Care.comCare.com is a consumer tech company with heart. We're on a mission to solve a human challenge we all face: finding great care for the ones we love. We're moms and dads and pet parents. We have parents and grandparents, so we understand that everyone, at some point in their lives, could use a helping hand. Our culture and our products reflect that.Here, entrepreneurs, self-starters, team players, and big thinkers unite behind a common cause. Here, we're applying data analytics, AI, and the latest technologies to solve universal problems and connect people in new ways. If you like having autonomy, if you thrive on collaboration and building new things, and if you're all about using your talent for good, Care.com is the place for you.What Your Days Will be Like:The Data Engineer will be focusing on building out data feeds and tooling from our application platform and enable rapid ingestion into our centralized Data Lake/Data Warehouse. The Data Engineer will work across business areas and application teams at Care.com to rationalize data and design, build and maintain reusable data feeds which and ultimately empower analytics consumption at Care.com.The ideal candidate will have professional experience building data pipelines in a technical environment. S/he will have an understanding of application development, data warehousing, demonstrate strong business judgment, and be able to prioritize in a fast-paced environment.What You'll Be Working On:  Collaborate and partner with application teams to understand data collection/generation and design and partner to build and implement data feeds from our product tech stackDesign, develop, and build code for rapid feeds and ingestion into the Data WarehouseIdentify data sources used for building out data architecture diagrams/modelsEstablish engineering practices and setup frameworks for ""Data as a Service""Collaborate with relevant delivery teams, including infrastructure, operations, site reliability engineering, product development, and others to perform evaluations, POCs, and ultimately implement and operationalize new technology. Solve code level problems quickly and efficiently Participate in demos and code reviews Promote software best approach, standards, and processes Shape development processes to promote a high-quality output while continuing to iterate quickly Incorporate best practices for security, performance, and data privacy into data pipelines
What You'll Need to Succeed: BS or MS in Computer Science or relevant engineering experience5+ years work experience in Data Engineering/data pipelines3+ years SQL experience is a must1+ years Unix/batch scripting preferred1+ years Python experience is a plus1+ years Windows server admin experience is a plusExperience interfacing with business teams and turning requirements and vision into a technical realityMySQL & Vertica Experience a plus/preferredAWS experience is a plusAbility to drive efforts from start to finish as a self-motivatorKnowledge in Data Warehousing is a MUSTProven ability to maintain performance level in a fast-paced agile environment Pragmatic and realistic with solutions
For a list of our Perks + Benefits, click here!Care.com supports diverse families and communities and seeks employees who are just as diverse. As an equal opportunity employer, Care.com recognizes the power of a diverse and inclusive workforce and encourages applications from individuals with varied experiences, perspectives, and backgrounds. Care.com is committed to providing reasonable accommodations for qualified individuals with disabilities. If you need assistance or accommodation, please reach out to talent@care.com.Company Overview:Available in more than 20 countries, Care.com is the world's leading platform for finding and managing high-quality family care. Care.com is designed to meet the evolving needs of today's families and caregivers, offering everything from household tax and payroll services and customized corporate benefits packages covering the care needs of working families, to innovating new ways for caregivers to be paid and obtain professional benefits. Since 2007, families have relied on Care.com's industry-leading products—from child and elder care to pet care and home care. Care.com is an IAC company (NASDAQ: IAC).Salary Range: 110,000 to 135,000. The base salary range above represents the anticipated low and high end of the national salary range for this position. Actual salaries may vary and may be above or below the range based on various factors including but not limited to work location, experience, and performance. The range listed is just one component of Care.com's total compensation package for employees. Other rewards may include annual bonuses and short- and long-term incentives. In addition, Care.com provides a variety of benefits to employees, including health insurance coverage, life, and disability insurance, a generous 401K employer matching program, paid holidays, and paid time off (PTO)."
Senior Data Engineer,Nike,"Beaverton, OR (Remote)",https://www.linkedin.com/jobs/view/3775090168/?eBP=JOB_SEARCH_ORGANIC&refId=t9HE8VvUb%2BJaHM%2Brfs1tnA%3D%3D&trackingId=ZEBIiByV1lxJoGmISAE8tg%3D%3D&trk=flagship3_search_srp_jobs,3775090168,"About the job
            
 
Work options: RemoteTitle: Senior Data EngineerLocation: Remote, Beaverton, ORDuration: 6 Month ContractBecome a Part of the NIKE, Inc. TeamNIKE, Inc. does more than outfit the world's best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At Nike, it’sWhat You Will Work OnWe are looking for an experienced Senior Data Engineer to join our data team. You will be responsible for maintaining and improving our production Airflow pipelines, as well as developing new features using Python. This role requires strong Python programming skills, expertise with Airflow, and experience with SageMaker pipelines. Maintain and improve existing Airflow DAGs that move data through our analytics pipelineWork closely with data scientists and analysts to understand requirements for new pipelines and data transformation logicDevelop reusable Python modules and libraries for data transformation and integration Migrate existing Airflow pipelines to SageMaker pipelines utilizing our proprietary ETL libraryImplement new features for our Deployment Optimization platform using PythonMonitor pipeline health, troubleshoot issues, and resolve bugs in a timely mannerFollow best practices for version control, testing, and code reviews
What You Bring 5+ years of experience building and maintaining Airflow pipelinesExpert knowledge of Python, including modules like Pandas, NumPy, and SQLAlchemyExperience developing and deploying SageMaker pipelinesStrong understanding of data structures, algorithms, distributed computing, and data modeling Experience with Git, CI/CD, and automated testing frameworksExcellent communication and collaboration skills"
Remote Entry Level Data Analyst/Engineer,SynergisticIT,"White Plains, NY (Remote)",https://www.linkedin.com/jobs/view/3774171423/?eBP=JOB_SEARCH_ORGANIC&refId=f6As7U02xhgNmK54aPROHg%3D%3D&trackingId=NY7Vx63VHcR6A8j%2B2TkZ0w%3D%3D&trk=flagship3_search_srp_jobs,3774171423,"About the job
            
 
At SynergisticIT, we're all about making connections. Whatever IT goals you have, our software programmers can help achieve those. Our Software development teams can take up turnkey projects and execute them in an effective and efficient manner. If you are looking to source talent our recruiters will find the ideal IT talent for your company. What's the secret to our success? Well, it all starts with taking quality time to listen to each client's specific needs. After we have a thorough grasp of your IT goals, we can better customize our Developments as per your specific needs. We can also tailor make recruiting programs to exceed your expectations. Since our founding in 2010, SynergisticIT's strategies have earned the company an enviable position in the software development, IT staffing and IT skill enhancement fields. SynergisticIT continues to work with hundreds of satisfied American clients with our software programmers working on our projects and after gaining hands on experience on cutting edge technologies moving to contribute their skills to great clients like Apple, Google, Client, Ebay, Paypal, Kroger, the Walt Disney Company and hundreds more. If you are tired of working with inefficient programmers who take a lot of time to ramp up we want you to try us. Our software programmers can hit the ground running and get you the maximum return on your investment. You have already tried the rest its time you tried the best. SynergisticIT - Home of the Best Data Scientists and Software Programmers in the Bay Area. Why Us ? SynergisticIT has a proven track record of successfully skill enhancement and staffing IT employees for some of the world's most iconic brands. Our team takes the time to fully understand every client's needs so we could best meet your IT staffing requirements. The knowledgeable staff at SynergisticIT is always more than happy to work with clients to ensure they reach their software development goals. Besides staffing, SynergisticIT is also committed to helping young IT professionals advance their career with a robust upskill program . Everyone who goes through SynergisticIT's program learns all the skills necessary to succeed in many IT fields ranging from Java to Machine Learning. Additionally, everyone trained at SynergisticIT has been through extensive mock and technical interview screenings to bolster their career prospects. Last, but certainly not least, SynergisticIT takes great care to respect the privacy considerations for every client. All companies who work with SynergisticIT can rest assured their confidential data is protected using the most up-to-date encryption technologies. SynergisticIT also complies with all the latest NDA agreements. REQUIRED SKILLS For Java /Software Programmers   Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT  Highly motivated, self-learner, and technically inquisitive  Experience in programming language Java and understanding of the software development life cycle  Project work on the skills  Knowledge of Core Java , javascript , C++ or software programming  Spring boot, Microservices, Docker, Jenkins and REST API's experience  Excellent written and verbal communication skills 
 For data Science/Machine learning Required Skills  Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT  Project work on the technologies needed  Highly motivated, self-learner, and technically inquisitive  Experience in programming language Java and understanding of the software development life cycle  Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools  Excellent written and verbal communication skills 
 Preferred skills: NLP, Text mining, Tableau, PowerBI, Time series analysis  We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2022 and at Gartner Data Analytics Summit (Florida)-2023 Oracle CloudWorld Event (OCW) Las Vegas 2022 | SynergisticIT - YouTube https://www.youtube.com/watch?v=OAFOhcGy9Z8  https://www.youtube.com/watch?v=EmO7NrWHkLM  https://www.youtube.com/watch?v=NVBU9RYZ6UI  https://www.youtube.com/watch?v=Yy74yvjatVg SynergisticIT at Gartner Data and Analytics Summit 2023 - YouTubeFor preparing for interviews please visit  https://www.synergisticit.com/interview-questions/  We are looking for the right matching candidates for our clients  Please apply via the job posting  REQUIRED SKILLS For Java /Full Stack/Software Programmer   Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT  Highly motivated, self-learner, and technically inquisitive  Experience in programming language Java and understanding of the software development life cycle  Project work on the skills  Knowledge of Core Java , javascript , C++ or software programming  Spring boot, Microservices, Docker, Jenkins and REST API's experience  Excellent written and verbal communication skills 
 For data Science/Machine learning Positions Required Skills  Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT  Project work on the technologies needed  Highly motivated, self-learner, and technically inquisitive  Experience in programming language Java and understanding of the software development life cycle  Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools  Excellent written and verbal communication skills 
 Preferred skills: NLP, Text mining, Tableau, PowerBI, Tensorflow  If you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.  No phone calls please.  Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates"
Data Engineer II - Remote,Net Health,"Pittsburgh, PA (Remote)",https://www.linkedin.com/jobs/view/3779192681/?eBP=JOB_SEARCH_ORGANIC&refId=f6As7U02xhgNmK54aPROHg%3D%3D&trackingId=ZcbCZSjyf2ddIhp4b2AqMA%3D%3D&trk=flagship3_search_srp_jobs,3779192681,"About the job
            
 
Job DetailsDescriptionAbout Net HealthBelong. Thrive. Make a Difference.Are you looking for a meaningful and satisfying career where you have endless opportunities to grow and be financially rewarded? Net Health may be the perfect place for you.A high-growth and profitable company, we help caregivers harness data for human health. We also honor and respect the needs of our Net Health family and staff, which is why we offer a work-from-anywhere environment and unlimited PTO. Our welcoming and collaborative culture paired with progressive benefits makes Net Health the ultimate career home!As a leading-edge SaaS company in healthcare, we deliver solutions that help patients get better, faster, and live more fulfilling lives. Our software and predictive analytics cover the continuum of care, from hospital-to-home, across various medical specialties. Come join us and start the next chapter of your exciting career while helping others to live better lives.World-Class Benefits That Reflect Our World-Class Culture.Click Here to Learn More!:#WorkFromAnywhere #UnlimitedPTO #ComprehensiveBenefitsPackage #EmployeeResourceGroups #CasualDressCode #PrioritizedEmployeeWellness #DiversityAndInclusion #AVoice #NewHireSupport #CareerDevelopment #EducationalAssistance #EmployeeReferralBonus #ProgressiveParentalLeaveJob OverviewDesigns, models, documents, and guides the logical and conceptual relationship of data and database changes for complex applications. Analyzes needs and requirements of existing and proposed systems, and develops technical, structural, and organizational specifications. May also develop, implement, and maintain data systems to meet designs, models and specifications. This person will analyze client production issues and create SQL statements to fix the issue.Responsibilities And Duties Will work with development wen new features or changes happen to the schemaCreate and maintain internal procedures and documentation around reusable SQL scripts or new additions to the data schema due to newly deployed features and functionalityAssist support with triaging complex client issuesProvide ad-hoc reportsAnalyze data to spot anomalies, trend and correlate similar data setsAnalyze large, complex datasets to drive actionable insights and recommendationsEvaluate failures, defects, systemic problems and hardwareConfer with clients to identify problems, replicate the problems, and troubleshoot for root causeParticipate in Agile/Scrum process to refine, prioritize, and build solutions to meet customer needsCreate and maintain internal procedures and documentation around reusable SQL scripts or new additions to the data schema due to newly deployed features and functionalityPerform other related duties as required and assigned
Qualifications Bachelor’s degree or equivalent experience2-4 years of relevant experience
Required Software Experience MS Excel or Google Spreadsheets2-4 years SQL (both DML and DDL)Exposure to 1-2 relational Database Systems (Postgres, Oracle, SQl Server, Snowflake, RedShift, BigQuery etc.)2-4 years Data Visualization, Analysis, or reporting1-2 years with at least 1 scripting language (Javascript, Python, PHP, Bash, Powershell)0-2 years building and maintaining an enterprise Data Warehouse
Note: This job description is not intended to be all-inclusive. Employee may perform other related duties as requested to meet the ongoing needs of the organization.Colorado Pay Law: If you are a Colorado resident and this role is available in Colorado or remote, you may be eligible to receive additional information about the compensation and benefits for this role, which we will provide upon request. Please send an email to Recruiting@NetHealth.comIf you are a CA, CT, CO, IL, MD, NV, RI, WA or NY City resident and this role is available in one of those locales or remote, you may be eligible to receive additional information about the compensation and benefits for this role, which we will provide upon request. Please send an email to Recruiting@NetHealth.com"
Data Engineer,Smile ID (formerly Smile Identity),"San Francisco, CA (Remote)",https://www.linkedin.com/jobs/view/3641780519/?eBP=JOB_SEARCH_ORGANIC&refId=f6As7U02xhgNmK54aPROHg%3D%3D&trackingId=yVD7H%2F83Eg1M%2FrhlHAlc7A%3D%3D&trk=flagship3_search_srp_jobs,3641780519,"About the job
            
 
Smile Identity builds trust.Smile Identity is Africa's leading identity verification, and digital Know Your Customer (KYC) provider. We help companies scale rapidly across Africa by confirming the true identity of their users in real time, using any smartphone or computer. Our technology is powered by proprietary Machine Learning algorithms designed specifically for African faces, devices and network connections.Our team is a diverse group of hardworking, truth-seeking, and fun-loving Smilers spanning 5 offices, 10 countries and 8 time zones. Our products are already making waves across many industries, from Banking to Fintech and Telecoms. We recently announced a $20M Series B raise and are backed by leading global investors, including Norsken22, Costanoa, CRE, Future Africa, Susa Ventures, Commerce Ventures, Courtside Ventures, Two Culture Capital, Latitude, Valuestream Ventures, Intercept Ventures and Vinod Khosla who are supporting us every step of the way.Do you like working alongside a team of intelligent individuals? Do you want to have fun while making a real difference? Here at Smile Identity, you'll get the freedom and autonomy you need to do your best work, the flexibility to be creative, and the opportunity to grow and put your unique stamp on our mission.What are you waiting for? Come with us on this amazing journey!The RoleWe are looking for a data engineer who loves bringing order to chaos. The individual in this role will maintain our data warehouse and associated data infrastructure and provide the entire organization with the data they need to be successful. This role is open to candidates across the globe. You will be working with colleagues ranging from the US West Coast to Eastern Africa, with that in mind candidates working in timezones between US Eastern and GMT are preferred.What You Will Do Work with our entire organization based in the US, London, Berlin, Lagos, Nairobi, and Cape Town to centralize our data and maintain our data warehouses/lakes. You will select the right tools and services to bring our data together and provide a solid foundation for all our product and business analytics. Your north star? Empowering the entire organization with data to make the best possible decisions. Design, build and launch extremely efficient and reliable data pipelines to move data. Architect, build and launch new data models that provide intuitive analytics. Manage the delivery of high impact dashboards, tools and data visualizationsBuild data expertise and own data quality, including defining and managing SLAs for data sets. Partner with leadership, engineers, commercial, and data scientists to understand data needs. Influence short- and long-term strategy with cross-functional teams to drive impact. Educate your partners: Use your data and analytics experience to discover opportunities, identifying and addressing gaps in existing logging and processes. 
Requirements 4+ years experience with data infrastructure, ETL design, data warehousing, schema design and dimensional data modeling2+ years of experience in SQL, Python, or similar languagesExperience with designing and implementing real-time pipelinesExperience with code management tooling such as Git, GithubExperience with data migrations in production settingsYou have a deep understanding of modern data tooling and infrastructureYou are comfortable working independently with periodic guidance from engineering & business teamsYou are a strong believer in scale and automationYou are entrepreneurial — you take initiative, solve problems and love to troubleshoot. You are a great collaborator and can communicate effectively. You enjoy teaching and learning from your colleaguesYou are not ideological about programming languages or tools. You have opinions but are open to discussion and tradeoffsYou are a pragmatistYou are a seeker of truth
Preferred Qualifications Experience querying big data using Spark, Presto, Hive, Impala, etc. Experience with data quality and validationExperience with SQL performance tuning and E2E process optimizationExperience creating reports and dashboards with modern business intelligence tools (Tableau, Metabase preferred)Experience working with Postgres, Hevo, and cloud or on-prem Big Data/MPP analytics platform (i.e. Snowflake, AWS Redshift, Google BigQuery, Azure Data Warehouse, Netezza, Teradata, or similar). Interest or experience in working in the African Fintech EcosystemExperience in a high-growth team and/or startup experienceAbility to communicate and prioritise effectively with a distributed team around the world
Compensation Salary commensurate with experienceStock options HealthcareOpportunities for travel (Post-Covid19)
Autonomy and a chance to work at a mission-driven company with purposeWhat Success Looks LikeSuccesses in your first 3 months include Take the time and learn the ins and outs of our data warehouse and dashboards. Investigate how data is being logged in our systems and what existing data pipelines exist across our two data warehouses (Postgres and Redshift). Evaluate existing dashboards, data quality, and pipelines and identify gaps. Get introduced to the Product and Engineering team and their bi-weekly sprint processes. At this point you are mostly observing the dynamics and taking on tasks by the team, while building a partnership and exploring support opportunities. 
In your first 6 months Based on your initial exposure to our data stack, you have already built several improvements based on the gaps you've identified. You are able to manage the flow of data across the stack. You have extended our system capabilities as needed and have improved efficiency and simplicity of shared tools and libraries. You are deeply embedded in how we set up data logging and are able to manage and successfully execute on data requirements from teams across the company (e.g. Engineering, Product, CVML, Data Science, Marketing, Commercial). You proactively develop technical methodologies or tools which can solve important classes of problems. You can evangelize these methodologies and tools to other data scientists and engineers to scale multiple people. 
In your first 12 months You are the company expert in our data, infrastructure, and technical architecture, and are actively involved in product and business operations to either improve existing data tools or suggest new methodologies to accelerate team execution, including influencing data best practices. You drive scalable solutions across teams. You are able to solve challenging technical problems faced by multiple teams and provide significant technical advice to newer or less-technical analysts."
Data Engineer (100% Remote),Praescient Analytics,"Fairfax, VA (Remote)",https://www.linkedin.com/jobs/view/3768491689/?eBP=JOB_SEARCH_ORGANIC&refId=f6As7U02xhgNmK54aPROHg%3D%3D&trackingId=7VImZYADhcXr42WDBx2X9w%3D%3D&trk=flagship3_search_srp_jobs,3768491689,"About the job
            
 
Praescient Analytics, LLC is a Veteran-led, certified Woman-Owned Small Business (WOSB) founded in 2011 which specializes in implementing advanced analytics solutions across the defense, intelligence, and law enforcement communities. Praescient has extensive experience designing, developing, and integrating solutions for customers including the US Army, Special Operations Command (SOCOM), US Navy (USN), US Marine Corps (USMC), US Coast Guard (USCG), Department of Justice (DOJ), Drug Enforcement Administration (DEA), and Federal Bureau of Investigation (FBI), Immigration and Customs Enforcement (ICE), intelligence community, and local law enforcement agencies, among others.Praescient Analytics is in search of a Data Engineer to help develop best practices and providing consultative advice across a wide range of big data technologies and data management tools for our client. The Data Engineer will be expected to perform duties such as evaluating the performance of current data integrations, data management tools, and associated processes and procedures within a cloud systems environment. This position is fully remote. US Citizenship and a Public Trust clearance will be REQUIRED.Primary Responsibilities Manage and maintain ADLS file storage directories to support large multi-stage ETL pipelinesImplement pipelines to transfer sever-based data sources into ADLS, or directly to Synapse where appropriate.Establish quality controls for any manual uploads of flat file extracts into ADLSImplement ETL/ELT process and architecture within Azure Synapse and Azure Data Factory, including creating lookup tables where necessary to improve performance or efficiencyImplement fraud flag tables by entity and individual, linking all identified fraud flags for easy access via SQL query.Implement aggregate views to quickly summarize key information and enable high performance queries by analysts and other usersDocument all transformation processes and data architecture, including any derived or aggregate fields created to support the architectural design.
Required Qualifications 5+ years of hands-on experience maintaining SQL databases, including expert level skills in SQL and T-SQL.5+ years of hands-on experience working in cloud-based environments with distributed SQL pools.Experience with designing and implementing ETL/ELT processes in support of cloud-based data analytics environments.
Desired Qualifications Experience with distributed systems utilizing tools such as Apache Hadoop and/or Spark.Experience with Azure cloud offerings.Experience with big data analytic tools such as Databricks or Azure Synapse.Experience working with graph databases such as Neo4j.Working experience in Agile Scrum environments.Experience with source control tools such as GitHub or Azure DevOpsBachelor’s degree in Data Science, Business Intelligence, Computer Science or related fields, or the equivalent combination of education, professional training, and work experience
If you are a self-starter who is passionate about data analysis and eager to make a meaningful impact, we invite you to apply for this exciting opportunity with Praescient Analytics! Very competitive salary based on qualifications and experience.Comprehensive, Company paid healthcare for you (We pay your premiums and deductibles)401(k) with company matchingTravel & performance incentives26 days of paid time off$5K annual training allowance$500 book allowanceTuition reimbursement program
Praescient Analytics is committed to providing equal employment opportunities for all. Employees and applicants without regard to race, color, age, religion, sex, sexual orientation, marital status, gender identity, national origin, legally protected physical or mental disability, genetic information, citizenship status, or status in the uniformed services of the United States, status as a disabled veteran or veteran of the Vietnam era, or on any other basis which is protected under applicable law. This includes a commitment to provide a work environment that is free from all forms of illegal harassment including sexual harassment.This covers all terms and conditions of employment including (but not limited to): Hiring, placement, promotion, transfer, or demotion of all job classifications;Recruiting, advertising, or solicitation for employment;Treatment during employment;Rates of pay or other forms of compensation;Benefits;Selection for training;Company sponsored social and recreational activities; andLayoff or termination
 Applicants selected will be subject to a government security investigation and must meet eligibility requirements for access to classified information. US Citizenship RequiredPraescient Analytics is an Equal Opportunity Employer.Interested Candidates: Please forward your resume to recruiting@praescientanalytics.com and please visit our website to apply online at www.praescientanalytics.applicantstack.com/x/openings."
Data Engineer,Care.com,"New York, NY (Remote)",https://www.linkedin.com/jobs/view/3743209378/?eBP=JOB_SEARCH_ORGANIC&refId=f6As7U02xhgNmK54aPROHg%3D%3D&trackingId=65WpfTJQCQKOytBSVp9d8A%3D%3D&trk=flagship3_search_srp_jobs,3743209378,"About the job
            
 
About Care.comCare.com is a consumer tech company with heart. We're on a mission to solve a human challenge we all face: finding great care for the ones we love. We're moms and dads and pet parents. We have parents and grandparents, so we understand that everyone, at some point in their lives, could use a helping hand. Our culture and our products reflect that.Here, entrepreneurs, self-starters, team players, and big thinkers unite behind a common cause. Here, we're applying data analytics, AI, and the latest technologies to solve universal problems and connect people in new ways. If you like having autonomy, if you thrive on collaboration and building new things, and if you're all about using your talent for good, Care.com is the place for you.What Your Days Will be Like:The Data Engineer will be focusing on building out data feeds and tooling from our application platform and enable rapid ingestion into our centralized Data Lake/Data Warehouse. The Data Engineer will work across business areas and application teams at Care.com to rationalize data and design, build and maintain reusable data feeds which and ultimately empower analytics consumption at Care.com.The ideal candidate will have professional experience building data pipelines in a technical environment. S/he will have an understanding of application development, data warehousing, demonstrate strong business judgment, and be able to prioritize in a fast-paced environment.What You'll Be Working On:  Collaborate and partner with application teams to understand data collection/generation and design and partner to build and implement data feeds from our product tech stackDesign, develop, and build code for rapid feeds and ingestion into the Data WarehouseIdentify data sources used for building out data architecture diagrams/modelsEstablish engineering practices and setup frameworks for ""Data as a Service""Collaborate with relevant delivery teams, including infrastructure, operations, site reliability engineering, product development, and others to perform evaluations, POCs, and ultimately implement and operationalize new technology. Solve code level problems quickly and efficiently Participate in demos and code reviews Promote software best approach, standards, and processes Shape development processes to promote a high-quality output while continuing to iterate quickly Incorporate best practices for security, performance, and data privacy into data pipelines
What You'll Need to Succeed: BS or MS in Computer Science or relevant engineering experience5+ years work experience in Data Engineering/data pipelines3+ years SQL experience is a must1+ years Unix/batch scripting preferred1+ years Python experience is a plus1+ years Windows server admin experience is a plusExperience interfacing with business teams and turning requirements and vision into a technical realityMySQL & Vertica Experience a plus/preferredAWS experience is a plusAbility to drive efforts from start to finish as a self-motivatorKnowledge in Data Warehousing is a MUSTProven ability to maintain performance level in a fast-paced agile environment Pragmatic and realistic with solutions
For a list of our Perks + Benefits, click here!Care.com supports diverse families and communities and seeks employees who are just as diverse. As an equal opportunity employer, Care.com recognizes the power of a diverse and inclusive workforce and encourages applications from individuals with varied experiences, perspectives, and backgrounds. Care.com is committed to providing reasonable accommodations for qualified individuals with disabilities. If you need assistance or accommodation, please reach out to talent@care.com.Company Overview:Available in more than 20 countries, Care.com is the world's leading platform for finding and managing high-quality family care. Care.com is designed to meet the evolving needs of today's families and caregivers, offering everything from household tax and payroll services and customized corporate benefits packages covering the care needs of working families, to innovating new ways for caregivers to be paid and obtain professional benefits. Since 2007, families have relied on Care.com's industry-leading products—from child and elder care to pet care and home care. Care.com is an IAC company (NASDAQ: IAC).Salary Range: 110,000 to 145,000. The base salary range above represents the anticipated low and high end of the national salary range for this position. Actual salaries may vary and may be above or below the range based on various factors including but not limited to work location, experience, and performance. The range listed is just one component of Care.com's total compensation package for employees. Other rewards may include annual bonuses and short- and long-term incentives. In addition, Care.com provides a variety of benefits to employees, including health insurance coverage, life, and disability insurance, a generous 401K employer matching program, paid holidays, and paid time off (PTO)."
Data Engineer - Remote | WFH,Get It Recruit - Information Technology,"Jacksonville, FL (Remote)",https://www.linkedin.com/jobs/view/3766963082/?eBP=JOB_SEARCH_ORGANIC&refId=f6As7U02xhgNmK54aPROHg%3D%3D&trackingId=80Y3ZvJsEuhTsDDrwv%2BgYA%3D%3D&trk=flagship3_search_srp_jobs,3766963082,"About the job
            
 
Are you ready to embark on an exciting journey as an Associate Data Engineer? Join our dynamic team and be an integral part of our Business Intelligence initiatives, supporting one of the leading global pharmaceutical clients.Position OverviewAs an Associate Data Engineer, you'll play a pivotal role in crafting innovative data engineering solutions that drive business impact across the Americas Region. Your mission includes tackling complex data migration and transformation challenges, enabling the acceleration of end-to-end reporting and analytics, and managing data catalog for the business. Your problem-solving skills will be put to the test as you work in partnership with our IT team to ensure data integrity in our ""data lake.""Key ResponsibilitiesIdentify and resolve quality issues during complex data migration and transformation.Support BI analysts with fundamental data engineering capabilities to facilitate complex analytics.Be accountable for data engineering use cases, some of which may have ""limited time"" life cycles.Write queries and code real-time solutions for fast deployment within a sandbox environment.Engage in data engineering to support the acceleration of end-to-end reporting and analytics.Manage new data sources in compliance with HIPAA and HCC, including access protocols.Collaborate with the IT team to solve data issues in the data lake and answer urgent business priority questions.QualificationsBachelor's or advanced degree in Computer Science, Data Science, Business Administration, Engineering, or a related field with a focus on Information Technology.Minimum of two years of progressive experience in data warehousing and decision support/reporting environments.Minimum of two years of software development experience, preferably with data transformation scripting languages such as INFORMATICA, SQL, TALEND, or Python.Demonstrable expertise in data lifecycle management, including data ingestion, contextualization, and analytics.Familiarity with large datasets and understanding of data analysis workflows, experience with data visualization tools like Tableau is a plus.Strong attention to detail, organizational skills, and the ability to manage multiple tasks.Effective communication skills, both oral and written, for collaborating with business partners.BenefitsCompetitive salary in the range of $37.00 - $42.00 per hour.Comprehensive benefits package, including 401(k) with matching, dental and health insurance, paid time off, and vision insurance.ScheduleFull-time position, Monday to Friday.Equal Opportunity EmployerWe are an equal opportunity employer. We provide equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, national origin, age, sex, citizenship, disability, genetic information, gender, sexual orientation, gender identity, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state, and local laws.Join us in this exciting and meaningful role as an Associate Data Engineer and make a difference in the world of data and analytics!Employment Type: Full-Time"
Remote Work - Need Staff Data Engineer - USC only,Steneral Consulting,United States (Remote),https://www.linkedin.com/jobs/view/3746283980/?eBP=JOB_SEARCH_ORGANIC&refId=f6As7U02xhgNmK54aPROHg%3D%3D&trackingId=cQUNec5pZfFQTdYQbNB2aQ%3D%3D&trk=flagship3_search_srp_jobs,3746283980,"About the job
            
 
100% Remote, client is in NYLook for strong job history, Python, Machine Learning, SQL, 10/10 comms, etc. MUST be an Engineer SummaryWe're looking for an experienced Data Engineer to join our client's growing team of top notched IT professionals. You will work closely across multiple groups including Editorial and Audio, Marketing, Advertising, etc. to achieve their goals and objectives. The Data Engineering team builds tools throughout the stack while sharing knowledge across these departments.As the company grows, they're looking for Data Engineer who will help solidify and expand our pipelines and maintain their data warehouse. Their business model is based on performing complex and very detailed analyses of how our products perform with their subscribers. You'll be responsible for working alongside analysts, product, marketing, and other teams to define new data collection components and measurement schemes that support each new product and feature.How Can Add Value To Their Mission Create and maintain data pipelines to provide insights and drive business decisionsEstablish data warehousing strategy (ex. Kimball, Data Vault, etc.)Maintain data infrastructure on our AWS accountsCollaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.Write unit/integration tests, contributes to engineering wiki, and documents workImplement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it
What You'll Need To Succeed 7+ years of industry experience measuring product performance and user behaviorExperience working with a variety of data management technologies, including RedShift, Kinesis/Kafka, Glue, Spark, Postgres, Airflow, dbt, and others.Experience implementing BI reporting tools such as LookerExperience interfacing with engineers, product managers and analysts to understand data needsKnowledge of a variety of measurement beacons, SDKs, APIs including Google Analytics, Amplitude, Braze, Stripe, email service providersA commitment to building secure, resilient, fault-tolerant architectures, with clear documentation and procedures in place for supportA focus on accuracy and detail as you build, ensuring data pipelines produce clear, predictable resultsUnderstanding of the typical metrics a subscription and advertising-supported business needs to measure successExperience with Client techniques as applied to behavioral segmentation or anomaly identification is a definite plusFamiliarity using developer tools that increase productivity and facilitate the development of resilient code (eg. Docker, CircleCI, Serverless) is a plus"
Developer/Data Engineer || Remote,Steneral Consulting,United States (Remote),https://www.linkedin.com/jobs/view/3665291336/?eBP=JOB_SEARCH_ORGANIC&refId=f6As7U02xhgNmK54aPROHg%3D%3D&trackingId=WnQtfafX2XYhuB8Lh%2F9nAQ%3D%3D&trk=flagship3_search_srp_jobs,3665291336,"About the job
            
 
remote roleKey Experience(s)  Prior experience as a SQL or PL/SQL developer (5+ years) Previously developed in Power BI (5+ years) Previous experience working with Databricks Previous ETL data validation and reconciliation experience Previously participated in Data Conversion Understands how to iteratively develop Understanding of Agile (SCRUM) practices Previously run or contributed to discovery interviews Previous work on FISERV products, specifically DNA Previous financial services/banking experience is a plus
Key Skill(s)  Good communicator, both written and verbal Well organized Attention to detail Team Player
Key Technology /Certification(s)  PowerBI, SQL, Databricks"
Data Engineer,IVY TECH SOLUTIONS INC,United States (Remote),https://www.linkedin.com/jobs/view/3686025266/?eBP=JOB_SEARCH_ORGANIC&refId=f6As7U02xhgNmK54aPROHg%3D%3D&trackingId=%2BQHzZGLcSc2uz1JyTMVsrQ%3D%3D&trk=flagship3_search_srp_jobs,3686025266,"About the job
            
 
Remote PositionData EngineerOnly w2Please send the resume to sowmya.g@ivytechsol.us Job Description:DataStage Data Engineer US/GC/Certain EADs – 6 month remote contract.Together we are building a culture that values diversity and creates a space of belonging for all our team members. We believe that investing in your success is an investment in our customers and our business. Our people are what sets us apart and make us great. As a Data Engineer, you’ll provide your talents in contributing to the success of the client’s team by delivering the following:  Serve in the goalie rotation to support the Production environment. Responsible for maintaining enterprise-grade platforms that enable data-driven solutions. Search for ways to automate and maintain scalable infrastructure. Ensure delivery of highly available and scalable systems. Monitor all systems and applications and ensure optimal performance. Analyzes and designs technical solutions to address production problems. Participate in troubleshooting applications and systems issues. Identifies, investigates, and proposes solutions to technical problems. While providing technical support for issues, develop, test, and modify software to improve efficiency of data platforms and applications. Monitors system performance to maintain consistent up time. Prepares and maintains necessary documentation. Participate in daily standups, team backlog grooming, and iteration retrospectives. Coordinate with data operations teams to deploy changes into production. Highest level may function as a lead. Other duties as assigned.
Qualifications:  Requires a Bachelor's in Computer Science, Computer Engineering or related field and experience with ETL development, SQL, UNIX/Linux scripting, Big Data distributed systems. Prefer experience with IBM DataStage. Various programming languages like Java and Python, orchestration tools and processes or other directly related experience. A combination of education and experience may meet qualifications. Excellent analytical, organizational, and problem-solving skills. Ability and desire to learn new technologies quickly. Ability to work independently and collaborate with others at all levels of technical understanding. Able to meet deadlines. Good judgment and project management skills. Ability to communicate both verbally and in writing with both technical and non-technical staff. Ability to work in a team environment and have good interpersonal skills. Ability to adapt to changing technology and priorities. Must be able to work independently, handle multiple concurrent tasks, with an ability to prioritize and manage tasks effectively
Powered by JazzHRgDX0uvPo7F"
(Remote) Data Engineer,SynergisticIT,"Anaheim, CA (Remote)",https://www.linkedin.com/jobs/view/3767593300/?eBP=JOB_SEARCH_ORGANIC&refId=f6As7U02xhgNmK54aPROHg%3D%3D&trackingId=s7Kcy5FPPGb67%2FMhQApM5w%3D%3D&trk=flagship3_search_srp_jobs,3767593300,"About the job
            
 
The Job Market is Challenging due to almost 300,000 Tech Layoffs since October 2022 due to which thousands of laid off Techies are competing with existing Jobseekers. Entry level Job seekers struggle to get responses to their applications forget about getting client interviews. As the Saying goes ""when the Going gets tough the Tough get going” Candidates who want to make a tech career they need to differentiate themselves by ensuring they have exceptional skills and technologies to be noticed by clients.Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.All Positions are open for all visas and US citizensWe are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$'s and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs. Clients now post covid can also hire remote workers which increases even more competition for jobseekers.We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, PayPal, western union, Client, visa, Walmart labs etc. to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in IT IndustryWe assist in filing for STEM extension and also for H1b and Green card filing to Candidates We also offer optionally Skill and technology enhancement programs for candidates who are either missing skills or are lacking Industry/Client experience with Projects and skills. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. If they are qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients. Shortlisting and selection is totally based on clients discretion not ours.please check the below links to see success outcomes of our candidateshttps://www.synergisticit.com/candidate-outcomes/We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023Oracle CloudWorld Event (OCW) Las Vegas 2023/ 2022 | SynergisticIT - YouTubehttps://youtu.be/Rfn8Y0gnfL8?si=p2V4KFv5HukJXTrnhttps://youtu.be/-HkNN1ag6Zk?si=1NRfgsvL_HJMVb6Qhttps://www.youtube.com/watch?v=OAFOhcGy9Z8 https://www.youtube.com/watch?v=EmO7NrWHkLM https://www.youtube.com/watch?v=NVBU9RYZ6UI https://www.youtube.com/watch?v=Yy74yvjatVgFor preparing for interviews please visit https://www.synergisticit.com/interview-questions/We are looking for the right matching candidates for our clientsPlease apply via the job postingREQUIRED SKILLS For Java /Full Stack/Software Programmer Bachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleProject work on the skillsKnowledge of Core Java, JavaScript, C++ or software programmingSpring boot, Microservices, Docker, Jenkins and REST API's experienceExcellent written and verbal communication skills
For data Science/Machine learning PositionsRequired Skills Bachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITProject work on the technologies neededHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, SAS, Python, Computer Vision, data visualization toolsExcellent written and verbal communication skills
Preferred skills: NLP, Text mining, Tableau, PowerBI, TensorFlowIf you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates"
Data Engineer,NauWork,"San Diego, CA (Remote)",https://www.linkedin.com/jobs/view/3776572928/?eBP=JOB_SEARCH_ORGANIC&refId=f6As7U02xhgNmK54aPROHg%3D%3D&trackingId=VUpjCxGcTPzrVdhXP6UVBg%3D%3D&trk=flagship3_search_srp_jobs,3776572928,"About the job
            
 
A NauWork client is seeking a Data Engineer to join their team. The position is fully remote or hybrid based in San Diego, California.This client is a leading medical staffing agency with a mission to help others live better by helping healthcare professionals and the patients they serve. They’ve received multiple awards and accolades for “Best Places to Work” from companies like Glassdoor and Modern Healthcare.As a Data Engineer II with a specialization in MS Power BI, you will lead the development and maintenance of data-driven solutions, creating compelling visualizations, and ensuring data integrity. Your deep understanding of data infrastructure and data visualization will help drive strategic decisions, streamline operations, and empower our team with actionable insights.Responsibilities:Data Pipeline Development & Management: Design, construct, install, and maintain large-scale processing systems and other infrastructure. Manage and optimize data pipelines, ensuring data availability, accuracy, and optimal performance. 
MS Power BI Development & Management: Develop, maintain, and optimize Power BI dashboards and reports tailored to business needs. Collaborate with stakeholders to identify opportunities for data-driven decision-making and to define metrics and KPIs. Ensure consistency and integrity of data visualizations across all Power BI reports. 
Data Analysis & Optimization: Work with cross-functional teams to gather requirements, understand business challenges, and provide data-driven solutions. Continuously analyze data processes and tools for improvement and scalability. 
Data Governance & Integrity: Collaborate with data governance teams to ensure data quality, compliance, and consistency. Develop and maintain documentation on data pipelines, data models, and data dictionaries. 
Team Collaboration & Leadership: Collaborate with IT, analytics, and business teams to ensure seamless integration of systems and tools. 
Required Experience: 5+ years of experience in data engineering with a strong emphasis on data visualization. Bachelor’s degree in computer science, engineering, information systems, or a related field. Proven expertise in MS Power BI development, including DAX, data modeling, and performance tuning. Strong experience in SQL, ETL processes, and data warehouse design. Familiarity with cloud platforms like Azure or AWS. 
Preferred Experience: Experience in the healthcare or recruiting industry. Familiarity with data governance principles and practices. Excellent communication skills, both written and verbal. Strong analytical and problem-solving skills with a keen attention to detail. 
To Learn More: 503-388-9585 833-NAU-WORK nauwork.com/careers 
Category: Technology - System SoftwarePosition: Data EngineerLocation: [Remote] San Diego, CaliforniaJob Type: Direct-Hire, Full-Time"
Data Engineer with centric application,SPAR Information Systems LLC,United States (Remote),https://www.linkedin.com/jobs/view/3652261474/?eBP=JOB_SEARCH_ORGANIC&refId=f6As7U02xhgNmK54aPROHg%3D%3D&trackingId=sp4rjzT67hhwW8DMp%2BTtXQ%3D%3D&trk=flagship3_search_srp_jobs,3652261474,"About the job
            
 
Hi TeamToday we have Urgent Need Data Engineer REMOTE)Location: RemoteLong Term Data EngineerRequirements4+ years' experience developing data centric applicationsKnowledge on Scala, DataBricks4+ years' experience creating data transformation and validation logicStrong understanding of streaming and batch data processing best practices.Advanced knowledge of data formats (JSON, XML, Parquet, etc.) and data modeling practices.Data modelling experience shaping and transforming data into third normal form and dimensional models.Advanced understanding of best practices for structuring and organizing Data Lake file systems for large volumes of data.Thanks & Regards,Ruchi VermaEmail : Ruchi.Verma@sparinfosys.com"
