{"job_title":"Python QA Automation engineer","company_name":"Luxoft","location":"Romania (Remote)","job_link":"\/jobs\/view\/3771394730\/?eBP=CwEAAAGMPGxik7VClII1seAMJA1n5DP_sy8nqZbkMnn9LuaAPUprVtJ4n0eH7N3scXOiQL4DZr-TKXJtxvSS8rL4kWpln8B8yhCdzN5KYU8JAgQlgZZG_-f06kahCgYLG6tRTyK5XgCG-bHN_uPbU25Kko_2gsxFBzTDaBM3R7ecrrZb7Irr21oWgjxx4_lkD5CqrN6BqJQ1IbdQWV1idTuGQGzycFRCkkJsXPF47ToCax6MHXWg9BsCbFoCqF-Cv4N6r76zhoy1MfLpbBjLq2Bjwa7eJZgo3f_ImFro4f4wxzvxnRZnU1CGxoD6kz9_zk88nzDpmNFteaQ3lhotHKkjsf9VV0UkR-ClZKd-Z3z8GDv6T3MG8eWU4wRDjBoEUg&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=Ifz%2Bh8ugtJbb%2F78YoV40kQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3771394730","job_description":"About the job\n            \n \nProject DescriptionYou will be part of a multi-national team responsible with the development of the next generation SDN (Software-Defined Networking) solution for Data Center networking.The solution targets Data Centers of large organizations, including private\/hybrid\/public cloud environments. It is addressing the needs of users requiring an easier option than switch-by-switch, CLI-based approaches and can automate time consuming tasks such as configuration of L2-L3 network devices.The controller uses microservice architecture, the components will communicate via REST APIs and will also provide a user-friendly web-based user interface on the front-end.We are looking for a QA engineer to contribute to the test automation process for a web application that monitors various network performance statistics and provides extensive visibility into the traffic flows.Responsibilities Develop automated test cases in Python, using public test framework pyATSCreate libraries for new features and maintain the existing onesPrepare Test plan, Test cases and Test scripts for product enhancements and bug fixesDocument test results, identify exceptions and communicate results to the teamManage Defect lifecycle\nSkillsMust have 2+ years of experience in automation testing with a computer science bachelor's degree or equivalentWorking knowledge of REST APIsProgramming and scripting skills in PythonUnderstanding of OOP concepts\n Soft SkillsVery good written and spoken EnglishAbility to work, and thrive in a distributed teamSelf-starter, self-learner capabilities, takes initiative, identifies and completes tasksProfessional with the ability to properly handle confidential informationStrong problem solving and analytical skillsStrong written and spoken communication skills\nNice to have Basic networking knowledgeKnowledge of using Postman\/ similar toolISTQB Certification is a plusHands-on experience testing switches, routers, docker\/container networking and SDN controller is a plusWorking knowledge of VMWare, vSphere, JenkinsExperience with a versioning system (preferably Git)"}
{"job_title":"Experienced Azure Data Engineer","company_name":"I FUTURE","location":"Romania (Remote)","job_link":"\/jobs\/view\/3766632984\/?eBP=CwEAAAGMPGxik70PyO59q-J5YnCOROL_oPyu7T16pxPXnm8XntE-rTjWL1d96B4UvmW1Nmkk7oXCL50VKWAySj0850beSQuP7qUnsurn6RaX0x3MOs92xE6tNDtfFvilz0h7Hiz8srcE7Y0c9YayFkAE7peb_Ah6LzTL6zxC3W_KoHR5fIvApapu1peallo6nCu6QdblmighAcQxkEBXENaNRKJTmjujWuF4x3tj5100Nowzsr7yETtRd6CyoLLtf3MnBcPpcEHZVbl3KJYZY-Qh-gm1hrhNYF9ZnijezzfsR2S2NWMGdyMMN3fdqbObnobG--AYi0RcdTz9uT1AP16oWTdBKAOHBV3lrySJC6JFEt5pSAaqQi96cj7ZGR6Y4A&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=0wHIBqGxAaneJIy1IiE6bQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3766632984","job_description":"About the job\n            \n \nWhat you will do As an Experienced Data Engineer, you are helping our clients with achieving their digital strategies and you will be part of: Building complex data pipelines using ETL Tools to transform the data to meet the business needs and specificationsDesigning, developing, enhancing enterprise data warehousing (EDW) and Azure data platforms, data migration solutions, end-to-end BI platforms using a wide range of the Azure Services such as: Azure Data Factory, Azure SQL Database, Azure Data Lake Storage, Azure Synapse, Databricks, etcProvisioning data storage solutions, build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sourcesSupporting Data Architects with technical questions and decisionsProposing performance improvements (technical, architectural, processes, etc.) Provide technical leadership to the domain - mentor junior members in technical proficiency and understanding of Data Engineering Principles\nWhat we expect  Excellent knowledge of any SQL (ASQL, MSSQL, Oracle, etc.) and hands-on experience with procedural SQL and performance tunning skillsStrong knowledge of ETL process and hands-on experience with data pipelines development (using at least one of the tools: ADF, SSIS, Talend, Informatica, etc.)Strong knowledge of DWH\/data platforms design & conceptsGood knowledge about data modeling, data access, and data storage techniquesExperience with the following Azure services: Azure Data Factory, Databricks and Azure Data Lake Storage and\/or other data servicesWorking experience with Git or other versioning control toolsExperience with working in Agile environments\nNice to have Microsoft data certifications like: DP-900, DP-203, DP-300, etc. or Databricks certificationsExposure with object-oriented\/object function scripting languages (interpret and write basic code) - preferred are Python or C#\/.NETExperience with continuous integration, continuous delivery pipelines (CI\/CD)BSc or MSc University degree in the field of IT \nWhat we offer: Access to trainings, materials and bootcamps to build\/enhance your data skills in AzureSponsorship for Microsoft Azure, Databricks and Profisee certifications (but not limited to those only)Access to multiple online learning platforms Microsoft Azure SubscriptionAccess to various soft skills trainingsMultiple career development lanes: Azure Data Engineer SME, Azure Architect, Project Management, etc.Work from homeContinuous growth in a positive and multicultural work environmentRefer-a-Friend \u2013 get a bonus in the employee referral programFamily oriented benefitsShare purchase planPersonalized benefits package, including meal vouchers, public transportation, medical services, private pension, life insurance, gym subscription and many more"}
{"job_title":"Lead Data Engineer","company_name":"NTIATIVE IT Recruitment","location":"Poland (Remote)","job_link":"\/jobs\/view\/3770955127\/?eBP=CwEAAAGMPGxik3uStA2fWGueyLxEB_rcxO48VPJQHIVPG-azh0cSqOk3QOtaKtZnDUtajKacDaNw0df7NNGSPOU6aPTcXek6ck-KxFtvMZSuKru2njfJ-EJ-4kqJa3nvdUtZBX01WwC9bOMuHuufa0ykqpSsJ_qN2pkB5hNiIOxa4r4RjrhfCvFZX_jkHNmiU9KcJDAjOprsf1irmwhnbXId5yuBIFYjYn2BmzO01SQ_QiVgMcHLAS9iDI_0BJJro4LCQ2KsgBvO_WLKMF0Gbixf0FbOqe7eU1nlqMI_C04iro2-XNicE-jT-2DbP3JFZt2C-hEZesUvgkfdtDydaC9H4k84wMKZatezVAJ1vbBB8qYIeMDVrjlMbnH6yFBAqQ&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=QT84k0%2BKwFrYVRntuRF9Vw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3770955127","job_description":"About the job\n            \n \nWe work with company which is the world\u2019s most comprehensive sources for petroleum pricing and news information. They provide real-time and historical spot, wholesale\/rack and retail fuel prices for the refined products, renewable fuels and natural gas and gas liquids (LPG) industriesThey are seeking for a first in Poland \u2013 Lead Data Engineer to join a team of motivated engineers. \ud83c\udfdd Benefits: Strong Benefit packageAnnual Bonus (5%)Contract of employment (B2B will be available from the next year)Remote Work (Office in Gda\u0144sk if you prefer to work on-side)Flexible working hours\n\ud83d\udcbb Requirements: Minimum of 4 years database developer experience (SQL Server or equivalent) with building a data modelsAbility to write SQL queries and statements to explore source data and data issuesWorking knowledge of cloud data technologies and architecture (preferable AWS)Working knowledge of Python for data analysis and automationProficiency in BI tooling, Power BI preferred\n\ud83c\udfc5 Responsibilities: As a Lead Data Engineer, you will design, develop and maintain database architecture and code initiatives supporting internal and third-party software solutions,delivering excellent products in scope and on time, and meeting current and long-term business needs for the business area. Lead, mentor, and coach junior data engineers to build stronger and faster teams.\nPlease reach out to me if you are interested!"}
{"job_title":"Staff Data Modeling Engineer","company_name":"SentinelOne","location":"Prague, Prague, Czechia (Remote)","job_link":"\/jobs\/view\/3765344274\/?eBP=CwEAAAGMPGxik8itMGnRzrghca0nuuVSgBOVRuZUAx5uGvkR3MfMUHSDZOUHqRvAc5U3Brg8FLo2ALpHpehqfdqPai9Bh5y4Jw7DnxEiP-qHT4C9nrCOEH0z-jrrVIy1RUW2kNDG6Vkop-qUOOMfqPLJNMOn0s1u5chbZ44RLmGD8dx6uirH9nzCLYInSuitI0HOKhdP9Hs7b3bx40zQjunfYbNZR06hW_JJWHySjiFW4nLu2aGocEKvHjXh7-0ap4NxEy-AJyWuLHL3iGT-iJd12HV018IBCBwxhdxmtKV8PAr2mUDFbxQx_b_TM_zecR4t_9JtCOL-ddTkcJwR3ltvtvNTia1S-BCxdCEEkMuSNhZhe_4IWyDdeLtcv_Kwgw&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=T%2F9AzfzjDzkeG7U4sH%2BPfQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3765344274","job_description":"About the job\n            \n \nAbout Us:SentinelOne is defining the future of cybersecurity through our XDR platform that automatically prevents, detects, and responds to threats in real-time. Singularity XDR ingests data and leverages our patented AI models to deliver autonomous protection. With SentinelOne, organizations gain full transparency into everything happening across the network at machine speed \u2013 to defeat every attack, at every stage of the threat lifecycle.We are a values-driven team where names are known, results are rewarded, and friendships are formed. Trust, accountability, relentlessness, ingenuity, and OneSentinel define the pillars of our collaborative and unified global culture. We're looking for people that will drive team success and collaboration across SentinelOne. If you\u2019re enthusiastic about innovative approaches to problem-solving, we would love to speak with you about joining our team!What are we looking for?SentinelOne is seeking a talented Staff\/Techlead-level data modeler to assist with designing and implementing data products. As a data modeler, you will work closely with architects, data engineers, data analysts and other data modellers to implement data modeling solutions to streamline and support stakeholder reporting and enterprise business intelligence use cases.To ensure success as a data modeler at SentinelOne, you should have in-depth knowledge of data warehousing, excellent communication skills, and an understanding of how to turn raw data from various sources into easily consumable data products using tools within the data ecysostem, and operate under a philosophy of writing code as a last resort. Ultimately, a top-notch data modeler should be able to design models that reduce data redundancy, streamline data movements, and improve enterprise information management and time to insight.What will you do? Analyzing and translating business needs into long-term solution data models.Regularly engage and consult stakeholders on solving business problems through data, guiding the conversation rather than simply taking orders.Perform data profiling\/analysis activities that help to establish, modify and maintain data models.Evaluating existing data systems.Working with the development team to create conceptual data models and data flows.Developing best practices for data coding to ensure consistency within the system.Reviewing modifications of existing systems for cross-compatibility.Implementing data strategies and developing physical data models.Updating and optimizing local and metadata models.Evaluating implemented data systems for variances, discrepancies, and efficiency.Troubleshooting and optimizing data systems.Ability to take on additional tasks and responsibilities as the organization needs.Mentoring less-senior colleagues and knowledge sharing with the broader Data, Analytics & Governance organisation.\nWhat skills & knowledge should you bring? Multiple years of hands-on experience with physical and relational data modeling.Must have - proven profficiency with Google Cloud Platform, BigQuery, and related technologies.Experience working with infrastructure as code (Terraform, Pulumi, etc.) Expert knowledge of metadata management and related tools.Experience designing and architecting data solutions.Expert SQL skills.Knowledge of mathematical foundations and statistical analysis.Strong interpersonal skills.Excellent communication and presentation skills - in both written and spoken English.Advanced troubleshooting skills.\nWhat We Offer You Flexible working hours, In Prague & nearby we're working in a hybrid model with offices in Karlin (brand new Missouri Park), remotely in the rest of CZ or SK, with optional Brno offices (Clubco Vln\u011bna) for those who like to meetGenerous employee stock plan in the form of RSUs (restricted stock units) not options; 4 years vesting with 1-year cliff and then quarterlyYearly bonus depending on the performance of the company, paid out in 2 installmentsFlexible Time Off (on top of the standard 5 weeks of vacation)Flexible Paid Sick DaysFully Paid Short Term Sick\/Short Term Nursing LeaveGlobal gender-neutral Parental Leave (16 weeks, beyond the leave provided by the local laws) & Grandparent LeaveVolunteering paid day off & Additional paid Company holidays off (e.g. 4 days in 2022)Pension insurance contributionPremium Life Insurance covered by S1Cafeteria points (5.000 CZK\/month), which you can spend on leisure & sports (e.g. discounted MultiSport card), kindergarten\/school fees, travel etc. Private medical care membershipGlobal Employee Assistance Program (confidential counseling related to both personal and work life matters)High-end MacBook or Windows laptop, Home-office-setup gear & on top of that additional WFH AllowanceUdemy Business platform for Hard\/Soft skills Training, internal mentoring 'MentorOne' & Support for your further educational activities\/trainingsAbove-standard referral bonusOn top of RSUs, you can benefit also from our attractive ESPP (employee stock purchase plan)Refreshments, snacks, massages at the offices & weekly yoga at Prague office\/via ZoomOptional company events for those who like to meet outside of work too (sport, BBQ, charity etc.)DEI&B programs that promote employee resource groups like SentinelWIN (Women Inclusion Network), Blk@S1, Latinos@S1, Pan-Asian@S1, Out@S1 (LGBTQIA+) and Sentinels Who Served\nSentinelOne is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.SentinelOne participates in the E-Verify Program for all U.S. based roles."}
{"job_title":"Data Engineer (m\/f\/d)","company_name":"Ubermetrics Technologies GmbH","location":"Berlin, Berlin, Germany (Remote)","job_link":"\/jobs\/view\/3729218104\/?eBP=JOB_SEARCH_ORGANIC&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=IcSX6wxHMiWNqCSna6vkHA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3729218104","job_description":"About the job\n            \n \nAbout The PositionAs a data engineer, you create data products for our media analysis and intelligence services. You join a product-oriented cross-functional data team. Together with MLOps engineers, you enable the team to productize deep learning models designed by our data scientists. You focus on delivering high-throughput data pipelines. Moreover, you support the data scientists optimizing machine learning models for production deployments. Ideally, you bring a passion for owning data products in a high-bandwidth communication setup between all technical roles and product management.Your profile Excellent skills in Python and Java. Experience designing data-intensive systems in cloud environments, including data analytics and data warehousing. Experience implementing and querying scalable data storage systems (e.g., Postgres, BigQuery, Elastic Search, Snowflake). Sound knowledge of data processing \/ ETL concepts, orchestration (e.g., Apache Beam, Dataflow, Kafka, Airflow, Pub\/Sub), and data modeling with large-scale datasets. Familiar with modern cloud concepts such as containers (Docker), Kubernetes, and serverless computing. Understanding modern deep learning frameworks like Tensorflow, PyTorch, or ONNX. \nNice to have Experience and passion in designing and implementing systems for Natural Language Processing and Information Retrieval applications. Experience with MLOps workflows and the life cycle of machine learning models. Experience optimizing data structures for high-volume text data and text embeddings. Familiar with the Google Cloud Platform. Understanding of the needs of NLP-based Machine Learning Applications. A plus is familiarity with data visualization, dashboarding, and exploration tools (e.g., LookerStudio, Vega, Pandas\/Seaborn, etc.). Experience with Kotlin. \nWhat we offer: Exciting technical challenges and great opportunities to learn, grow and contribute. A welcoming, friendly, supportive, and multicultural working environment. The chance to bring in your ideas and be creative in a team. A focus on building an excellent product by doing things the right way. Flexible working hours and help with relocation from abroad. Work in an expanding and future-oriented company with a global perspective. Decide your own remote working balance \u2013 100% is possible. Flexible vacation and working time policies. 40+ passionate engineers working on products they are proud of. Possibility for personal growth and development. Lots of responsibility and a real chance to make an impact \u2013 shape our future products and services for an international client base. \nAbout usUbermetrics is a leading media and data intelligence platform, focused on research and development. It is part of the UNICEPTA Group, one of the global market leaders for media and marketing intelligence. The Ubermetrics platform processes over 50,000 content pieces per minute from over 460 million sources. It enables our dedicated monitoring and analytics teams within the UNICEPTA Group to leverage state-of-the-art data alerting, monitoring and analysis solutions for Communication and Marketing professionals from leading global companies and organizations. For these, UNICEPTA\u2019s actionable insights are also a basis for strategic decisions in risk management, supply chain management or compliance."}
{"job_title":"Lead Data Engineer (F\/H)","company_name":"Havana IT & Apps","location":"France (Remote)","job_link":"\/jobs\/view\/3764502190\/?eBP=CwEAAAGMPGxik3i1Qj2XjbiOTRKEhRutasKABlWaSbxCex3tz83AzkHQ5jnhiSH5W4mJZjzXEe3c4fE4EGLXaxfNutU3YyRXxZuoyO4-htuUOUx-b39Ny8MCBQCVUvpE31n4gFu3zI7mtK2rSqDiycmFDFXH_mEZ36ldBZJ1xRobT5OWqHMfujtszXetlhh3ELj65WKC0z-OFNb1qfEDc0mQzVONLJu4sRYXvZj6QB1GXUWnvWgtyug4qkxLAE6KSjZh7zWDIoQfpQDRqtpycQkzJzTFWMGaKDPpFk8Zss0-2QTJttDVAZS9Dy94gw8foYYhPCbRire0cMgIygoogV64c__md5xPyQ9FNZFMElfsWs6TwicZK0z29_rOfwa62CzA&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=iN7UPtUJ8PW%2FQliZn4sl7g%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3764502190","job_description":"About the job\n            \n \nGroupe Havana: Cr\u00e9\u00e9 en 2011, nous incarnons la transformation digitale en misant sur l'innovation, la performance et le bien-\u00eatre au travail.Notre identit\u00e9 : 200 experts d\u00e9ploy\u00e9s \u00e0 travers la France.Acteurs cl\u00e9s dans les domaines de la DATA, du Cloud et de l'intelligence artificielle.Nous accompagnons nos clients dans la transformation digitale de leur SI\nAujourd\u2019hui, nous proposons des projets nouveaux et recrutons des Lead Data Engineer (H\/F) en Full-Remote.Contexte :Les Data Factory de nos clients ont pour objectif de concevoir et mettre en \u0153uvre des solutions d'Intelligence Artificielle afin d'am\u00e9liorer et d'optimiser les performances des diff\u00e9rents services.Les missions principales seront les suivantes : Le consultant prendra en charge quelques cas d\u2019usage dans un projet sp\u00e9cifique qu\u2019il pilotera tant techniquement que fonctionnellement.Outre l\u2019expertise technique indispensable, votre r\u00f4le sera de f\u00e9d\u00e9rer en mode Agile une petite \u00e9quipe (Data Scientist, DevOps, Data Engineer).\nLe profil recherch\u00e9 : Titulaire d\u2019un dipl\u00f4me sup\u00e9rieur en informatique avec une exp\u00e9rience significative (minimum 5 ans) sur un poste similaire ;Rigoureux(se) avec une forte capacit\u00e9 d\u2019adaptation, d\u2019analyse, et d\u2019un bon relationnel.Une exp\u00e9rience internationale peut \u00eatre un atout\nL'environnement technique indispensable : Solide expertise en Data Engineering tel que de la construction des pipelines \u00e0 l'int\u00e9gration de mod\u00e8les de Machine Learning\u2026Parfaite maitrise des services \u00ab Data \u00bb (Azure, GCP, AWS, autres)Expertise en d\u00e9veloppement Python et parfaite utilisation de ses frameworks (avec plus de 80 000 lignes par projet).Expertise ou notions de DBTM\u00e9thode Agile et DevOpsMa\u00eetrise de l'anglais indispensable car dimension internationale\nPetites infos en plus : Il s\u2019agit d\u2019une mission de longue dur\u00e9e et \u00e9volutive que nous vous proposons.Celle-ci est possible en CDI, freelance et portage salarial !TJ : Selon profil \nNous rejoindre c\u2019est : \u00catre acteur des projets de transformation digitale et d\u2019am\u00e9lioration SI de nos clients ;Int\u00e9grer une \u00e9quipe et b\u00e9n\u00e9ficier d\u2019un management de proximit\u00e9 ;\u00catre moteur dans le d\u00e9veloppement de notre structure ;Apporter sa contribution \u00e0 nos projets d\u2019incubation de Startups (Lab) ;Avoir la possibilit\u00e9 de d\u00e9velopper ses comp\u00e9tences \u00e0 travers diverses formations ;Pouvoir \u00e9changer sur des sujets \u00e0 la pointe de la technologie lors d\u2019\u00e9v\u00e8nements ; (Workshop\/Afterwork) ;\u00catre soucieux de l\u2019environnement et du bien-\u00eatre au travail\nCe poste n\u2019est pas ouvert \u00e0 l\u2019alternance ou aux stages !Poste ouvert aux personnes en situation d\u2019handicap !"}
{"job_title":"Analytics Engineer, Finanace & Fintech","company_name":"Wolt","location":"Helsinki, Uusimaa, Finland (Remote)","job_link":"\/jobs\/view\/3779719331\/?eBP=CwEAAAGMPGxik5eTG4IlomCTumlnMGdoYDcGwRWkUMJP6olQEvUWBsixzEtkF2MKXkzFpPx2kyRCU_iU4gPwZXHyMqWxX83XMM8_YyG6q2pHwDf_n7zoXEIW5LdCi-y7REG93e87rv1iObulpHJcOIDe_YHF2SGkaN3CqPSqhAIXIKJIO-ZMq6VxG63p_ObSLzP_Uu7Pn-3Lu5nMdS6wB4dV4_PTPx58lJQ8YcCZmOjQ5aY2g74lb-pKRmXuMkg_zwLbM_SKmVPrADaRYe14zFDt0ZDg6weVgGbInuQxqK9I5gaApp_OQLDyrt5fJ-cmXIJobK5aCLu9P7qTlgJ8OEHLZ2B9&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=V1IapAvCDwyBV4sxzImRdQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3779719331","job_description":"About the job\n            \n \nJob DescriptionYour daily work will include:  Developing reporting as a whole, from understanding the needs of the business to providing easily understandable and actionable data. Working on our centrally maintained data integrations and data pipelines powering our Data Warehouse, our Looker data models and dashboards. You'll get to utilize our modern BI stack as part of your work (Python, Looker, Snowflake, Airflow, AWS, Kafka, Github).\nWhat we offer:  Complex environment with tons of data just waiting to be utilized \u2014 you\u2019ll get hands-on experience in working on various projects, tools, and datasets. You can choose the ways of working - you can work 100% remote, hybrid with occasional visits to our tech hubs in Helsinki, Berlin, Stockholm or onsite. You would get to work in a company culture where we take ownership beyond the obvious, do common things uncommonly well, think big but stay humble, do right by people, treat others kindly and justly, and recognize that if we don\u2019t learn, we won\u2019t stay still but fall behind and keep in mind that Luke was Yoda\u2019s greatest achievement. Read more about how we work.\nOur humble expectationsOur humble expectations  Plenty of experience working as a BI Developer, Analytics Engineer or Data Engineer. Strong hands-on experience with data integrations, data pipelines, data models, and dashboards. Tech skills: Python, SQL, Airflow, Kafka, AWS, and one of the modern BI tools (Tableau, Power BI, Looker or similar). Since you\u2019ll be taking care of our internal stakeholders, we\u2019re looking for someone who truly enjoys interacting with people on a daily basis. The ability to search for information and ask relevant questions from various teams will be crucial.\nFAQ:  I\u2019ve never worked with workflow automation tools like Airflow or Azkaban before. Is this a blocker for me to be an Analytics Engineer?\nYou\u2019ll get to build and maintain data pipelines, which will require you to work with Airflow on a regular basis. Experience with such tools is highly appreciated but not a must as we are willing to teach you. All you need is the desire to learn, and learning will be even easier if you have worked with Python before.  What is the split of dashboard development and data plumbing tasks? \nFocus of this role is on building the basis for reporting needs, hence majority of the tasks will be related to creating datasets, wrangling data and implementing metrics. At the same time, there will be opportunities to create dashboards in order to serve the needs of stakeholders.  Will I work with raw data or participate in data collection?\nNext StepsOur offering to you Lots of room to build the direction of analytics at Wolt. Our Product and Operations organizations will be growing too, meaning that you have the chance to build the team around you and shape the way the organization works with data and analytics. You can choose the location from our tech hubs Helsinki, Berlin or Stockholm. You have the chance to decide the ways of working - a hybrid, at the office, or remote within the locations above. \ud83d\udc99 Read more about our remote setup. In addition to our country-specific benefits, our compensation package includes a monthly salary based on your expertise and equity. The latter makes it exceptionally easy to be excited about our company growing and doing well, as you'll own a piece of the pie. \ud83d\ude80You would get to work in a company culture where we take ownership beyond the obvious, do common things uncommonly well, we think big but stay humble, do right by people, we treat others kindly and justly, recognise that if we don\u2019t learn, we won\u2019t stay still but fall behind and keep in mind that Luke was Yoda\u2019s greatest achievement. Read more about how we work. \ud83e\udd29 \nNext stepsThe position will be filled as soon as we find the right person, so make sure to apply as soon as you realise you really, really want to join us!If you want to check up on your application or have any further questions about the position you can turn to Group Talent Acquisition Partner \/ Analytics, Michal Szafraniec at michal.szafraniec@wolt.comAbout WoltWolt is a technology company that makes it incredibly easy to discover and get the best restaurants, grocery stores and other local shops delivered to your home or office. Wolt is not just a delivery app \u2013 we\u2019re a technology company building a commerce platform to seamlessly connect our millions of customers with thousands of merchant and courier partners, in real-time across 23 countries and 250+ cities. Our apps (iOS and Android) have the industry\u2019s highest ratings, largely thanks to our customer-first-mindset, which shows in how we build products and run operations. In June 2022 we officially joined forces with DoorDash. Combined, we have a presence in 27 countries, 23 of which operate with the Wolt brand and app. Wolt and DoorDash continue largely independently, with Wolt\u2019s name, brand, product, technology and team.Our Commitment to Diversity, Equity & InclusionWe want to have all sorts of people in our team \u2013 people like you and me, and people different from you and me. To be able to work with diverse teammates \u2013 when it comes to gender, age, ethnicity, life background, sexual orientation, political views, religion, or any other personal trait \u2013 we consciously aim to offer equal opportunity for everyone to work with us. This is because we believe diverse teams make the most thought-through decisions and build things in the most inclusive way.Join us today to build Wolt together!The position will be filled as soon as we find the right person, so make sure to apply as soon as you realize you really, really want to join us!The compensation will be a negotiable combination of monthly pay and DoorDash RSUs. The latter makes it exceptionally easy to be excited about our company growing and doing well, as you\u2019ll own a piece of the pie.For any further questions about the position, you can turn to Product+ Talent Acquisition Partner - Michal SzafraniecAbout WoltWolt is a technology company that makes it incredibly easy to discover and get the best restaurants, grocery stores and other local shops delivered to your home or office. Wolt is not just a delivery app \u2013 we\u2019re a technology company building a commerce platform to seamlessly connect our millions of customers with thousands of merchant and courier partners, in real-time across 23 countries and 250+ cities. Our apps (iOS and Android) have the industry\u2019s highest ratings, largely thanks to our customer-first-mindset, which shows in how we build products and run operations. In June 2022 we officially joined forces with DoorDash. Combined, we have a presence in 27 countries, 23 of which operate with the Wolt brand and app. Wolt and DoorDash continue largely independently, with Wolt\u2019s name, brand, product, technology and team.Working in Product Development at WoltAt Wolt, we\u2019re about getting things done. You\u2019ll probably enjoy it here if you like taking ownership, developing yourself and being around friendly, humble and ambitious people.The behind the scenes of Wolt is run by an awesome bunch of over 400+ planners, builders, designers and data crunchers. We call ourselves Product+, as we\u2019re the very core of Wolt\u2019s products, tools and platforms. To build our products, we work in over 40 cross-functional, independent and autonomous teams. Teams are made up of a mix of talented individuals: engineers, designers, data scientists, analysts, and product leads. Each team takes ownership for solving customer problems in the best possible way.Our Commitment to Diversity, Equity & InclusionWe want to have all sorts of people in our team \u2013 people like you and me, and people different from you and me. To be able to work with diverse teammates \u2013 when it comes to gender, age, ethnicity, life background, sexual orientation, political views, religion, or any other personal trait \u2013 we consciously aim to offer equal opportunity for everyone to work with us. This is because we believe diverse teams make the most thought-through decisions and build things in the most inclusive way.Join us today to build Wolt together!"}
{"job_title":"Data Engineer","company_name":"Zurich Insurance","location":"Barcelona, Catalonia, Spain (Remote)","job_link":"\/jobs\/view\/3731984061\/?eBP=CwEAAAGMPGxik4ht7Cdly8zC3kf9gdH-sOOYt-SI911tzHXRMr_-6lhCBsQOqsjweQaurdXxLrekhUypgpliEMyD_fovQ-NDLc1W9UNQMiANfbesH8_BROw3CwHYv6cd1cVG1fQmFQSWb8p5zHvsultXvYHBHPkIlZLjfT-A7hAJo88dnUp9LPay4GrNypJMZ9oHNCJIbmlnma23CEkCCKVLkArAsjB04Rv6g6OUEunU1w0eX2AWTo8nBYI8u0L2a3HkPFBc4PlivY1Wtvlp0FlSPRdtJzbfx6ZaQGBqfT74HKoCQ3nlkS2pBUTYUVXcPqjxKyvtmGdcNb7gJeUqAwpP_VYuO92bTne2hPugAMbKUhYKHrtWsz5XYJ2PPEXlFg&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=V9f2rqOerHL7e3NYqzVp9g%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3731984061","job_description":"About the job\n            \n \nOur opportunity We are seeking a highly motivated and skilled senior data engineer to join our international Business Technology Solutions organization.In this role, you will be responsible for supporting Actuarial applications. You will be responsible for building new and enhancing existing applications with SQL, making sure they run in a robust and performant manner. Solutions will be developed for both local and global customers, working with both cloud and on-premise solutions.You will proactively expand your expertise in both existing and new functionalities, along with best practices in the relevant space, applying these learnings in your daily job. Your role Responsibilities As a Data Engineer your main responsibilities will involve   Manage SQL development , able to read and execute SQL execution plan  Maintaining and optimization of SQL DB  Maintain and execute SSIS integration services.  Build reports, dynamic queries using SSRS  Manage the solution components and dependencies with other upstream and downstream systems  Maintain alignment of the solution with application development and security best practices  Support in testing and validation of changes.  Oversee issue resolution.  Participate in defect triages \nSkills Your Skills and Experience  As a Data Engineer your skills and qualifications will ideally include:   University level education or equivalent.  Advanced level of English.  Strong knowledge of MS SQL (developer able to read and execute SQL execution plan, housekeeping , monitoring the db , optimization \u2013 performance management, new implementation).  Understanding of SSIS: ETL processes, automation of process execution , troubleshooting , understand dynamic SQL query execution.  Understanding of SSRS : build report, write dynamic queries and troubleshoot the repot.  Understanding of SSAS: DAX , MDX \u2013 Tabular cubes , how to trouble shoot in analysis services.  Support Power BI: report building and troubleshooting, deployment and review of PBI configuration.  Nice to have understanding of .net , c sharp, API , understating of CICD deployments.  Nice to have Basic Actuarial knowledge .  Nice to have Basic understating of Azure.  Soft skills + understating of ITIL principles.  Basic understanding of Agile methodologies.  Team collaboration skills  Analytical and problem-solving capabilities \nAdditional Information As well as a competitive salary and a yearly bonus we offer benefits package which includes:   Option to work remotely within Spain even up to 100% - you choose  Flexible working hours  Wide range of internal and external trainings  Free English and Spanish classes depending on the needs  Ticket restaurant  Life Insurance  Pension Plan - after 1 year in the company  Referral bonus if you bring other talented people like you  Special banking and insurance conditions  Exclusive Employees discounts \nPrimary work location is Barcelona, Poblenou. Option to telework from any location within Spain territory is also feasible.We are looking forward to receiving your application!Please apply with your CV in English.Who We AreLooking for a challenging and inspiring work environment where you can make a difference? At Zurich millions of individuals and businesses place their trust in our products and services every day. Our 53,000 employees worldwide form the basis of our success, enabling, businesses and communities to face a world of risk with confidence. Imagine if you could help people do this all over the world. You\u2019d give them confidence and reassurance by protecting what they love most. It\u2019s a big challenge, but you will be supported by a world-class team who believe in helping you to reach your full potential and deliver on our promises.So be challenged. Be inspired. Help us make a difference.At Zurich we are an equal opportunity employer. We attract and retain the best qualified individuals available, without regard to race\/ethnicity, religion, gender, sexual orientation, age or disability.You are the heart & soul of Zurich! At Zurich, we like to think outside the box and challenge the status quo. We take an optimistic approach by focusing on the positives and constantly asking What can go right?We highly value the experience and know-how of our employees and offer a wide range of opportunities across business areas to encourage you to apply for new opportunities within Zurich when you are ready for your next career step.Let\u2019s continue to grow together! Location(s): ES - Barcelona Remote working: Schedule: Full TimeRecruiter name: Alvaro Gallego Zazo"}
{"job_title":"Data Engineer","company_name":"Akkodis","location":"Bulgaria (Remote)","job_link":"\/jobs\/view\/3765414948\/?eBP=CwEAAAGMPGxikycDI7BXobHYpGSTt_16dRkKnQj2yz5pFz4puHTzATshVl_vz3daRyQvXXL1u8wtERluvcTbzuQQ92LDKteS5Cp-YNAuo1FRdaPOZDyaIkIA4p2wVVpYhRYRdNb0NMVhMh_TRzyvQLr3cNR4TiNVWBILTbTZhuYUhUFFKvIToe5ILDtt9N9_gpa4RSF7Gkn28XUrwWk4AFy9f4YCoF2-Gk40jl7Gp2-eNWjwiDHcM3ESE9GPkIQroPUtPkU7GpMCcxENh7PKx8B7sBHO4dvnbhArF3-wtTwsGmfwpuEVoVJf_TWKJEq7eu_Nd4ZFUCCzLHbNsrN5qTkOS9aboIO7VGYLPiJzXE3HQJGtow_N3tmSUkxDcLnxizx3&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=T6xyUihpJhPGOwTiA18eKQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3765414948","job_description":"About the job\n            \n \nAbout Akkodis:Akkodis (formerly Modis), is a global leader in the engineering and R&D market that is leveraging the power of connected data to accelerate innovation and digital transformation.With more than 17 years of experience in Bulgaria, we deliver technology solutions in IT, Software, Cloud, and Digital fields. We have around 1200 employees in our two office locations and now we are looking for more talents to join us in our mission of engineering a smarter future.Position Highlights:We are seeking a skilled and experienced Data Engineer to join our team. The ideal candidate will be deeply involved in discovering, analyzing, and assembling large and complex data sets. They will design and build our big data infrastructure, ensure data security, and optimize the performance of our big data platforms, primarily within the AWS cloud environment.Main Responsibilities: Discover, analyze, and assemble large, complex data sets to meet functional and non-functional business requirementsDesign, build, optimize, and maintain robust 'big data' data pipelines, architectures, and datasetsBuild scalable ETL pipelines for various data sources using Python in the AWS\/Azure ecosystemEngage with AWS services including AWS Lambda, Amazon EventBridge, Amazon S3, Amazon Kinesis, and AWS Step FunctionsImplement and manage ELK stack or OpenSearch-based platformsEnsure robust data security measures and access controls are implemented across our AWS data infrastructureCollaborate with team members to improve existing systems, streamline processes, and drive data-related initiativesUnderstand and leverage the architecture of data warehouses for optimal performanceTroubleshoot and resolve data issues, ensuring data accuracy and reliabilityCollaborate effectively with cross-functional teams, presenting data findings and insights when required\nRequirements: 4+ years of experience in building, optimizing and maintaining big data pipelines and architecturesStrong proficiency in PythonExperience with ELK stack or OpenSearch platformsFamiliarity with AWS services (such as AWS Lambda, Amazon S3, Amazon EventBridge, Amazon Kinesis, and AWS Step Functions) or Azure (optional)Hands-on experience with ETL pipeline construction in an AWS\/Azure environmentSolid understanding of data security and implementing access controls in the AWS\/Azure cloud platformA clear grasp of Data Warehouse architecture conceptsExceptional problem-solving, analytical skills, and a knack for troubleshooting complex data challengesStrong interpersonal skills with a demonstrated ability to communicate data findings clearly to both technical and non-technical audiencesTeam player with the ability to collaborate effectively in a diverse environment\nYou will get: Competitive remuneration packageReferral bonus program25 days of annual paid leaveAdditional health insurance (outpatient & hospital medical care, dental care, coverage of dioptric glasses, and more)Free Psychological Counselling via Green line and on the spotNewborn or newly adopted child bonusFood vouchers - 150 BGN\/monthUpskilling & reskilling training programs and e-learning hubDiverse career growth opportunitiesRecognition awardsSports cards (partially covered by the employer) and company sports initiativesSpecial company discountsVarious social and charity initiatives\nUnited by our passion for talent and technology, we look at the world differently. The future won\u2019t wait, it\u2019s time to make incredible happen. Are you ready?"}
{"job_title":"AWS Data Engineer","company_name":"InterEx Group","location":"Sweden (Remote)","job_link":"\/jobs\/view\/3765431120\/?eBP=CwEAAAGMPGxik0UQD7Qe6zqV6CPWLsaV7-le55O1eOEblCN3ic1cugT-r2gyQ_pmr-A94iNMD6-fXM-Q7NfWDiSLJxSte7wPD5Bzihl2UvZG-e43irshLfJXEoHdVM6RXDET_xN3ojV9NnYPaAH2uCpwSPJ5Ko8SMC9qVBMcJ9CO0ykjCgFYMvVGgDJO9xpyze_C_74LiIFR2N3hnYPFQn4IsEDQi0aV7Y0VipkKngZQnoe3PvqbqmDBqCN-kr_9g5pIca_zDO60D3AyWv8tW-Nqh7u9cuSd9t_ngQJFfE02gwDvzbBF9OENWfBHJD8XESORQxDtLS3VdOdzXoHM7MBNBpmowYU9IeYJNRqyETuVWNUBdMHh6inzMpD2tItWwNkX&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=xU5%2BckE85hYpWAPvZmeFhQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3765431120","job_description":"About the job\n            \n \nThis client, we are growing our Data & Analytics footprint. As our new Senior Data Engineer, you will collaborate with product owners, architects and other key profiles across the global organisation helping business verticals and clusters maximise the value of our data and drive business change as an impact of this.You will be responsible for delivering value-add products, ensuring high success rates as well as be an ambassador that data quality is always a priority. Your primary focus will be designing, building and implementing scalable data products on our global data platform and to secure ownership and stability of the products. Qualifications and Skills: The tech stack needed are: Data EngineeringExperience using an IDE for ETLPythonSQLCloud (AWS)Big Data TechData Modelling & Data Warehouse experienceExperience working within scrum and in an agile team\nPreferably you would be someone with strong experience in ETL processes and data pipelines."}
{"job_title":"Data Engineer","company_name":"Fever","location":"Madrid, Community of Madrid, Spain (Remote)","job_link":"\/jobs\/view\/3757554580\/?eBP=JOB_SEARCH_ORGANIC&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=vkHeWa4jcrp9oXfX7U2VZA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3757554580","job_description":"About the job\n            \n \nHi, we're FeverWe're excited you are checking out this job offer.We are the leading global live-entertainment discovery tech platform with a clear mission: to democratize access to culture and entertainment. How do we achieve our mission? Fever has developed a proprietary technology that inspires a global community of over 125M people through personalized and curated experiences in their local city whilst empowering entertainment and event creators to reach new audiences and enhance their experience.Sounds amazing, right?Behind the user-friendly iOS and Android apps and webpage that work across the world is the engineering team. We are in charge of creating, developing, improving, and maintaining all Fever services so that more people can have an amazing experience.About The Role You'll be part of the Data organization, building and operating the core technologies that enable data scientists, analysts and the different business units to leverage rich data in efficient and innovative ways to generate impact and connect people to the most relevant real-world experiences. You'll own critical data pipelines for our Data Warehouse and the resulting data products that are used daily across the company to inform all sorts of decisions and models. You'll ideate and implement tools and processes that increase our ability to exploit our diverse sources of data to solve business problems, understand behaviors, \u2026You'll work with the latest Big Data and Machine Learning technologies to enable new use cases and continuous innovation. \nOn your first month in Fever: You will be fully integrated into the team. During this month you will have already participated in onboarding, pair programming, one to one, Scrum sessions, and you will have met the different departments at FeverYou will get familiar with Fever's tech stack and frameworks used to develop our data strategyYou will attend some of the Fever Original's experiences like Candlelight\nAfter 3 months in Fever: You'll be able to come up with solutions to new difficult problems and you'll be generating impact and creating new business opportunities. You'll have responsibilities and ownership over parts of our Data Warehouse or other critical tools. You will participate in some of the hackdays or hackathons we organise with other teams, and you will mostly know everybody from the data and engineering communities. \nOn your 6th month in Fever: You'll contribute to the overall health of our data ecosystem, improving performance, scalability, robustness, \u2026You'll be able to identify gaps in our platforms and processes and be a champion for continuous improvementYou'll be mentoring other new joiners to the teamYou will participate in some of the team buildings we organise for your team or the whole engineering team\nKey Responsibilities  Build trusted data assets that power Fever's decision makingHave a business-oriented mindset and create data automatization to create huge business opportunitiesDesign, build and support modern and scalable data infrastructure, e.g.: Write robust, maintainable code to orchestrate our ETL workflows. Build data quality monitoring processesBuild data tools to make our analysts and scientists more efficient\nCollaborate with other engineers, and stakeholders to understand what data is required and how best to make it available in our Data Platform. Understand the technical trade offs of different solutions, implement them and make them scalable\nAbout You You are smart, get stuff done, have great energy, and thrive in a fast paced environmentYou are an expert working with large volumes of data from multiple sources, both internal and external (e.g. APIs)You are comfortable with software engineering best practices and you are proud to write robust, readable and maintainable code. You are an expert in Python3 and its data ecosystem (e.g. Pandas, Pyspark)Strong knowledge of SQL (PostgreSQL, Snowflake, \u2026)Experience with AWS (S3, EC2, RDS, \u2026)You are proficient in business English\nIt would be a plus if you... You have worked with Airflow or similar tools. You have worked in a multidisciplinary team working with roles such as data analysts, data scientists, marketing or product managers. You are familiar with tools and processes for reproducible, production-ready ML applications (e.g. data logging, ML workflows, model serving). You have worked with the API of the most popular marketing tools (Facebook, Google, Instagram, etc.)You have built data-powered tools either in a professional setting or as passion projects. \nBenefits & Perks Attractive compensation package consisting of base salary and the potential to earn a significant bonus for top performance. Stock options. Opportunity to have a real impact in a high-growth global category leader40% discount on all Fever events and experiencesHome office friendlyResponsibility from day one and professional and personal growthGreat work environment with a young, international team of talented people to work with!Health insurance and other benefits such as Flexible remuneration with a 100% tax exemption through Cobee. English LessonsGympass MembershipPossibility to receive in advance part of your salary by Payflow. \nThank you for considering joining Fever. We cannot wait to learn more about you!If you want to learn more about us: Fever's Blog | Tech.Eu |TechCrunchFever is committed to creating an inclusive and diverse workspace where everyone's background and ideas count. Our main goal is to find the best possible talent regardless of place of birth, racial or ethnic origin, gender, gender identity, religion, opinion, sexual orientation, disability, pregnancy, marital status, age or caring responsibilities. We encourage everyone to apply!If you require any kind of accommodation during the selection process please contact our Talent team so we can help you by providing a welcoming and seamless journey.If you want to know more about how Fever processes your personal data, click here Fever - Candidate Privacy Notice"}
{"job_title":"Data Engineer (Python)","company_name":"Reward Gateway","location":"Bulgaria (Remote)","job_link":"\/jobs\/view\/3765423601\/?eBP=CwEAAAGMPGxik-mUV4ucVyOD5kWtF2Sk0k_vXF-jvPbUKFOnreCu0EPtNM5_9z3N-9cbLqjJSEOIGUpRaClFeK7305KpO59mjO2pcwizGdAirv4wyBSGKCJ5ROPdkNNzfgEuMHVHRlo0Q-aLah6B2bO3RD3h9QsZlnRjgLq3nWbk5L3JkkFKuVfyYRt5yhOw58ETX2rTimqjG0z-qE_rTQPNW_KS9fzpksZHb6zsOtXX28s5Y-3UFe8yNstk3gqOH5V10Qg74bwMydBCqC4c7wDituOhFUtPpBfnNtwuSealnz37jlTaCwIHNoBOsgu8JqaR0J_JZTANSVDTp6iqT8ZEN92HgVONA6RDvWRtvhPmIDbswm1RRAAWuLO6vLiBiA&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=q0BQIQAqbIu%2BLXMM342mNQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3765423601","job_description":"About the job\n            \n \nAt Reward Gateway, we\u2019re driven by our mission to \u201cmake the world a better place to work.\u201d Across the globe over 750 of us work together to bring this to life through our products and technology. We help our 4000+ clients and their leaders to transform employee experience that will attract, engage and retain top talent through employee benefits, strategic reward and recognition, well-being, and much more.We are looking for a Data Engineer to join the newly formed Data Team at Reward Gateway. You will work closely with the Head of Data, to define and build the core of the new Data Platform. You will be responsible for monitoring and maintaining data pipelines, ensuring that data flows into our centralized data platform from multiple sources. You will work with Analysts within the Data team and wider business, to ensure that the core data platform can be used to drive decision-making across the business.Key Responsibilities: Help to design and build the core data platformMonitor and support issues identified in the day-to-day running of the data pipelinesCollaborate to develop and implement coding standards and best practices across the data team, to ensure code quality, readability, and maintainabilityCreate and maintain data testing frameworks and procedures to validate data quality, integrity, and accuracyWork closely with Analysts to deliver business value on the top of the core data platform\nExperience and Skills we need: Excellent practical knowledge of Python and SQLKnowledge of PHP would be advantageousExperience designing, building, and delivering Data Products to support different business functionsExperience working on cloud platforms and databases, ideally with AWS\nThe Interview Process: A video interview with the Senior Talent Partner and the Head of Data. This should last no longer than 40 minutes.A final video interview with the Head of Data and Head of Development.\nBe comfortable. Be you.At Reward Gateway, we want all of our employees to feel comfortable bringing their passion, creativity and individuality to work. We value all cultures, backgrounds and experiences, as we truly believe that diversity drives innovation. Express yourself, join our community and help us Make the World a Better Place to Work.We hire BETTER. From perks to people, our BETTER approach to hiring earns us more trust, happier people and more world-class talent that help us to make the world a better place to work. Find out more about Reward Gateways approach to benefits, equality, talent, technology, empathy and what you\u2019ll get in return for joining our Mission at rg.co\/lifeatrg."}
{"job_title":"Lead Data Engineer","company_name":"Thoughtworks","location":"Hamburg, Hamburg, Germany (Remote)","job_link":"\/jobs\/view\/3764088487\/?eBP=CwEAAAGMPGxik0RrahrSpVq_vEsytEDxip-H-0TeYHw1I118MwOCx0lHGjfRgIkhhw7zLd2Hs1zfOyhSGC8fNREhn4pjAeuCU40bJGAmZHLRFyyd6syC91emn43FoeRzlZ7lkiy71fPGQtWCNf4z1EDjCsfYWgP8ioOIskLX7LqFHRxHI5e8etzqmGdJlp1zH_yyeN00JGGc28nM2BIqR2Wd5dwLMwCpVhZmzIGCyjQdZdNbb6UQVIOetKDeWW1M9hhxfQ7BHXJbft-rw0omwHtlrDA_Fb-gC7S0M8296TJ6sM44uQ4Yaa1ajOAelQz-8IuimM1SfKHyq6Kg84Unjxw8hmGAD90bIAxNL_ck1jXrVrbU1lVzUg2b5lAjRVUM7BfU&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=TAmpK%2BzXAOG0t0nwXNfXIw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3764088487","job_description":"About the job\n            \n \nLead data engineers at Thoughtworks develop modern data architecture approaches to meet key business objectives and provide end-to-end data solutions. They might spend a few weeks with a new client on a deep technical review or a complete organizational review, helping them to understand the potential that data brings to solve their most pressing problems. On projects, they will be acting as the architect, leading the design of technical solutions, or perhaps overseeing a program inception to build a new product. Alognside hands-on coding, they are tech-leading the team to implement the solution.Job responsibilities You will be leading the design of technical solutions and overseeing a program inception to build a new product.You will be responsible to create, design & develop intricate data processing pipelines, addressing our clients' most challenging problems.You will collaborate with Data Scientists in order to design scalable implementations of their models.You will pair to write clean and iterative code based on TDD and leverage various continuous delivery practices to deploy, support and operate data pipelines.You will lead and advise clients on how to use different distributed storage and computing technologies from the plethora of options available.You will design, develop and operate modern data architecture approaches to meet key business objectives and provide end-to-end data solutions.You will develop data models by selecting from a variety of modeling techniques and implementing the chosen data model using the appropriate technology stack.You will be responsible for data governance, data security, data privacy to support business and compliance requirements.You will seamlessly incorporate data quality into your day-to-day work as well as into the delivery process.You will ensure a smooth collaboration within Thoughtworks\u2019 team as well as with the client\u2019s teams, encouraging open communication and advocating for shared outcomes\nJob QualificationsTechnical Skills You have experience in leading the design of technical solutions and overseeing a program inception to build a new product.Working with data excites you: you have created Big data architecture, you can build and operate data pipelines, and maintain data storage, all within distributed systems.You have hands-on experience of data modeling and data engineering tools and platforms such as Kafka, Spark, and Hadoop.You have experience in writing clean, high-quality code using the preferred programming language.You have built & deployed large-scale data pipelines and data-centric applications using any of the distributed storage platforms and distributed processing platforms in a production setting.You have hands on experience in data platforms (Cloudera\/Hortonworks etc) and cloud based hadoop distributions.You have experience with data-driven approaches and can apply data security & privacy strategy to solve business problemsYou have hands-on experience with data infrastructure and operations working in cloud environments.You have experience with different types of databases (like, NoSQL, data lake, data schemas etc)\nProfessional Skills You understand the importance of stakeholder management and can easily liaise between clients and other key stakeholders throughout projects, ensuring buy-in and gaining trust along the way.You are resilient in ambiguous situations and can adapt your role to approach challenges from multiple perspectives; You don\u2019t shy away from risks or conflicts, instead you take them on and skillfully manage them.You are eager to coach, mentor and motivate others and you aspire to influence teammates to take positive action and accountability for their work.You enjoy influencing others and always advocate for technical excellence while being open to change when needed.You are a proven leader with a track record of encouraging teammates in their professional development and relationshipsCultivating strong partnerships comes naturally to you: you understand the importance of relationship building and how it can bring new opportunities to our business.\nOther things to knowLearning & DevelopmentThere is no one-size-fits-all career path at Thoughtworks: however you want to develop your career is entirely up to you. But we also balance autonomy with the strength of our cultivation culture. This means your career is supported by interactive tools, numerous development programs and teammates who want to help you grow. We see value in helping each other be our best and that extends to empowering our employees in their career journeys.About ThoughtworksThoughtworks is a global technology consultancy that integrates strategy, design and engineering to drive digital innovation. For 30+ years, our clients have trusted our autonomous teams to build solutions that look past the obvious. Here, computer science grads come together with seasoned technologists, self-taught developers, midlife career changers and more to learn from and challenge each other. Career journeys flourish with the strength of our cultivation culture, which has won numerous awards around the world.Join Thoughtworks and thrive. Together, our extra curiosity, innovation, passion and dedication overcomes ordinary."}
{"job_title":"Big Data Engineer (Java, AI, ML, Big Data, Data driven) - Frankfurt am Main, fully remote","company_name":"Optimus Search","location":"Frankfurt am Main, Hesse, Germany (Remote)","job_link":"\/jobs\/view\/3767968785\/?eBP=CwEAAAGMPGxik_kWiemgpOyChB5KbKHzuVuypG8aVqPjgC3lIo42-_2kY8tXuO4lyAQ5F7281U5AZ91ZQVD2SQnPqFCVXFUNLF--rYEW4AxNnjIPai2-piFcDP8dUYy7q2dioR9B1npl9H4fyzpNVkB_sgDhQ6GAqF-yZSShS-c-9aewQsHhhBazOfVLwLo81rOjKcRtY6ZG5x91Sjf4BvNCuQYtRZWV8UajPQ1mWZeaWKDDUSrx7OU7S-sqz1_Ods-y3IFUJ9kG-MxGcm7p_A7G_P6QT-PMj5n_cR-q_5XT4BGKT2AXfemVIfyd1APCWlPfVtqHksPH3jU8nveYtUu6l75mv_F3f4Q4GasK0SfBAvgWGbSqBX1B3cAEXWbzfg&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=6oXhNnpaBOmUHzzCsfkHJQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3767968785","job_description":"About the job\n            \n \nBig Data Engineer (Java, AI, ML, Big Data, Data driven) - Frankfurt am Main, fully remoteAre you an experienced Data Engineer looking for a new challenge? Here's a fantastic opportunity to join a leading software company based in Frankfurt. You can choose to work either onsite or fully remote. This company is renowned for its excellence in digital advertising and is now seeking a Data Engineer to play a pivotal role in advancing their core system using cutting-edge technologies.The data team at this company is responsible for managing the data layer framework, which includes building reporting frameworks for AI, data scientists, and self-serve users. This role offers a unique chance to work in a globally scaled environment as part of an R&D group focused on developing a complex and innovative platform. To put it in perspective, they handle up to 120 billion requests every single day!Key Responsibilities: Utilize your 3+ years of data engineering experience to drive development, with proficiency in Java (ideally also Python).Work with technologies such as Pipelines, ETLs, Hadoop, Spark, Kafka, and Streaming systems.Manage data using SQL and NoSQL databases.Demonstrate expertise in Linux, Docker, and Container Orchestration.\nThis company boasts a remarkable team of brilliant and friendly individuals who are passionate about their work and fostering a vibrant company culture. They prioritize continuous learning, which is reflected in their employees' long-term commitment to the organization.As the successful candidate, you can expect a competitive salary in the range of \u20ac70,000-90,000, depending on your experience level, with the potential to grow into a Lead Developer role.Don't miss out on this exciting opportunity to be part of a forward-thinking team in a rapidly evolving industry. Apply now to embark on the next chapter of your career!Keywords: AI, Big Data, Machine Learning, Cloud, Agile, scalability, stability, Kubernetes, Azure, Java, Elastic Search, MongoDB, Gitlab, Kafka, Scala, Python, Docker, Linux, Hadoop, Spark, Kafka, artificial intelligence, Data"}
{"job_title":"Cloud Data Engineer","company_name":"BSG","location":"Italy (Remote)","job_link":"\/jobs\/view\/3767621796\/?eBP=CwEAAAGMPGxik7ACAdLeH9tKW7QQDEkRmpI-XjuL1e5AlWPSYTq_srsBJuQVFqxmmyaoeW1KUKFwYfwL1rx1jerLhbHQB6ZNDJQXYb43atXDF5JZ2Y8Z_2o840b1buI4kEB5B3CAXmz9rs_lteB5CxjfX_Cad5NZGCve2Lns4YVPFMGW7a5JTzLMB43hV4HGiTQRFTRSEVrZvuzPvKxDNwSHImZC9_tKZPCdhH2OGIdvh-0aqXOqb9llDkiy-GMoizJcN4vQY-phK7nI8cNqmB1x9-YUBup0Mf8JELz08SYIJ8qycIWsEL3CZ0NrfR6XnvNtnswQ3RB8UnudcgdldUnFzz-6jAPTUgf2IUZbSlxeEKECpvElziV85NUuy9_NxC5m&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=pqWjG4zZZ4gXGgoFEKZHcw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3767621796","job_description":"About the job\n            \n \nYou will be involved in the development of comprehensive Azure solutions, contributing to the definition of solutions through full involvement in all phases of project management: Analysis, Design, Test, Build and Deploy. Responsibilities: Design and development of ingestion processesDesign and implementation of ETL flows (es. Azure Data Factory, Databricks, Glue, DataFlow,...)Design and Development of solutions based on Data Lake, Lakehouse and relational Database (es. SQL DB, Azure Synapse, Delta Lake, Redshift, Aurora, BigQuery, ....)Design and Development of notebooks using Python and\/or Spark\n Skills: At least 3 years\u2019 experience in Data & Analytics Projects on Cloud Data Platform (Azure)Excellent communication, analytical and problem-solving skillsGood level of English\nNice to have: Experience in Data & Analytics Projects on AWS and Google Cloud Platform\nWhat we offer: Permanent ContractRemote WorkingCertificate courses"}
{"job_title":"Senior Data Engineer","company_name":"Facephi","location":"Madrid, Community of Madrid, Spain (Remote)","job_link":"\/jobs\/view\/3765792536\/?eBP=CwEAAAGMPGxik5OLFnZ74gWuHMYgsUqSpsxH1SxbnRmq6kAiNbG6Dvi7RXfxevJoSS2iv1rmZauKOJy0JJZ2IrwhidIh_uYi56dXnUpbNKDX8z99bShAniIQ69VP1xwjrX4VCfxO6AEk1v9ldAP7Q5nRHlk-M8TNcvKaFv3iKX0WmijBPlxGAVSqNymyGw6VZ-TFXcqXNMeQWWShBzZgkT5hYXNdLr03k6SXmljrujv4dp4tBxOSbHVvJKEvPgjQXcINKAK5L4f9FbTFvnlG9_EXAzTMxvs6gpip4-JG74zCF46n9DO8re5RVqUgO4Zl2I-yPCXLbgBzdzRcH9oCBapLVEKXpF-P5xLDHAT4zBz80H7HGN6NElSX4t0pboZJlh1v&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=iXq%2FObrODmYFzqNGkye%2BKw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3765792536","job_description":"About the job\n            \n \n\u00bfQuieres una oportunidad para formar parte de nuestro equipo de Producto?\u00bfTe gustan los retos?Pues esta es tu oportunidad...En Facephi, estamos buscando nuevos\/as compa\u00f1eros\/as con experiencia en posiciones similares a Data Engineer para que se unan a nuestra gran familia. Si tienes ganas de a\u00f1adir valor al equipo y asumir nuevos retos que se te ir\u00e1n presentando, \u00a1ven a conocernos!\ud83d\udc49 \u00bfCu\u00e1les ser\u00e1n tus funciones? Dise\u00f1o e implementaci\u00f3n de arquitecturas escalables de explotaci\u00f3n de datos procesar, transformar y agregar datos de diversas fuentes en formato Batch, Near Real Time, y Real Time.Proponer y testear nuevos frameworks y servicios.Definici\u00f3n e implementaci\u00f3n de ETLs.Creaci\u00f3n de modelos con DBT.Definici\u00f3n de procesos de CI\/CD.Modelado de persistencia de datos en base al patr\u00f3n de arquitectura \u201cMedallion\u201d.Orquestaci\u00f3n de procesos a trav\u00e9s de Apache Airflow.Supervisar continuamente las canalizaciones de datos y los procesos anal\u00edticos para identificar cuellos de botella y \u00e1reas de mejora, garantizando una entrega de datos eficiente y fiable.Negociar y acordar requerimientos con otros miembros de la empresa.Team player is a must.\n\ud83d\udc4c Requisitos m\u00ednimos Al menos 5 a\u00f1os de experiencia en empresas como ingeniero de datos o similar.Alto conocimiento en lenguaje Python y SQL. Deseable Scala.Al menos 3 a\u00f1os de experiencia con Apache Pyspark (deseable conocimiento de Spark Structured Streaming).Deseable experiencia en AWS: Kinesis, Glue, Athena, etc.Deseable experiencia en modelos productos-consumidor: Kafka.Deseable conocimiento en la creaci\u00f3n de modelos con DBT (data build tool).Experiencia con flujos de CI\/CD con GitHub actions.Experiencia con Apache Airflow.Experiencia con Docker.\nValorable:  Conocimientos sobre Apache Iceberg.Experiencia con Azure, GCP.IaaC: conocimientos en Terraform.\n\ud83d\udc99 \u00bfQu\u00e9 ofrecemos? Formar\u00e1s parte de una gran familia integrada por personas con las que trabajar unidas y, de las cuales, poder inspirarte.Equipo innovador, joven y transparente.Estabilidad laboral.Contrato indefinido a tiempo completo.Flexibilidad horaria para conciliar tu vida personal.Plan de teletrabajo.Seguro m\u00e9dico.Plan de carrera especializado.Facephi Corporate Benefits, donde nos complace poder ofrecerte una gran variedad de descuentos en las mejores marcas."}
{"job_title":"Staff Data Engineer (ML\/AI) - Europe, Remote","company_name":"Plentific","location":"Berlin, Berlin, Germany (Remote)","job_link":"\/jobs\/view\/3719620264\/?eBP=JOB_SEARCH_ORGANIC&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=Ur5BXdGzns1e53TuxpUsMQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3719620264","job_description":"About the job\n            \n \nWe're Plentific, the world\u2019s leading real-time property solution, and we're looking for top talent to join our ambitious team. We\u2019re a global company, headquartered in London, and operating across the United Kingdom, Germany and North America.As a B2B company, we're dedicated to helping landlords, letting agents and property managers streamline operations, unlock revenue, increase tenant satisfaction, and remain compliant through our award-winning SaaS technology platform. We also work with SMEs and large service providers, helping them access more work and grow their businesses.We're not just any proptech - we're backed by some of the biggest names in the business, including A\/O PropTech, Highland Europe, Mubadala, RXR Digital Ventures and Target Global and work with some of the world\u2019s most prominent real estate players.But we're not just about business - we're also building stronger communities where people can thrive by ensuring the quality and safety of buildings, supporting decarbonisation through our ESG Retrofit Centre of Excellence and championing diversity across the sector through the Women\u2019s Trade Network. We're committed to creating exceptional experiences for our team members, too. Our culture is open and empowering, and we're always looking for passionate, driven individuals to join us on our mission.So, what's in it for you? A fast-paced, friendly, collaborative and hybrid\/flexible working environmentAmple opportunities for career growth and progressionA multicultural workplace with over 20 nationalities that value diversity, equity, and inclusionPrioritisation of well-being with social events, digital learning, career development programs and much more\nIf you're ready to join a dynamic and innovative team that\u2019s pioneering change in real estate, we'd love to hear from you.The RoleThis is a fully remote position based anywhere in Europe.We are looking for an experienced Staff Software Engineer to join the Data Engineering team. You'll be reporting to the Head of Data Engineering and will have responsibility across large production code bases and will also be tasked with software architecture designs and reviews. The role is heavy hands-on coding, as an individual contributor, with no people management responsibilities, though you will be expected to enjoy mentoring other engineers.The Data Engineering team, alongside the Frontend, Backend and DevOps teams, sits at the centre of everything we do at Plentific and is constantly tackling challenging problems, such as online payments, quoting, invoicing, booking, search \/ scoring algorithms, ETL, data pipelines, in-app messaging, Public APIs, ML\/AI, real-time notifications and fraud prevention.The team has a stronger focus and ownership of the production Machine Learning systems, the data warehouse, Public APIs, real-time data pipelines, LLM's and AI in general, and our flagship interactive analytics module named 'Advanced Analytics'. Almost all code so far is written in Python and SQL.Our tech stack is made of, amongst others: AWS, Kubernetes, Django, PostgreSQL, Snowflake, ElasticSearch, dbt, Looker, scikit-learn, FastAPI, Celery, Jenkins, GitHub.Responsibilities Be the main individual contributor to the most strategic and high impact projects in PlentificOwn and defend the software architecture designs from conception to release, including build vs buy discussionsCollaborate with Product stakeholders, to understand, define, develop and implement scalable, cutting-edge solutions that amaze our customersServe as a tech lead to look up to, providing guidance and mentorship to help develop the skills and talents of othersChampion best coding practices, documentation, reviews, unit and integrations testing, data quality and security, and performance\nRequirementsSkills Excellent Python and SQL skills, but you should be open to picking up other programming languagesA strong interest in learning and developing AI-powered systems (such as LLM-based)A self-starter who assumes responsibility for their work, accepts direction and feedback from co-workers and managers, and happily helps make anyone\u2019s good idea a realityAbility to think out of the box with a can-do attitude to get things done efficientlyExcellent communication skills in English\nExperience And Qualifications 7+ years of relevant experience as a Software EngineerExperience with Machine Learning is a must, since we are heavily expanding our capabilities in this area\nBenefitsAs you can see, we are quickly progressing with our ambitious plans and are eager to grow our team of doers to achieve our vision of managing over 2 million properties through our platform across various countries. You can help us shape the future of property management across the globe. Here\u2019s what we offer: A competitive compensation packageCompany laptopRemote workingLearning management system by SAP Litmos"}
{"job_title":"Data Solution Developer (f\/m)","company_name":"HCLTech","location":"Czechia (Remote)","job_link":"\/jobs\/view\/3767606293\/?eBP=CwEAAAGMPGxik0U100wvpn36R853ydbrHGtWDvr3k3jAs_MWlkTB2n1hsAI-9xXBrpdru2bzs6Z5C5uJ9vcvHsAHzUs0NEXhE3PGDT-vO59r5PrUNGjIGEitnARUIJrwwwrHTgXBJSoGe9UDpM1xpbG0EeUwPfkI-ESDe7icCmkLcTOf_eI8gUS4AqFjsFCDcMY2pC6EPb0pH0ExpgiELMJpmjsSdAK_6KEzQAtv1HIQR75A5bwxvRqbwbIn_hT7UROTxqBNqXWnxa0bw7kegRdQ_Zmb_DXjV6qbUFUO9FjhulI3-Or0adkgz27DwxAYbYJDeKqNmj1uF8qnkPrGxgNilVjLQ88ZvA_i0sNSGYfhYx61NtsqT0Pa7Q8sV2jhhmCA&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=w5D9C5JnV6i3SdDs5ntU1Q%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3767606293","job_description":"About the job\n            \n \nWe are HCLTech, one of the fastest-growing large tech companies in the world and home to 211,000+ people across 52 countries, supercharging progress through industry-leading capabilities centered around Digital, Engineering and Cloud.The driving force behind that work, our people, are diverse, creative, and passionate, raising the bar for excellence on a regular basis. We, in turn, work hard to bring out the best in them as we strive to help them find their spark and become the best version of themselves that they can be.If all this sounds like an environment you\u2019ll thrive in, then you\u2019re in the right place. Join us on our journey in advancing the technological world through innovation and creativity.Location: RemoteYour Role: Contribute to the analysis of maturity gaps within the scope of the Cash Data Services.  Collaborate with central CBT teams and field stakeholders in the analysis of business requirements leading the development and design of data transformation and reports, focusing on assurance controls such as identity management, transfer reconciliation, and anomaly detection.  Design\/development of data transformation and reports focusing on assurance controls (IDM, reconciliation, and anomaly detection). Develop data models and write data-transformation code to validate prototype automated controls. Prepare technical specifications to turn data-transformation into pipelinesIn alignment with IT standards, develop automatic data pipelines, secure data acquisition, data cleaning; Apply data engineer best practices. Liaising with data analysts, infrastructure engineers etc. Assessment of new technologies and innovative approach to data engineeringWriting reports; document business logic; draft Service Agreement with COs\nYour Experience: English language - professional levelAWS - S3, CloudFormation, CloudWatch,.. (must have)LambdaPython (must have)DjangoSQL (must have)PostgreSQL\nDesired Experience:  Tableau OpenShift Glue SageMaker DBT Jupyter Notebook Docker Azure DevOps Sentry Git\n Why Us:  We are one of the fastest growing large tech companies with offices in 60+ countries across the globe and 222,000 employeesOur company is extremely diverse with representation of 165 nationalitiesWe offer the opportunity to work with colleagues across the globeWe offer a virtual-first work environment, promoting a good work-life balance and flexibilityWe are invested in your growth, offering learning and career development opportunities at every level to help you find your sparkWe offer comprehensive benefits for all employeesWe are a certified great place to work and a top employer in 17 countries, offering a positive work environment that values employee recognition and respect"}
{"job_title":"Data Engineer","company_name":"S&P Global","location":"Gda\u0144sk, Pomorskie, Poland (Remote)","job_link":"\/jobs\/view\/3757147966\/?eBP=CwEAAAGMPGxik0ckBVHa7XDCKtPG0l7l02QqjM6Saare7Q8-IbIHiXfXVdWz41wirv6iQv9bgGGR7CpBc5uDpaLkBb0wF_-CsEFhmmUSvz31ZqiWMj6a4SNeNHnfrlc5-8sOGWgjQZ5ysYpX8_z0GxlkOrAu1qhlXRBCNQ-GlDAkOyHiPRgJ2nGLGJoNVSD-ExBlXQlih0hH_cDGQZc6UaHjgaVyFMWzhTKMLzarvmd3jWBa4pZFsBcXK-YsTnB-LmATJTDXjkf1NHmfuO2M1Pim_m8YsGbMzpdQjN2ZwmxMy2Pp_3hQmAo8oXB-dn7Y5NxrT0vBMIXVbCldMI26kMIn7O4SRSPUMkNjUzrREbxEwIyJppPFLFzRbBFHdFgRsw&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=u%2FYqshtmiJyqOOqchO4WxA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3757147966","job_description":"About the job\n            \n \nThe Role: Data Engineer - Carfax Europe.The Team: CARFAX Europe GmbH provides trusted information that helps millions of people to shop, buy, own and sell used cars with more confidence. Our flagship service is our Vehicle History Report, a curriculum vitae for used vehicles to solve the asymmetric information problem in the used car market. Our customers get access to an extensive multinational database consisting of +27 billion historical records related to over 1 billion cars in +20 countries across Europe and North America. Today, we are a team of 100+ people in six European countries \u2013 while retaining a start-up feeling including flat hierarchies and flexible decision-making processes.We are looking for employees who share our vision and who will help us achieve the goal of changing the used car market in Europe for the better.What\u2019s in it for you:  Part of a cross-functional team consisting of software developers, data analysts, and data engineers.A very pleasant working atmosphere in a dynamic, international team.Interesting projects, working with the largest vehicle history database in EU.Flexible remote work options.\nWe\u2019re looking for a person with the following:  At least 3 years working experience in software development or data engineering.At least 1 year experience with AWS data processing and storage tools.Agile practices: pair programming, TDD, CI\/CD, refactoring; breaking abstractions experience is highly appreciated.Basic configuration skills for Kafka or (other event streaming platform)Experience building and configuring consumers and producers for events\/messages.Development experience on JVM platform (Kotlin, Java).Database administration experience.Very good communicator.\n Flexible Working  We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and\/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. Benefits Working with the newest technologiesJob position matched to your experience and expectationsCash Incentive planRecharge - is S&P Global\u2019s flexible time-off approach under which there is no prescribed maximum amount of time off you can takeGlobal Wellbeing Support - S&P Global will reimburse you each year, up to 1500 PLN for wellbeing-related activities, for expenses that help you achieve your own healthy lifestyle \u2013 mind, body and spirit.Five days off for charity\/volunteering5 additional Wellbeing days in yearFree day on birthday and work anniversary Paid parental leave of 26 weeks for all parents10 days of fully paid sick leavesEnglish ClassesOptions to work from homeChillout & fun room (table tennis, table football, Xbox, billiards)Attractive benefits package (private health care, life insurance, MultiSport card)Fruit days, coffee, tea, chocolate"}
{"job_title":"Ingeniero de Datos con PySpark (Remoto)","company_name":"UST Espa\u00f1a & Latam","location":"Spain (Remote)","job_link":"\/jobs\/view\/3765421345\/?eBP=CwEAAAGMPGxikxg_pm9s8kg-iCuxLV7EQwF2Ld9FNX-RVAjuUHHdto019A3rgBzehRHNXXW5JOehphHptRKuIMVCwj9Op_ZbZ1BkpPNUxg-aENs4cAtlowE8UciU92cg7hLLVGR4BMeoFp2T5Wt6zgtewHaJhoahjb6jgRciJHjfuBcBwjpbptLimrAFFQrFsUERA57sMKIa7W28xHe8m2iKJ1e_whsigJthzPgT84l_8FXm9-YBw40HjCmeHYCL_FR7fAuJGjQYcmqD-4w5pwGZB31hfLqpPyGZrtzjDwNOzOfy0kfaiX58BDxqxMvbfefPGfN7w5uGdTQUo71OcW8CNvo47SCDCH5Hynsx49Z_NvH0e9028W33Vd479z-U3EAe&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=Llf2s6i%2BdfgYH7MPr4eIsQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3765421345","job_description":"About the job\n            \n \n\ud83d\ude80 \u00a1Seguimos buscando talento\u2026y nos encantar\u00eda que te unieras a nuestro equipo!Para que nos conozcas algo mejor, UST es una multinacional norteamericana certificada como Top Employer con m\u00e1s de 30.000 empleados a nivel global y con presencia en m\u00e1s de 30 pa\u00edses. Somos l\u00edderes en servicios de tecnolog\u00eda digital y proporcionamos soluciones tecnol\u00f3gicas de gran alcance a grandes compa\u00f1\u00edas.\ud83d\udd0e \u00bfQu\u00e9 buscamos?Estamos buscando un Ingeniero de Datos con al menos 2 a\u00f1os de experiencia trabajando con PySpark e ingestas masivas de datos, para importante cliente del sector de las telecomunicaciones.Valorable y deseable: tener Certificado de Discapacidad (al menos de un 33%).\ud83d\udca1 Requisitos m\u00ednimos: PysparkIngesta masiva de datos en entornos complejosSpark y ScalaConocimientos de lenguajes como Java o PhytonBBDD: SQL y MySQLFormaci\u00f3n en Big Data\n\ud83c\udfa9 Requisitos deseados: Ingl\u00e9s medio alto.\n\ud83d\udcb0 \u00bfQu\u00e9 te ofrecemos?-\u2708\ufe0f 23 d\u00edas laborables de vacaciones y el 24 y 31 de diciembre.-\u2764\ufe0f Numerosos beneficios sociales (seguro m\u00e9dico, ayuda al teletrabajo, seguro de vida y seguro de accidentes).-\ud83c\udf74 Programa de Retribuci\u00f3n Flexible (tarjeta comida, cheques guarder\u00eda, tarjeta transporte, clases de ingl\u00e9s online, seguro m\u00e9dico para tu familia\u2026).-\ud83c\udf93 Acceso gratuito a varias plataformas de formaci\u00f3n.-\ud83d\ude80 Estabilidad y carrera profesional.-\ud83d\udeb6 Tenemos implantado un plan de compensaci\u00f3n de referencias internas.-\ud83d\udd17 Posibilidad de elecci\u00f3n de percibir tu salario en 12 o 14 pagas.-\ud83c\udfe1 Medidas de conciliaci\u00f3n (horario flexible, teletrabajo, asesoramiento de especialistas (psic\u00f3logo, nutricionista, entrenador personal), jornada intensiva los viernes y en verano seg\u00fan proyecto).-\ud83c\udf81 Plataforma UST Club descuentos y descuentos en gimnasios.\ud83d\udce7 Si quieres conocer m\u00e1s, no dudes en inscribirte y nos pondremos en contacto contigo para ampliarte informaci\u00f3n de la posici\u00f3n \u00a1Te estamos esperando!"}
{"job_title":"Data Driven | Azure Data Engineer","company_name":"Devoteam","location":"Lisboa, Lisbon, Portugal (Remote)","job_link":"\/jobs\/view\/3767993223\/?eBP=CwEAAAGMPGxik9ojKtuFEIRtmz7ha68pWYFOQReiYPEPDiHbEIjtbb90XKHIieZe-R-T-nLBDwA-e5zUvzLyNXFCILP4D5yBYX6SPkc34uo3N-xcgrKT1Y1ngwz86XTdQ9fYRguUTxoq9BqgTwPdQh-DpkAKl4GE4h4qHPp1OFbo2d1v5uEhWT95b7CmEZsi0qhDMHugUjFj6OOKA2Il0a-29rmkqsewQadJgKcY7hg6OQMq59w1YeI063J_rJ5ZqbgNxVo61C1MVEOoRxdXaCMh4pB4zaulWP-V2iIBL00kySCVmxiqLhJogYhUC_NnZD2xsv_YnWidwGn15vl56lF24D_k7ukkRSDhgbKzhAuKOhAkv1pWuAxTB-urRefbFpC1&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=0ATu31rZhhTbWS%2F9Fl6tTA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3767993223","job_description":"About the job\n            \n \nCompany DescriptionAt Devoteam, we believe that technology with strong human values can actively drive change for the better. Discover how Tech for People unlocks the future, creating a positive impact on the people and the world around us. We are a global leading player in Digital Transformation for leading organizations across EMEA, with a revenue of \u20ac652M. We believe in transforming technology to create value for our clients, partners and employees in a world where technology is developed for people. We are proud of the culture we have built together. We are proud of our people at the service of technology. We are proud of our diverse environment. Because we are #TechforPeople. Join our multidisciplinary team of Cloud experts, Designers, Business consultants, Security experts, Engineers, Developers and other extraordinary talents, spread across more than 18 EMEA countries. Become one of our +8.000 tech and business leaders on cloud, data and cyber security. Let\u2019s fuse creativity with technology together and build innovative solutions that actively change things for the better.  Job DescriptionWe are currently looking for an Azure Data Engineer to work with us. Create ingestion pipelines from various data sources;Develop ETL processes, design database systems, and tools for both real-time and offline analytics;Monitor and ensure data quality;Ensure data availability for stakeholders and business processes;Develop data models and structures for BI and Data Science teams;Analyze and troubleshoot data-related issues and discrepancies;Collaborate with analytics teams to foster data-driven decision-making.\n  Qualifications  Strong analytic skills related to working with unstructured datasets;Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases;Experience building and optimizing big data data pipelines, architectures, and data sets using Azure and Databricks;Strong experience with Azure services including Azure Data Factory, Azure Data Lake, Azure SQL Data Warehouse, and others;Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement;Experience supporting and working with cross-functional teams in a dynamic environment.\n  Additional InformationNice to have Experience with data visualization tools like Power BI or Tableau;Experience with other cloud platforms like AWS or GCP;Familiarity with machine learning toolkits and algorithms.\nDoes this sound like you?Come build with us, innovative solutions that actively change things for the better.Apply today!"}
{"job_title":"Data Engineer - Cloudera","company_name":"Paradigma Digital","location":"Spain (Remote)","job_link":"\/jobs\/view\/3772022763\/?eBP=CwEAAAGMPGxikyP-bNtZZaXUpf6v1sEeUL_jZr858qG7Stakihb06cmkH4-VNw714vwXy1NXq8dyrXhmTcl0AwOLPpFFMLEXvTMZHD_OORVodH9A3Clret3QNS-fIahwQP3d7U6KSvR4YKLg8RlK68eu-OsoYyCbigpjsHwGpayA5IArgJN5WZzPRcXWua7Kuc2Pk_qQVSRGdyWAumjGlfSIvJ9ArqXyR_0oLUcwRMy5ca9QfM_rhmx3A5_34q8EyuDxIWM0VA21kDd-ACzNoGWNBhaEXHJ0A1EFQzabubSQ4XT_EPZrB43J55QmhdrHo4Rph2G-H3IkXV5zLN4LFGSzfGIwNVwOciJgzmvGGEDgcUZMf2JQp5iimNezBNguHO3A&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=YC61Q6P%2FU9515ancISpPQA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3772022763","job_description":"About the job\n            \n \nC\u00f3mo somos por dentro.Si vienes a Paradigma vas a encontrar un equipo de Data formado por m\u00e1s de 50 compa\u00f1eros muy capaces que te ayudar\u00e1n a crecer profesionalmente dentro de una compa\u00f1\u00eda de casi 800 que no intenta ser la m\u00e1s grande sino la que mejor trabajo entrega. No contratamos solo para el proyecto X sino para ser parte del equipo a largo plazo.En Paradigma huimos de la consultor\u00eda tradicional, tenemos un enfoque pr\u00e1ctico, basado en los fundamentos de dise\u00f1o como disciplina para aportar innovaci\u00f3n, pensamiento cr\u00edtico, enfoque humano e impacto en negocio. No \u00fanicamente, pero s\u00ed es frecuente que en Paradigma realicemos aplicaciones complejas, modernizaciones de grandes cores tecnol\u00f3gicos, sistemas cr\u00edticos para grandes compa\u00f1\u00edas. Por ello buscamos mentes capaces de conjugar la tecnolog\u00eda con el negocio y comprender requisitos dif\u00edciles para as\u00ed aportar soluciones v\u00e1lidas y creativas.\ud835\udde0\ud835\uddf6\ud835\ude00\ud835\uddf6\u00f3\ud835\uddfb \ud835\uddf1\ud835\uddf2\ud835\uddf9 \ud835\uddfd\ud835\ude02\ud835\uddf2\ud835\ude00\ud835\ude01\ud835\uddfc : Participar\u00e1s en la optimizaci\u00f3n de modelos de datos en stack de Cloudera: Impala, Spark, ETL en Hive, HDFSIntegraci\u00f3n de logs con SplunkIntegraci\u00f3n de flujos y orquestaci\u00f3n de procesos con herramientas como AirflowTendr\u00e1s contacto directo con el \u00e1rea de negocio y tecnolog\u00eda.Entorno Tecnolog\u00edco: Scala, Spark, Kafka, Airflow, Impala, Hive...\nRequisitos t\u00e9cnicos: Scala, Cloudera (con todo su ecosistema), Spark, Kudu y kafkaMonitorizaci\u00f3n y operaciones: integraci\u00f3n de logs o evoluci\u00f3n de lo hecho en Splunk para la parte de observabilidad\/Grafana.\n\u00bf\ud835\udde4\ud835\ude02\u00e9 \ud835\uddf2\ud835\uddfb\ud835\uddf0\ud835\uddfc\ud835\uddfb\ud835\ude01\ud835\uddff\ud835\uddee\ud835\uddff\u00e1\ud835\ude00 \ud835\uddf2\ud835\uddfb \ud835\udde3\ud835\uddee\ud835\uddff\ud835\uddee\ud835\uddf1\ud835\uddf6\ud835\uddf4\ud835\uddfa\ud835\uddee?\u2705 \ud835\udde3\ud835\uddee\ud835\uddff\ud835\uddee\ud835\uddf1\ud835\uddf6\ud835\uddf4\ud835\uddfa\ud835\uddee \ud835\uddd8\ud835\ude03\ud835\uddf2\ud835\uddff\ud835\ude06\ud835\uddea\ud835\uddf5\ud835\uddf2\ud835\uddff\ud835\uddf2: es nuestro modelo de trabajo 100% flexible, te permitir\u00e1 elegir desde d\u00f3nde trabajar, no ser\u00e1 necesario ir a la oficina de forma presencial.\u2705 \ud835\uddd9\ud835\uddf9\ud835\uddf2\ud835\ude05\ud835\uddf6\ud835\uddef\ud835\uddf6\ud835\uddf9\ud835\uddf6\ud835\uddf1\ud835\uddee\ud835\uddf1: esta en nuestro ADN, t\u00fa te organizas tu horario teniendo en cuenta que tienes un horario de convivencia con el equipo que es de 09:30-13:30.\u2705\u00da\ud835\uddf9\ud835\ude01\ud835\uddf6\ud835\uddfa\ud835\uddee\ud835\ude00 \ud835\ude01\ud835\uddf2\ud835\uddf0\ud835\uddfb\ud835\uddfc\ud835\uddf9\ud835\uddfc\ud835\uddf4\u00ed\ud835\uddee\ud835\ude00: trabajamos con las tecnolog\u00edas m\u00e1s punteras para las empresas m\u00e1s importantes del pa\u00eds.\u2705 \ud835\udddf\ud835\uddf6\ud835\uddf3\ud835\uddf2\ud835\uddf9\ud835\uddfc\ud835\uddfb\ud835\uddf4 \ud835\udddf\ud835\uddf2\ud835\uddee\ud835\uddff\ud835\uddfb\ud835\uddf6\ud835\uddfb\ud835\uddf4: creemos que es fundamental estar a la \u00faltima en tecnolog\u00eda. Para ello contamos con seminarios online internos, coordinamos grupos de meetups e impartimos charlas en los principales eventos nacionales. Adem\u00e1s, contamos con clases de ingl\u00e9s y ayudas para cursos, eventos y formaciones. Nos gusta compartir conocimientos \ud83d\udd0a https:\/\/www.paradigmadigital.com\/blog\/\u2705 \ud835\uddd5\ud835\uddf2\ud835\uddfb\ud835\uddf2\ud835\uddf3\ud835\uddf6\ud835\uddf0\ud835\uddf6\ud835\uddfc\ud835\ude00 \ud835\udde6\ud835\uddfc\ud835\uddf0\ud835\uddf6\ud835\uddee\ud835\uddf9\ud835\uddf2\ud835\ude00: Seguro M\u00e9dico 100% pagado para el empleado.\u00bfTe sientes identificado o identificada? \u00a1Te estamos esperando!\"Paradigma es una empresa que ofrece un entorno de trabajo diverso e inclusivo d\u00f3nde el respeto por las personas es lo m\u00e1s importante. Aseguramos la no discriminaci\u00f3n por razones de g\u00e9nero, edad, raza, religi\u00f3n, orientaci\u00f3n sexual o cualquier otra condici\u00f3n o circunstancia personal o social. Nos esforzamos en garantizar la igualdad de oportunidades y salarial entre hombres y mujeres por trabajos de igual valor\""}
{"job_title":"Data Engineer (all genders) REMOTE","company_name":"AllocNow","location":"Germany (Remote)","job_link":"\/jobs\/view\/3772498263\/?eBP=JOB_SEARCH_ORGANIC&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=99xOx1f9JJt31X6NJTph%2Bw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3772498263","job_description":"About the job\n            \n \nAllocNow is a pioneering cleantech company, focusing on the chemical and process industry. Our mission is to facilitate the sustainability transformation by providing a platform that enables effective management of the environmental impact of products at scale. The Product Sustainability Platform automates lifecycle assessments with unprecedented levels of consistency, efficiency, and reliability, supporting companies on their journey towards net zero and circularity.We are growing and searching for motivated and versatile talents to strengthen our team. Get in touch if you like to work purposefully and make a difference!Tasks Develop and maintain data pipelines using Python (pandas) and Airflow. Collaborate with cross-functional teams to gather and understand data requirements. Optimize data processing and storage for performance and efficiency. Give and receive constructive feedback to teammates through code reviewsWrite clean, testable, and documented code with a \u201cnever-stop-learning\u201d attitude\nRequirements 2-5 years of experience in data engineeringStrong background in Python, especially pandasProven experience with SQL and databases (e.g. PostgreSQL)Experience with Apache Airflow is a plusExperience with cloud computing (AWS, Azure) is a plusResidence and work permit in GermanyEnglish language (C1), German is a plus\nBenefits Almost unlimited growth opportunitiesExposure to renowned clients and relevant business problemsCompetitive compensation and benefits package\nWork modeTo enable our remote work mode, we work with: MS Teams for synchronous communicationGitLab for project managementDaily project standup meetings, bi-weekly company meetingsBi-monthly face-to-face meetings of our team\nEqual Opportunities for EveryoneWe are open to all groups of people without regard to age, color, national origin, race, religion, gender, sex, sexual orientation, gender identity and\/or expression, marital status, or any other legally protected characteristics.Our MissionThere is no planet B. Humans must reduce greenhouse gas emissions. We take action together with our clients in the chemical sector which by itself contributes up to 40% of global industrial GHG emissions. Join us on our mission to lead the way to a zero-carbon economy and boost innovation to make chemical companies climate neutral.Our solution is Industry-specific: Handling the complexity of chemical value chains is our daily businessBusiness-focused: We make sustainability data available to a broad range of users and empower them to take actionData-driven: We offer a fast and cost-effective calculation of sustainability metrics\nAre you keen on joining our team, building a great product, and growing with us? Get in touch!"}
{"job_title":"Data Engineer (BIOTECH)","company_name":"Nexer Group","location":"Czechia (Remote)","job_link":"\/jobs\/view\/3766004194\/?eBP=CwEAAAGMPGxik3NsC3F-fkKxCUMyqn5OQ9IoLJhVdkPIczr7AW2yEeowbUiGxnKUubtkO9di5ENqjn6oxF8TI7aNUOaBgelYpY_jic9ghOHC02WanQ0zw7JZTNAtvToh1dHxdbQgCE6W52CluiIJarLU3V7_JEByhpdEfaLtNHE7GUWfWqSA3f3BcIZRe9Hk72ZZpatwO5cHfOjiCjgoMsEyP2S7Bu83YFigXV_IbLhVnqJHRwp7zP0f36HbFk8oI-VoFYORvEBd3KgxYThRVa_ji5kby0jZjMLqiBso8QWYOUL0QLiaiUYs6_zpYUDSyHFCoyviAMH-4BlpwAL2wr1n07JMjCHSd12_IYn0LMAWwWPWPAidAY9VOKsp2urWjg&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=lp5wPUkiV1AtGN%2FPm5DOgQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3766004194","job_description":"About the job\n            \n \nAbout usNexer Czech republic is a division within DANIR AB \u2013 an IT consulting and R&D company. We have the opportunity to work with world-renowned brands from Scandinavia, the USA, the UK, and Western Europe. Our goal is to grow strong but rather in competencies than in numbers.If you like what we do, see our offer, maybe it is you we will have the pleasure to meet! :)The project and the role description:Our client is an AI-driven PharmaTech British company committed to discovering, designing and developing better medicines. It developed the first-ever functional precision medical platform to successfully guide treatment selection and improve patient outcomes. We are looking for an experienced Data Engineer to join the Tech Group of the Precision Medicine unit. As a Data Engineer you will build state of the art data pipelines and warehousing solutions that act as the foundation to our pharmacoscopy image analysis platform, thereby supporting the groundbreaking research taking place. You will build systems that scale to tens of millions of high-resolution images along with complex biological omics and clinical metadata. Your work will not only ensure our data is stored and used according to FAIR principles, but more importantly empower the scientists, relentlessly working to get the right drug into the right patients. Responsibilities Work on highly impactful data problems, in support of drug discovery Work at the intersection of big-data and biotech research Use modern, cloud native tools Have a say in design decisions Work in a collaborative and supportive team environment Receive training on novel technologies \nYou might be the perfect match if you are\/have: 3+ years of experience as a data engineerLocation in Czechia or Slovakia for easy signing of offers of cooperation and for occasional meetings of the team.Basic understanding of Machine Learning in general Worked in agile teams before Excellent communication skills (English) Familiarity with FAIR data principles Possesses a finisher mindset (i.e. ownership) Experience with the following technologies Python 3.6+ Relational DBs (e.g.: PostgreSQL, MySQL) Orchestration frameworks (e.g.: Airflow, Luigi, Nextflow, Prefect) REST APIs Docker + Linux GCP, AWS or Azure\nMoreover, we appreciate skills in these areas: Knowledge of clinical data management Knowledge of imaging data Knowledge of Next Generation Sequencing data Experience with any of the following technologies is a plus: \n- R programming language - Django- BaseRow - NextFlow - PySpark - GCP - FastAPIWhy should you choose us: Exciting projects, multinational and inspiring environment for talented IT professionals. Various projects in diverse, cutting-edge industries. Biotech, Automotive, Internet of Things, or AR\/VR; Code review done by skilled engineers (over 60% of our team are people with over 5 years of experience in the industry); Becoming a part of a team of motivated individuals that are here to stay. We value loyalty \u2013 as you grow, we grow with you; Respect for your private life so you don't have to work overtime or on weekends; Online and offline events \u2013 Barcelona, Goteborg, Oslo, Capetown are among our business and integration trip destinations.\nPerks and benefits: Salary: employment contract: 90-110.000K\u010d\/month or B2B: 6-7.500 K\u010d\/MDFully remote, hybrid or HO - choice is up to you! :)Choice of employment form: we offer B2B or employment contract;Personal Training Budged and Passion Day - an extra day off for your passion, hobby, and growth to spend as you please;Flexible working hours with no micro-management approach. Our core hours are 10-15, the rest of the working time is your decision;We provide high-quality work equipment.\nSubmit your application online in one easy step! Apply now!"}
{"job_title":"Senior Data Software Engineer","company_name":"Orbis","location":"Madrid, Community of Madrid, Spain (Remote)","job_link":"\/jobs\/view\/3765988877\/?eBP=CwEAAAGMPGxik9nRVZy_RWoRoOr07n9d9O6tJI18F9uVWo1KfdJOvVl8OhtPxyJ4klFkXN7kz7ycMSJ1k7MdjVslgco43ZxqDU7Q0FGI62s8ToDoFQ6Dzcb6LzBCGlUOKZIgRsK7PjpwrrQiXcUVOwypKdBcRhXd1FLEDrjdC3egaS-sjMji1kX_7gpJirrflZu-OEuDubvSRXIAP-GFYwgyvGVIEtXkNS-U6s9wJNcFL2vJufTWAs1xerKBux9j4NaLKdyOtTfEHGYQ0vwH_mK_kIXMfVDgreLvrrOTZAJoEYQf0bdVoRYzF9_TKcoSvMspfLakyx9EvJ-emq61fXJRP5cKOM-tuBhDJ1Lae2MHt-DhrgJUDLcdG3Pgi5tf2Esu&refId=R4kit4FmGIFicWAUQnd9JQ%3D%3D&trackingId=i0wgKf36Irx4r%2Bzd7%2FweJw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3765988877","job_description":"About the job\n            \n \n\ud83d\udcdd Title - Senior Data Software Engineer\ud83d\udcb0 Base \u2013 Competitive + additional benefits\ud83d\udccd Location \u2013 Madrid\ud83d\ude8a Hybrid or RemoteFluency in English is mandatory.About the company \ud83d\udca1They are a fast-growing AI start-up with over 13 million users which has recently secured over $10M in funding.They are a remote-first and fast-paced company offering an exciting development environment within an agile start-up culture.Role Summary \ud83d\udcbcThey're looking for an experienced Senior Data Software Engineer to be their first data-focused backend engineer!Key responsibilities\ud83d\udd11 Help define their data approach and introduce suitable technologies to support their platform's growth.Develop the necessary ETL infrastructure.Work with their Engineering team to define the various data sources. Work with their CEO and marketing team to provide the necessary data reports and visualizations. Stay up-to-date on the latest data trends and best practices.\nExperience required \ud83e\udde0 4+ years experience in software engineering. 2+ years experience in data engineering or data science.Strong experience with SQL, database modelling and data cubes.Experience with transactional and columnar databasesStrong professional experience writing clean, tested and deployable Python code. Full professional proficiency in English, with Spanish as a plus.Experience working within a tech-driven company.\nApply to the Role:If you are a proactive person who is excited about new challenges and has a passion for data engineering, then apply to this advert or email your CV to vega@weareorbis.com.About Orbis Consultants:Orbis Consultants is a global, multi-sector recruitment agency specializing in Technology, Financial Services, and Creative.We\u2019re a curious bunch of creative recruiters, relentless in our pursuit of bringing together the smartest talent with the world\u2019s leading global brands and innovative start-ups.https:\/\/www.weareorbis.com\/"}
{"job_title":"Junior Data Engineer","company_name":"Zurich Insurance","location":"Bratislava, Bratislava, Slovakia (Remote)","job_link":"\/jobs\/view\/3745500531\/?eBP=CwEAAAGMPGxmqkCJZKbBVCJ42ggeNBZJKkgTu1m2Fi-60EHrJvdN-rfJWgr1XSQvnyTGzXW9_54FBLRhoTOUphxWFTBK5spG-wWyMkTKHzkIA4hTSYbwZjT0WcZLcPEIWnupWGJqSyadSEdeCVg78lvJfPuww15LxSJ8tgBnUpF87CkdgWqWCDv1TUbPKeBh8RE09vailPnfD571MK74E8hg1GhbACyBfc8fvvFn49Zkamb6yjapdiUxksdwiNf8qwrX8zO-AzlV8Dm215ML0M3ERj9P86F37opeZWPCvrqIvxB3qxgQ5wmAlRyPLWSjHB-F39FrxG9Vndwvr_XoCx9gzHvMGG0i5W7TjJe0mnacVfSc2vw_yuiRKNOvaaX1ly8OYY8&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=rqr6U%2BMy3aNZwvvTFTSoDg%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3745500531","job_description":"About the job\n            \n \nOur opportunity Junior Data Engineer, Commercial Insurance Underwriting Team, 80%-100% Are you a motivated, hands-on, and innovative person, interested in working for one of the largest global insurers? Are you passionate about developing analytical software that addresses the daily business challenges of a leading global insurer? If so, this junior position might be the perfect fit for you.We are currently seeking a Junior Data Engineer to join our global Commercial Insurance Underwriting team. In this role, you will have the opportunity to:  Assist in solving business problems related to Underwriting, such as understanding claims drivers, portfolio optimization, and risk selection.  Gain valuable insights into the workings of Commercial Insurance through dedicated training and mentorship.  Collaborate with a dynamic and entrepreneurial global team that is committed to challenging the status quo.  Contribute to the development and adoption of our main global Underwriting analytical product suite.  Enhance your technical skills by working alongside internal and external experts. \n Your role As a Junior Data Engineer, your main responsibilities will involve:   Collaborating on projects with a focus on end-to-end success.  Exploring suitable cloud-based technologies to address specific business problems.  Extracting insights from various internal and external data sources using a range of tools and methodologies, such as building data pipelines in Spark and Scala, applying Semantics and\/or Machine Learning, and extending front-end applications.  Participating in the development of user-friendly applications, from proof of concepts to full-scale solutions, including portfolio management applications and Applications Programming Interfaces (APIs) integrated into core Underwriting processes.  Ensuring the reliability and expansion of our platform in a production environment, including building or assisting in the development of AI models, optimizing data pipelines, and enhancing automation architecture (e.g., web scrapers, and automated user alerts).  Coordinating directly with product managers and global application users, with a focus on driving adoption.  Assisting in the mentorship and development of more junior team members. \nYour Skills And ExperienceAs a Junior Data Engineer, your skills and experience will ideally include:  Technical proficiency, including professional experience in data engineering.  Familiarity with Dataframe APIs (such as Spark or Pandas) and SQL.  Knowledge of query optimizations (RDBMS or Spark) and indexing.  Solid understanding of Java and\/or Scala, with experience in functional programming being a plus.  Familiarity with scripting languages like Python, R, and bash.  Experience working across various stages of the software development lifecycle.  A can-do attitude, with a focus on delivering end-products that meet user needs and specific business use cases.  A passion for tackling real business problems and the persistence to follow through with recommendations.  Strong teamwork and communication skills.  Excellent written and spoken English, with knowledge of other European languages considered a plus. \n We offer Apart from monthly salary offer starting from 2 500EUR\/gross and a yearly bonus we offer benefits package which includes:Working Time BenefitsPersonal days off, Concentrated work week, Additional vacation, Home office, Extra days off at occasion of childbirth, Sabbatical leaveMonetary BenefitsLife insurance from Zurich Austria, Compensation for salary loss during sick leave, 3rd pension pillar contribution, Risk Life Insurance, Meal contribution on top of the legally required minimum, Years of service bonus, Wedding bonus, Baby bonusOther BenefitsEdenred electronic cafeteria, Public Transport contribution, Maternity leave benefits, Company and team eventsLearning\/DevelopmentProfessional Certifications, Online Education Portals, Extensive Onboarding program, Strengths based culture (GALLUP)  Location(s): Bratislava or Kosice co-working space  Remote working: Yes (Slovakia based), if possible we would like to meet with you more often in the few first weeks  Schedule: Full-time or shortened work schedule (We can provide 75% up to 100%) \nAbout UsAt our company, we recognize the importance of fostering an open-minded, safe and inclusive environment for everyone. We stand with diversity and respect different backgrounds and lifestyles. That's why we've implemented numerous initiatives to ensure our employees feel comfortable, accepted and respected at all times."}
{"job_title":"QA Manual\/Automation Engineer (with Python)","company_name":"Luxoft","location":"Poland (Remote)","job_link":"\/jobs\/view\/3771956957\/?eBP=CwEAAAGMPGxmqqw4ys5zkJ1SrqnlsEHIOUXuYZpE_gWauuLW1cairJgO2tzIJ8V0Ika8fVrCnsKfq1A91gLlQfyUXcT9qid1XQ8xqcuqXuQBNNXa-s-hu4gQu3IShvqk5jlVgPNGbpbK1CpYnvzwNvmG023f2YcWaY5vgeruNsUhpcPvuTm83nLNKb1S89X8ylhPozmsysjQFaiRipL2K0xR8ZlYgXD8a0svu27iyU4JoAdA8EdZh799miZI5BcPWqpGukdV4RM5T4CVn6izlRX5Nr_Vcc653sBV6BvsMOZWFLB44H91jBGtazgIWd6Xj9XPRlxbqrJGhySi28tOhK-ohmQoHdAZCoaqvYiAt9zAGdX9GaVi_xVh_-O-gRaJJXZT&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=1SdoaZX9q5Y0HnxJb8VDWA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3771956957","job_description":"About the job\n            \n \nProject DescriptionDevelopment of monitoring and diagnostics system. It fulfils both local and remote data access and analytics requirement, as well as local and remote troubleshooting purpose.ResponsibilitiesWork with the Product Owner to define test cases that prove the acceptance criteria for incoming user stories for the Web apps.\u2022 Create functional and non-functional UI\u2022 Communicate clearly in English with the development engineers regarding test expectations and defects.\u2022 Use defect tracking tools to log and clearly describe defects and conditions for reproducing them.\u2022 Contribute to design and estimation conversations.\u2022 Contribute to the quality of the solutions by identifying issues in architecture, design and implementation\u2022 Contribute to our Agile development process as a scrum team member from requirements analysis and design up through final feature acceptance and deploymentSkillsMust have\u2022 At least 4 years of creating and executing test cases\u2022 Working knowledge of functional and non-functional software testing, the software test life cycle, and various test design methodologies (function, performance, accessibility, scenario etc.).\u2022 Test cases creation and execution based on Customer and Software requirements\u2022 Python 3+ years of experience\u2022 Experience of setting up testing framework from scratch\u2022 Experience in testing of Backend (API) and data quality\u2022 Knowledge of API testing tooling like Postman, Swagger\u2022 DBs basics and SQL database usage expert\u2022 Familiar with IoT OR Time series data handing knowledge\u2022 Linux knowledge\u2022 Experience with AWS services\u2022 CI\/CD (Jenkins)\u2022 Experience with Performance testing\u2022 Good soft skills in communication.\u2022 Exemplary verbal and written communication skills (English).\u2022 Creative problem-solver capable of creating and reproducing interesting software bugs..Nice to have- Experience in cooperation with QA automation team- AWS Green Grass- Experience or knowledge of Industrial protocols (Modbus) Languages English: B2 Upper Intermediate"}
{"job_title":"Data Engineer","company_name":"TUI","location":"Barcelona, Catalonia, Spain (Remote)","job_link":"\/jobs\/view\/3771225067\/?eBP=CwEAAAGMPGxmq1-sEIiA_88uh5GDgmUKjKXUygv6ubMskU05IQnC8VXqy3jxRFDh7lPDnbcm7YV-pxH_fOS69Txd0ew5rV4-jqP-yKVbSnWh-pomBy8Kt9qVkWKcuHXw3rMzsk060jBiPRfQhfu3MSS5tjHALGe_fp3woGSOSLzS1ftIVnpjRcN4P9EkhAy8VhiBUCFN4AdWI36VLKkzVEQsUkSbuesrSM1H1lR7-kbFg7etUSB3WVsepemj8cFD5KswI9vD76C4JFT41_bm8uY9mVgrygzpWgCt7qoif04DkH6yrj4P-6-kiyoPb2cGsK_LZIotzlQxiw2HTVcTStsVnxaa2NEzfZB6x_ONS63jHaEA-hfGnfan_32EvgYeeaFGc0Q&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=wBs1nD7pKm3DI1pn3Z%2FIDA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3771225067","job_description":"About the job\n            \n \nTUI Group is the world\u2019s number one integrated tourism business. CVM technology analytics is a team responsible for ingesting, modelling and extracting data in the TUI Central Region for CRM purposes. We are a multi-disciplinary team of experts across Architecture, Engineering, DevOps and Agile Delivery providing services across the UK, Ireland, Sweden, Norway, Denmark, Finland, Germany, Belgium and The Netherlands.At TUI we\u2019re ambitious to become the leader in technology within the travel industry and to achieve this we are looking to build a capable, creative team who want to be a part of accomplishing that goal.We never stop looking ahead, seeking new ways to delight our customers and grow our business. We recognise the power of digital and the massive contribution this brings to creating a truly unique and differentiated customer experience.We are looking for a talented and dedicated technical enthusiast to join the Analytics Master Domain organisation which provides state of the art data products. ABOUT THE JOB: As a Data Engineer, you will be part of a cross-functional team that enables data engineering skills and capabilities across a whole domain. Being an enthusiast in data engineering, with a strong DevSecOps mindset, you\u2019ll use your excellent collaboration skills to work with your team to deliver the best answers to our customers\u2019 needs with full responsibility for its data flows from design to operation. You will use your deep technical skills to work closely with your colleagues to ensure an optimal data delivery architecture which is consistent throughout ongoing projects. You will work on data collection, data pipelines, data delivery to other systems and building a strong core data warehouse. You will Support your fellow Data Analysts and Data Scientists on data engineering tasks and work as a team to deliver data driven solutions.You will Build and maintain data processing systems, including data ingestion, data quality control, and data warehousing.In addition to ensuring operational and analytical excellence you will be working on connecting on-premise data with cloud computingPerform root cause analysis to identify and resolve data quality issues.Demonstrate meticulous attention to detail in ensuring the quality of your work, encompassing comprehensive documentation and stringent security measures.\nABOUT YOU: Work experience as a Data Engineer or similarStrong SQL and data profiling skills \u2013 enjoy working with data, process analytics and development, understanding of common architectures. Experience in data modelling with ETL (e.g., usage of Informatica) and scheduling (e.g., UC4, airflow).Knowledge of BI applications such as Power BI, Tableau or Spotfire.Able to work with GitLab or similar tools for code management.Preferred experience with AWS and SnowflakePreferred experience with Big Data projectsGood communications and influencing skills, with the ability to explain technologies and solutions to technical and non-technical stakeholdersCritical thinker and able to provide constructive feedbackBachelor\u2019s Degree or equivalent in Computer Engineering or similarExperience in the Tourism Industry is a plusFluent in written and spoken English, German skills is a plus.\nAbout Our Offer Working in the leading global tourism group: We stand for intercultural cooperation and offer the opportunity to work in international projects and teams.Fantastic holiday benefits including discounts, special offersMobile working, flexible working hours and working from abroad: We believe that work is something you do, not where you go. Our offer: TUI Way of Working Health and Wellbeing support in five key areas \u2013 Health, Social, Community, Career and FinancialDevelopment and career opportunities: We offer a wide range of digital training and international career opportunities.Additional benefits relevant to the local market that you'll be based in\nAt TUI, we know people are as diverse as the destinations we send our customers to. We love to see your uniqueness shine through and inspire the future of travel. If you would like to read more about what Diversity & Inclusion means to us simply visit our Smile page Click hereIf you have any questions, please contact the Recruiter for this role via the contact information included in the advert.Please Note: These vacancies will be managed by an International Recruitment Team and therefore your application may be viewed by TUI colleagues outside your home country.#TUIJobs"}
{"job_title":"Data Engineer","company_name":"Next Ventures","location":"Poland (Remote)","job_link":"\/jobs\/view\/3767611937\/?eBP=CwEAAAGMPGxmq40T9opByJXD00n0KcwJt_KWlF04bp0so107oMET-Es5qGnmlskDOWAxXF1cnLedlqAoShUCXT1dw4Zszcy_Mr1okvnsncG1I9AmVL0UOMWInHEEXEstXu-676hBwofqASFapVA2V97HAvnvh7CsBkUs99pfYmnla0afpBiRVGrxbmXjOImeVEPmtjzh7QFGPXt_hVP6hJ9Cxipbh-dcYNqlulLhNXSl-poncmp5eMk7beEbJDw_aQLK2G_F_yIejtYwVEoEVrYaXH3keYTM0kF2IoVs5UstXqmbwSKWTfx0WEKa5AqW4a5TjiFLki56wgaudNGLMHIW29bPdsHTZjdqfyiCqJF1nXJQ1QZbOkE9po6KCjrclyHGjKE&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=uMyThWjirkx7aP2%2BSuU2Fg%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3767611937","job_description":"About the job\n            \n \nJob Title: Data Engineer (GCP, Python, CI\/CD) - Pharma Industry Company Overview: Join our innovative and dynamic pharma team dedicated to advancing healthcare through cutting-edge data solutions. We are seeking a skilled Data Engineer to play a crucial role in building automated data pipelines and designing cloud-based data warehouses. This fully remote position offers the opportunity to contribute to the transformation of our data infrastructure, utilizing the latest technologies and tools. This is a 6 month initial contract and the candidate needs to be based in PolandResponsibilities: 1. Automated Data Pipeline Development:\u2022 Develop, implement, and maintain automated data pipelines using Python, CI\/CD practices, and GCP-Dataflow to extract gated cell populations' data from diverse sources. \u2022 Ensure seamless integration of data from source systems to the Data Platform on Google Cloud Platform (GCP). 2. Cloud-Based Data Warehouse Design and Implementation: \u2022 Design and build a robust cloud-based data warehouse on GCP, leveraging GCP-Dataproc, to store metadata, panel information, and gated cell populations' data. \u2022 Collaborate with cross-functional teams to understand data requirements and optimize the architecture for scalability and performance. 3. Data Integration and Transformation: \u2022 Implement data integration and transformation processes using GCP services to ensure consistency and accuracy in the stored data. \u2022 Collaborate with data scientists, analysts, and other stakeholders to understand data needs and design solutions that meet business requirements. 4. Performance Monitoring and Optimization: \u2022 Implement monitoring systems, utilizing GCP tools, to track the performance and health of data pipelines and data warehouse components. \u2022 Proactively identify and address bottlenecks or inefficiencies to optimize data processing and storage. 5. Documentation and Knowledge Transfer: \u2022 Create comprehensive documentation for data engineering processes, configurations, and solutions. \u2022 Facilitate knowledge transfer sessions to ensure team members are well-versed in the developed data infrastructure. Qualifications: \u2022 Proven experience as a Data Engineer with expertise in Python, CI\/CD practices, GCP-Dataflow, and GCP-Dataproc. \u2022 Strong proficiency in Python and experience with Google Cloud Platform (GCP) services. \u2022 Previous experience in the pharmaceutical industry is a plus."}
{"job_title":"Data Engineer","company_name":"Oliant LLC","location":"Bulgaria (Remote)","job_link":"\/jobs\/view\/3724530131\/?eBP=JOB_SEARCH_ORGANIC&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=t5Jh0MYcEtGLvJIbH2%2F%2Fdg%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3724530131","job_description":"About the job\n            \n \nWe're on the lookout for a passionate Senior Data Engineer who can bring a blend of SQL, Python, ETL, DBT, and Airflow skills to our dynamic team\nYou Will Get The Chance To Design, construct, install, and maintain large-scale processing systems and other infrastructureDevelop and manage ETL processes to source and load both internal and external data, ensuring data integrity and accuracyUtilize SQL and Python to build scalable and efficient data pipelines. Implement dbt to define, document, and execute data transformations and tests in the data warehouseSet up, orchestrate, and monitor data workflows using Apache AirflowCollaborate with data scientists and analysts to provide data support and integration for analytics and machine learning effortsEnsure optimal performance of our database and respond to potential issues\nRequirementsWhat You'll Need: Bachelor's or Master's degree in Computer Science, Engineering, or a related fieldMinimum of 5 years of experience as a Data Engineer or in a similar roleProficiency in SQL, Python, ETL processes, and data warehousing solutionsHands-on experience with dbt and Apache AirflowStrong analytical skills and attention to detailExcellent communication skills, both verbal and written\nBenefitsWhat We Offer Competitive salary and benefits packageSign-on BonusAnnual performance bonusOpportunity to work with a dynamic team on cutting-edge data solutionsFully remote workContinuous learning and growth opportunities"}
{"job_title":"ETL \/ Data Engineer - Remote","company_name":"Sofomo","location":"Wroc\u0142aw, Dolno\u015bl\u0105skie, Poland (Remote)","job_link":"\/jobs\/view\/3762569518\/?eBP=CwEAAAGMPGxmq58j_Jyx8DM9lmOm6Kx_yWx5ow86kaJlRHDMiaUwNNM63Y_-hDEcqaJhjqIzocHJ2tROHUdaDRB1vUUUc3f6QLyESF3HweB1QFMH8aCSRPmct2zKBn1b9mG2rb3i4NUss-0XU68eyPjvsEY_oTyMwz2XRA4M1Cj7o0a0g8Boub186KpkaNIFQE6asHJbfulUo52IhPt5bneYACJfcobml_SOFMTuONN_7wwdnth-xRD0U9WZ4L5FwCgYu1Jnxo2NCdM5dCwV13wFInUJ0Wa9alQsuE2YgtuP3ABjMjCd6NMhPFA8UtN-OZD6VqOA7SwFQmwyplHMcD1opN38b1VMdlLiGLhftBtLhbaWvEed1z-4kZVWOA7PkH15SjA&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=kV4BASKvwOQ%2BQuVTZWWWtw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3762569518","job_description":"About the job\n            \n \nJob descriptionWe have an exciting opportunity for an ETL \/ Data Engineer who is passionate about building data engineering systems. This is a key role where you will join a small Sofomo team working for one of our clients. You will help design, build and execute a new data engineering system that connects, import and transform data taken from and to multiple third party data points. Over time you will have an opportunity to build custom data engineering solutions.Python development experience is not required, however it will make working with all the API\u2019s easier and faster. Your technical experience and technical skill set are the most important. However, we will also choose based on your personality, attitude and desire to grow your skills.Why Sofomo?By joining Sofomo, you will have a chance to work with experienced developers and experts across multiple technologies. You will have unique opportunities to grow your skills and learn something new every day. You won\u2019t just be a task taker. You will design advanced solutions, make technical decisions, choose specific technologies and more.Your daily tasks on the job Solution Design - You won\u2019t be just taking tasks. This job involves actual design, architecting and implementation of ETL and data engineering systems. Ownership - You will have ownership over your development from design to launch.Data Engineering - Design and implementation of a robust data engineering system built from the ground up with custom data pipelines in the cloud.Data Engineering - Development of custom data engineering solutions. Data Engineering - Data model design, design patterns, creating reports, scriptingAgile Approach - You will work collaboratively with other team members in an agile, Scrum way.Learning - You will learn new technologies, frameworks, etc. every day.\nMust have ETLData EngineeringSQL\nNice to have PythonAWS AthenaAWS Glue and PySparkTerraform\nWhat We Offer Competitive salary.Challenging work on complex and very innovative projects.Work in an international environment.Generous benefits package with all kinds of great stuff.Trainings accustomed to your needs.Company social and integration events (eg. bowling, lasertag, go-karts).Flexible working environment.Office near Wroclaw\u2019s city center.Cozy and friendly atmosphere.\nJob details Online recruitmentRecruitment language: EnglishStart ASAPPaid holiday100% remotelyFlexible hours\nBenefits Sport subscriptionTraining budgetLanguage coursesInternational projectsIn-house trainingsMobile phonePrivate healthcareFlat structureSmall teamsConference budgetTeam Events\nPerks in the office Free coffeePlayroomFree beveragesStartup atmosphereFree lunchNo dress CodeBike parkingShowerModern officeIn-house trainingsFree snacks"}
{"job_title":"Senior Data Engineer","company_name":"Modash","location":"Estonia (Remote)","job_link":"\/jobs\/view\/3763518710\/?eBP=CwEAAAGMPGxmq8Eu-Uiv7e-fDo0Ip5icqss5Jx-b8gNJy6g-Sa9r5czi32nF075lBuv8wf4u2ZnA-sRxdlGdD-yss90bK-6634Z6Goy8rn33LA4ZlunJTZdDA1sXjGL6qgalCGyISpA8O18aZv8K7ETOSXN1Ohg4bfgzfxG6ZMVo8l17geE9ZjQK1DPEQ1Izp_MFrqk8Elg47W3ZenfuZ691OICotX_4Qwa8CbjpoiAOYnwfOnBMfzIHeOLeOvU2m9FvVEo0QC0xO-617O56PRZtAnJdLP8TW_3c6MbK3MLM6N7YNPkkNHGEmKJcYxhTnGWn-NJ9BpPxtYJAtEHVIBxTPT8M7rVZ4duB05xVzQJpGyH9_k_q9KxHvCWkdpPLPHODYBgLATS1kxsDVI4w5-rQ0aEq77YpwQ&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=pDqQ3p4jeKVX%2BDLriG6X1g%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3763518710","job_description":"About the job\n            \n \nThe world doesn\u2019t need giant media organizations to tell every story. The world needs millions of creators. People who are brave enough to share their own stories, create their own art. To educate and inspire the world.We\u2019re working to help every creator earn a living and help companies find the right content creators to work with.Modash is the starting place to create sponsorships for thousands of creators every month. We help creators find their voice and be visible for brands to find them. Modash platform helps iconic consumer brands scale their partnerships with online creators. We\u2019re looking for a full-time Senior Data Engineer to join our Data team to help bring our mission to life.Being a Data Engineer at ModashHere are some things you might do in a week as a Senior Data Engineer at Modash: Take ownership of building the best data platform for influencer marketing.Design, develop, and test data pipelines in order to collect, process and store data..Collaborate with your colleagues, from pair programming to mob reviewing. We are all for one.You are expected to take part in every area of the data product, from brainstorming, roadmap planning, implementing, and reviewing, to releasing. Working with the CEO, CTO, engineers, sales, and customers.Help us choose the best technical direction by providing well-reasoned ideas on which frameworks and tools to use.Implement systems to monitor data quality for optimized accuracy and clarity.Teach and be taught through code reviews and feedback.\nWhat we do not expect you to do is: Be dependent on others. You should be a fully autonomous and proactive individual.Take for granted the tasks that are assigned to you. Always question the status quo.\n\u200dWhat we\u2019re offering 60,000 - 120,000 \u20ac. Depending on skills and experience level.Flexible working hours \u23f1. We trust you to do your job, without anyone looking over your shoulder. Do your best work whenever it suits you.Unlimited paid vacation time \ud83c\udf34. If you\u2019re happy & well-rested, you\u2019ll do better work. Take the time you need to enjoy a balanced life.Fully remote working \ud83c\udfe0. As long as you have a reliable internet connection, we want you to work wherever is best for you. At home, in a caf\u00e9, on a beach. Whatever works.Personal development \ud83e\udde0. When you grow, we benefit. If there\u2019s a course, book, or conference that will help you upskill \u2013 we\u2019ll cover it.Ownership \ud83d\udca1. You\u2019re the expert at what you do, and so you should have the flexibility to make decisions and take action quickly. No unnecessary red tape. Got an out-of-the-box idea? You\u2019ll have the autonomy to go ahead and try things that you might not be able to at other companies.\nExperience that would make you great at Modash:  Experienced as a Data EngineerUsed to working with unstructured dataExperienced working in Spark environmentExperience managing data workflows with a distributed workflow manager (i.e.: Airflow, AWS Step functions)Hands-on experience in writing code in Python and SQLExperience in building and maintaining ETL & ELT data pipelinesFamiliarity with AWS ecosystem: DynamoDB, Glue, EMR, Kinesis, SQS, Lambda, ECSHands-on experience with SQL\/NoSQL database designYou have a passion for building well-architected softwareYou have worked on product features end-to-end including scoping, architecting, coding, testing, and rolling out features\nThis is important to keep up with the Modashians: Get-it-done attitude. We all run into roadblocks every day. We\u2019re looking for someone who can find solutions, motivate themselves, and keep getting things done.You aspire to be great. We\u2019re not shooting for mediocrity here.Interest in the creator economy. Our mission is to help creators get paid. You don\u2019t need to live and breathe the creator world, but we\u2019d like it if your values align with ours.We\u2019re looking for applicants in Europe, Africa, or Middle East time zones. Ideally, you\u2019ll have at least a few working hours overlapping with GMT+3 each day.You should be fluent (or nearly fluent) in English. Our team is distributed across many countries, but we work & collaborate day-to-day in English.\nIf you meet most (but not all) of the above criteria, don\u2019t let that stop you from applying. We\u2019re still interested in hearing from you.\u200dOur tech stack AWS with Pulumi (Infrastructure as Code)Node.js with Typescript on AWS Lambdas and ECSPySpark on EMRApache AirflowDynamoDB, DocumentDB, S3, Kinesis, SQS, EMR, Glue, API GatewayGitHub, Yarn, Jest, Miro, Confluence, Jira, GSuite"}
{"job_title":"Data Engineer","company_name":"Beyondsoft Singapore","location":"Spain (Remote)","job_link":"\/jobs\/view\/3763883727\/?eBP=CwEAAAGMPGxmqyAvX_OybYAXfl7wFs_i2T9wIlbU38nv9KxAwyO__QuU0S8bHwSkh7_WTXdcA0bZiB0U8d5Pp5NgIRp_OSRPnZ0p6mkV5DQXVUC2GOJdoknnp2uoLYK5jCs3KU0_YmEcFZyh4rQ2pRyICPtsErHbQUufY5Bw9BVE2_wyb6J_SRFq8w0JF9jrueVyW_a9EvO30X1t0n8nahJm1zNf8rLcnTPP_I_AOIIq4j91AZhRj52eEsE6ncIWP3YajDUnjltcSFOUkefA7wQJ_nxGrov3tKKuVw6D8qHjelRViarr0rsVKsWHYzg1PjcrrSQyaiotJo1dC5phdglk1XfByOZOmRmPJ-KwrORaGd2_dh93hTMKz_UYY6CzmHmBvx8&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=ruaEtjYQgxzBlaRe29Pkfg%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3763883727","job_description":"About the job\n            \n \nBeyondsoft (listed by the Shenzhen Stock Exchange, stock code 002649) is a global provider of IT consulting, product and solution services. Relying on strong R&D and innovation capabilities, the company widely adopts emerging technologies based on big data and mobile internet, including big data management platform, enterprise risk warning and public opinion monitoring system, AI-based intelligent operation and maintenance service, and intelligent automated test products. And a wide range of products and solutions, including internationally authoritative software testing qualification training, for a wide range of services in the fields of high technology, internet, finance, retail, logistics, energy, manufacturing, and medical.The 3D Data Team from a client within the Tech field is seeking an experienced candidate who thrives in a fast-paced environment to join their team as Data Engineer.The role can be performed remotely within Spain and also the English skills are important since the role will work within an international team based outside Spain.Specifically, this role will focus on data platform enablement through data engineering and documentation, tools and technology implementations. Selected candidate applies developed subject matter knowledge to solve common and complex business issues within established guidelines and recommends appropriate alternatives. Works on problems of diverse complexity and scope. May act as a project leader providing direction to team activities and facilitates information validation and team decision making process. Exercises independent judgment within generally defined policies and practices to identify and select a solution. Ability to handle most unique situations. May seek advice in order to make decisions on complex business issues. Responsibilities:  Implement and deploy secure and performant data architectures, enhancements, updates, and programming changes for portions and subsystems of data pipelines, repositories or models for structured\/unstructured data.Analyses design and determines coding, programming, and integration activities required based on general objectives and knowledge of overall architecture of product or solution.Writes and executes complete testing plans, protocols, and documentation for assigned portion of data system or component; identifies and debugs and creates solutions for issues with code and integration into data system architecture.Leads a project team of other data engineers to develop reliable, cost effective and high-quality solutions for assigned data system, model, or component.Collaborates and communicates with project team regarding project progress and issue resolution.Represents the data engineering team for all phases of larger and more-complex development projects.Provides guidance and mentoring to less experienced staff members.\nExperience & Qualifications:  B.S. and MSc degree in Computer Science, Mathematics, Physics, or other relevant disciplines.Experience using data engineering tools, languages, frameworks to mine, cleanse and explore data.Strong understanding of database technologies and management systems (Databricks).Strong understanding of cloud-based systems\/services such as AWS and MS Azure.Database architecture testing methodology, including execution of test plans, debugging, and testing scripts and tools.Fluent in NoSQL & relational based systems.Fluent in Python and other Data science languages and tools (Jupyter Notebooks and\/or Google Colab).Experience on API\/OpenAPI \/FlaskExcellent written and verbal communication skills; mastery in English and local language.\nScope & Impact:  Collaborates with peers, junior engineers, data scientists and project team.Typically interacts with high-level Individual Contributors, Managers and Program Teams.Leads a project requiring data engineering solutions development."}
{"job_title":"AWS Data Engineer","company_name":"Devoteam","location":"Portugal (Remote)","job_link":"\/jobs\/view\/3764249222\/?eBP=CwEAAAGMPGxmqwfVP79gIzG5SDlVQN_9UpIKVK3M6rITO5KluwyssV_U2ldYTtEjk4fBZ47GId6CzW9pEGiw_7ffWHpXnB5sfv9OscThUkGOXtluH8UN74XGHKwL6QdQRXn6OGTMijkrnRIbBio2IzadNxNyNW7E33m4X6KmUkq7lQd43bNKNH9i5MIunEAtBJBjW9gdNO331FSIa7NKBqsbf4ttGn4CZ8LJKMPt5C0IkpyWaGix-YCyhg2z6pzbVMfQYGbnOuduvW4JtBizouSF_Cip6IDjz9RyLX8822XWtIPZTlWmuNKKKiqLEtXrwCs9yiVi-G-qdmHib-5GN2e1-1bQ9QZASDfDcRkXFOHUmQhggR1c1wZttY2v8exw_BZhvjs&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=AMg%2FKcgUXvessw3I6VUHMA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3764249222","job_description":"About the job\n            \n \nAWS Data Engineer, RemoteAbout DevoteamAt Devoteam, we believe that technology with strong human values can actively drive change for the better. Discover how Tech for People unlocks the future, creating a positive impact on the people and the world around us. We are a global leading player in Digital Transformation for leading organizations across EMEA, with a revenue of \u20ac652M. We believe in transforming technology to create value for our clients, partners and employees in a world where technology is developed for people. We are proud of the culture we have built together. We are proud of our people at the service of technology. We are proud of our diverse environment. Because we are #TechforPeople. Join our multidisciplinary team of Cloud experts, Designers, Business consultants, Security experts, Engineers, Developers and other extraordinary talents, spread across more than 18 EMEA countries. Become one of our +8.000 tech and business leaders on cloud, data and cyber security. Let\u2019s fuse creativity with technology together and build innovative solutions that actively change things for the better.About the job:We are currently looking for a Data Engineer to work with us.What we're looking for: Experience with AWS services such as Amazon S3, EC2, EMR, Glue, Lambda, Kafka, and KinesisUnderstanding data modelling, data warehousing, datalake, and data pipelines conceptsExperience with ETL tools such as AWS GlueSQL and NoSQL databases, such as MySQL, Postgres, MongoDB, or DynamoDBProficiency in Python and Unit testsVersion control system Git and Git pipelinesKnowledge of security and compliance best practices for handling sensitive dataAWS Gateway API knowledgeWorking with file format like XML, JSON, parquetFluency in English\nDoes this sound like you?Come build with us, innovative solutions that actively change things for the better.Apply today! Send me your CV sara.fialho.nunes@devoteam.com"}
{"job_title":"Senior Data Engineer","company_name":"SNGULAR","location":"Spain (Remote)","job_link":"\/jobs\/view\/3765038357\/?eBP=CwEAAAGMPGxmq99lXAHj4-MsLrJcrOgdG9N7tsuJlkKrByXMpZt5eY30C2u8puJzLgkMPEk4rsCyslYuOtxeYDmxu2D5XqKx1iwrjcFTpF-4inmjttAjeHxA4rgSAxZXNy7Kdt1Ks29_lWiAt5RQhOidvRxy77DZP1Rg5iQ68ThIi7rlVpHQJyoSxgEVybK1eFuABDdgOU9NPBn_O2Qdc4_zu4L7NV8PLLzhOEqrHG6MtGu_2p3bpIubYbpt_cKTlBy78LI4NLdvae_6oNclzxQRLInDPb3CWLi0N2rY7SDYt4l8PpQ_64GQNQJiYXKcmaFj5fOkcThCVba79uVI6rYThwcLA_uYGGUDEdXDZ4xP0tBY0LxA2GCUJ1_mVYDgA59a-Wk&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=QXE9pzbwIrj2r4aRc71HhQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3765038357","job_description":"About the job\n            \n \n\u00bfPOR QU\u00c9 ELEGIR SNGULAR?La gente viene a Sngular atra\u00edda por los proyectos, que usan tecnolog\u00edas punteras, pero se quedan por los grandes profesionales con los que trabajan. Y adem\u00e1s porque ofrecemos esto: Acceso a formaci\u00f3n continua: presupuesto individual para formaci\u00f3n, obtenci\u00f3n de certificaciones, 2 d\u00edas libres para asistencia a eventos, acceso ilimitado a Udemy, clases de ingl\u00e9s.Plan de carrera y seguimiento 1 to 1.Flexibilidad horaria, full remote, posibilidad de trabajar desde nuestros Hubs.Jornada intensiva en julio y agosto.22 d\u00edas de vacaciones + d\u00eda de cumplea\u00f1os + 2 d\u00edas de asistencia a eventos t\u00e9cnicos + 24 y 31 de diciembre.Wellbeing pack: Ayuda para la mejora del bienestar.Retribuci\u00f3n flexible.And last, but not least: \u00a1porque somos muy sngulares! Tenemos Tutti Fruties todos los viernes (ya te diremos en qu\u00e9 consisten), fiestas, espacios donde podr\u00e1s expresarte, proponer cambios y ser part\u00edcipe de ellos (lo que nos gusta llamar #challengeyourcompany).\nEn Sngular nuestro prop\u00f3sito y valores nos han dado como resultado una empresa con una cultura plural, donde trabajamos con respeto a todo el mundo, donde existe una igualdad de oportunidades real, donde nos enorgullecemos de ser proactivos, trabajamos con humildad e intentamos mantener siempre un sano esp\u00edritu de equipo, sin perder nunca el buen humor.Conoce todo lo que hace de Sngular un #BestPlaceToGrowTrabajamos con clientes que ya conoces \u2014porque usas sus productos o servicios todos los d\u00edas\u2014 en pa\u00edses como Espa\u00f1a, M\u00e9xico, EEUU o Portugal. Si te apetece vivir un mont\u00f3n de experiencias, sin tener que cambiar de equipo para conseguirlo, en SNGULAR te vas a sentir como en casa.\u00bfA QUI\u00c9N BUSCAMOS?En SNGULAR queremos ampliar nuestro equipo con la integraci\u00f3n de varios Senior Data Engineers para diferentes proyectos. Para apoyar con funciones,entre otras, como gestionar las ingestas de datos desde Snowflake hacia Tinybird y la exposici\u00f3n de datos a trav\u00e9s de APIs tambi\u00e9n en Tinybird.Se requiere experiencia previa trabajando en proyectos donde manejases grandes vol\u00famenes de datos y donde el rendimiento jugase un papel importante.Te podemos formar y certificar en Tinybird.\u00bfQU\u00c9 REQUISITOS T\u00c9CNICOS NECESITAS?Los b\u00e1sicos para todos los proyectos: Experiencia previa m\u00ednima de 4 a\u00f1os como Ingeniero de Datos orientado a Big Data para desarrollo de procesos en PythonMucha solvencia en SQLExperiencia en an\u00e1lisis de datos y transformaciones complejas y con grandes cantidades de datos.Desarrollo, gesti\u00f3n e implantaci\u00f3n de ETLs\nDependiendo del proyecto se valorar\u00e1 positivamente conocimientos previos: SnowflakeJava y Spring BootNodeJSGoogle Cloud Functions y Storage o Azure DatabricksScala con Spark\n\u00bfCUANTO VOY A COBRAR?En SNGULAR contamos con diferentes niveles salariales, que var\u00edan en funci\u00f3n del perfil y de las habilidades y conocimientos que aporta cada persona. En este caso, puede variar entre 35 y 45k dependiende del perfil.Cada a\u00f1o tendr\u00e1s una revisi\u00f3n, para documentar tu crecimiento como profesional y asegurarnos de que tu salario sea acorde a la misma.Si crees que SNGULAR puede ser una buena oportunidad para seguir creciendo a nivel profesional, inscr\u00edbete en la oferta y nos pondremos en contacto contigo lo antes posible para conocernos mejor."}
{"job_title":"Data Engineer","company_name":"Chili Piper","location":"Germany (Remote)","job_link":"\/jobs\/view\/3754245940\/?eBP=JOB_SEARCH_ORGANIC&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=Vq2ZQ%2Fr3lUjMpLqOB4w19g%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3754245940","job_description":"About the job\n            \n \nAbout Chili PiperChili Piper is a B2B SaaS startup. Our product helps clients turn inbound leads into qualified meetings instantly, helping revenue teams connect to buyers faster.Think Calendly. Except way better. Way more powerful. And with customers like RingCentral, Airbnb, Square, Intuit, Spotify, Twilio, and many other cool logos.We\u2019re growing fast. And we don\u2019t mean that in the cliche way. We are sitting on a fresh round of funding, and are ready to take over the world (in the most civil and appropriate way possible, of course).Position Overview: We are seeking a talented and motivated Data Engineer to join our team and play a key role in propelling Chili Piper to the next level of data-driven decision-making. As a Data Engineer, you will be responsible for designing, implementing, and maintaining our data infrastructure to support the analytics and reporting needs of the company.You\u2019ll primarily work with our Analytics Engineer and SRE team to define solutions as well as with business stakeholders across the company to understand their needs and build systems to unlock operational efficiencies or analytic insights.This role offers a unique opportunity to reassess our current data architecture and facilitate our transition to a higher level of data maturity. You will also take charge of evaluating and implementing the latest data engineering tools and technologies to best meet the evolving needs of our team.What You\u2019ll Do: Maintain and improve existing data pipelines and build monitoring systems around them. Work with the team to define our data architecture and infrastructure. Develop an understanding of our data model and optimize our data models and pipelines for scale. Design & build data models using SQL & dbt. Ensure system security and data privacy compliance. Improve existing systems' performance, observability, reliability, and scalability. Configure warehouse ingestion tools (e.g., Snowpipe) and provision, maintain and optimize our data warehouseDevelop and maintain a scalable, robust and efficient data platform serving analytic and operational needs across the organization. Work independently and share your knowledge across the business and mentor colleagues in areas of deep technical expertise. Working with product owners and stakeholders to gather requirements and translate them into technical requirements as well as providing timely updates on progress and highlighting relevant risks or opportunities. \nWho You Are: 4+ years of software development experience, preferably as a data or backend engineer, maintaining and working with data pipelines & ETL processes on big data environments. Deep knowledge with data warehouses like Snowflake, BigQuery, Databricks. Can reduce latency of end-to-end pipelines through data orchestration in addition to incrementalization or streaming. You have strong knowledge of common data integration patterns (CDC, ELT, etc.)Proficiency in a programming language such as Python, Go, or Scala. Expert SQL skills and knowledge; can write complex queries, comfortable with window functions and can design \/ have strong opinions on database design\/schema. Hands-on experience in using event-driven architecture with Kafka. Experience with a job orchestrator (Airflow, Prefect, Dagster)Demonstrable understanding of how to expose data from systems (eg. through APIs), link data from multiple systems and deliver streaming services. Initiatives around performance optimisation and cost reduction. Solid understanding of security best practices, accessibility, compliance, and GDPR regulations. Experience in modern software development tools and ways of working (Agile methodologies, Git, CI\/CD & DevOps tools, infrastructure as code, metrics\/monitoring, etc.)Thrive in ambiguous situations, possesses a proactive problem-solving attitudeAutonomous in approach and experience mentoring and advising other team members. Communicate effectively with Product Managers , Engineering and Commercial teams to translate complex business requirements into scalable solutions. \nDesired experience: Experience with batch \/ streaming services. Strong perspective on analytics engineering development cycle (data modeling, version control, documentation + testing, best practices for codebase development)Knowledge in modern and classic Data Modeling - Kimball, Data Vault, OBT etc. Experience with the modern data stack (Fivetran \/ Snowflake \/ dbt \/ Looker \/ Hightouch or equivalents)Experience with product \/ marketing analytics would be an asset. \nAdditional InformationWhy you'll love being a part of our team:Our team loves Chili Piper because we\u2019re building the company of the future. Work with an immensely talented global teamWork in a business that\u2019s run fairly and transparentlyCompetitive pay based on market rate wherever you liveWe lead by example--showing industry peers and leaders how to innovate, improve, and grow--while having fun\nHow we work: Freedom and flexibility. We\u2019re a 100% distributed team working from around the world, and we've been fully remote since 2016. Our team members can work from wherever they want in the world, as long as they show up on our weekly all hands meeting on Zoom. Solve interesting problems. The software landscape has exploded. There are dozens of solutions for each problem. We want to be different. We come up with new angles on existing problems or invent better solutions to help companies with their sales and marketing. Then we turn these ideas into beautiful, smart software. Autonomy and ownership. Working on a distributed team means you don\u2019t have someone micromanaging you or looking over your shoulder to make sure you\u2019re getting things done. We\u2019re a team of do-ers who take full ownership for their results. Be helpful. Our first value as a company is help. Help our customers be successful. Help our prospects get the right information and make the right decision whether or not it includes our products. Help our team members reach their full potential. \nThe perks: Unlimited VacationGenerous Health, Dental, and Vision InsuranceAny equipment\/software\/tech that you need to do your job"}
{"job_title":"Senior Data Engineer","company_name":"adesso Romania","location":"Romania (Remote)","job_link":"\/jobs\/view\/3772509364\/?eBP=CwEAAAGMPGxmq5O64DpAl-zhdbMbVZRuJsjyqwnKcUej662y8yFVPX4a3PEQhulFkOQkmlQ59lle1VAI-iYzEGiSwhtYjMrMySvS3gJwM0UOQIsAkswcLBL-lmUHFY5LJSnL7AfkbCkmCXbYdn8gtNWLf17DdzsXA0kMpa0GVKF9Z20FdUeX5dxSXavn5BEub9Uhfc5-FjfZOAKMJ7KfZfWZvEplnAZFFjB--1aNhMtGxyUhp0hKnoZ43kv_w5q8BmmAt5hFvBXu6dp6R13H3jbwPP3AcRBhWyeMfYQf3oPhFEYFzIpMM6_RdOQlwQaZS-TzV42yZwJheICMfkGwFz0OBrzODei1z7d8nts2xzyqT1MTTcr4raD11-6teKmcF6yo&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=pjTaT76zji3bvunEbIMPTQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3772509364","job_description":"About the job\n            \n \nAs a Data Engineer at adesso Data & Analytics, your morning routine is an efficient, unrelenting ETL process. You have a data mindset and get satisfaction from designing and organizing databases and collecting, transforming (and structuring) designs and unstructured data. Do you oversee customer processes, and can you translate them into solutions within (cloud) data platforms? Do you have a good ear for both substantive and technical requirements and have realistic expectations? Then we are looking for you!What you are going to doAs a Data Engineer at adesso Romania you are part of a dynamic environment with fun and very talented colleagues. You will work at adesso Data & Analytics (DnA) and you will contribute to the growth and development of the organization.At adesso Data & Analytics, you help our clients become more data-driven by building data pipelines and converting the raw, unstructured data into formats that help other data professionals, such as data scientists and analysts, analyze. This work includes creating and maintaining an infrastructure that automates the building of analytics and machine learning models. Our clients consist of medium and large organizations.Knowledge and experience neededAs a Data engineer at adesso Romania you get your satisfaction from structuring and automating data. You get energy from designing, setting up, improving and automating data pipelines. You like working in a small close-knit team within a scale-up culture.Besides the daily fun, you like to brainstorm with colleagues. You have good communication skills and are also able to communicate with non-technical stakeholders. English speaking is necessaryRequired skills & knowledge Strong analytical skills in key disciplines such as infrastructure, cloud and back-end. Nice to have: IaCExtensive experience with Microsoft BI stack: SQL Server, SSIS, SSMS & SSAS Experience with Microsoft Azure, eg Azure Synapse, Azure Data Factory, Azure Databases and HyperScaleExperience with Spark, Python, PySparkExperience with CI\/CD, GITUnderstanding of data platform architecture (Data Lake \/Data Mesh \/ Data Vault)Great communication skills in English \nOur commitment to you An established business with the soul of a StartupA digital workplace experience with flexible working hoursAgile & lean organization: Optimized work processes to eliminate waste and horizontal hierarchyGlobal mobility and international rotationCompetitive salary, private health insurance, and comprehensive benefitsA bonus system based on company and individual contributionsStructured professional development with both soft and technical training programs, workshop opportunities and language learning support\nAbout adesso Romaniaadesso is providing IT delivery, consultancy and software solutions with international teams. The new subsidiary, adesso Romania, is based in Bucharest. It is to begin supporting adesso\u2019s international delivery network (www.adesso-smartshore.com) in staffing and logistical terms effective immediately.Around 600 of the more than 10,000 employees in the adesso Group already work for customers in Europe at adesso\u2019s SmartShore locations in Turkey, Bulgaria and Spain. Main technology stack is Java, .NET, FE, Mobile App Development, MS Power Platform, and DevOps.The IT experts work on digitalization projects as part of international project teams. Some of their work is done on-premises at customer locations \u2013 especially in the German-speaking countries \u2013 but some are also performed through virtual collaboration from adesso\u2019s individual SmartShore offices in Istanbul, Sofia, Barcelona, Madrid, and Jerez."}
{"job_title":"Data Engineer","company_name":"Fujitsu","location":"Lisbon, Portugal (Remote)","job_link":"\/jobs\/view\/3772579851\/?eBP=CwEAAAGMPGxmq0PGE-lwCGW5dTHc6P5JZBpFgkpbk3R254buElUw8zAUC1M6EEwM_Qy2WYr5njMjqwXAhi7AsWEqvSNQqbDxSrn80VE0HppPq_cWckOlnmz67DFryR3vJppPGo3BGAoVRHEe5Ljcm95YG1LUwKtlkVRjmqOtBzesfkhINm4f9CTpkrL8YYk1xRBR4QMvEKokWHiYuqF1pTQEmQl_asWWHdqO5I0VJU1sbmFZbY8PnpH5qsGM7edjsPt1ZaPtC4nF3blioEtwdGCjHyxAP-ewHDO9TlBGplVBs_gGqICcvy93bzrIH0W6gU1CP4YzALmVe-FTt9C58TbMbaQ9CUVj6X8aLBN1YI-8CyP4zgGEI-06NPzUvjN-Ky6edDI&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=1DrqeM9fiM%2Bg2uiFofWJNw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3772579851","job_description":"About the job\n            \n \nShape your worldAs Data Engineer you will support the programme globally as part of the Digital Transformation (DX), a new team coordinated centrally with new roles. The team will be responsible for developing, customizing and managing intelligent systems. These tools and technologies will drive the global wide road-map defined by GD. You will work collaboratively with an analytics team to look at data, find relations and give data driven recommendations that address key business questions.General Successfully completed studies in (business) computer science or a completed apprenticeship with a focus on computer scienceGood communication and presentation skillsAnalytical thinking and self-dependent way of workingAble to work in an agile team and to share skillsAble to work in a disciplined way and to follow short term targetsExperienced working in development, architecture or implementation teams combined with experienced working in operational teamsIdentify and make recommendations poorly performing queriesData driven mindset and passionate about numbers\nSkillAt least three years of professional development skills in the following Microsoft Business Intelligence tools are required:2-3 years of experience in the areaStrong data modeling and SQL experienceExperience integrating with SQL Databases, Web-Services, API\u2019s and data dumpsData cleaning and data wrangling tools used to reshape the dataAble to co-relate different sources of dataExperience in designing and maintaining data models, including documentationExperience working with SQL Server Integration Services (SSIS) and ETLExpertise in performance tuning of SQL queriesExperience in improving accessibility, performance\/efficiency, and quality of data"}
{"job_title":"Lead Data Engineer","company_name":"Luxoft Bulgaria","location":"Sofia City, Bulgaria (Remote)","job_link":"\/jobs\/view\/3772524546\/?eBP=CwEAAAGMPGxmq8e7Q8s6bImUm1nAnb0IpZ-y5Ue9aMe82QpFlucg6D8LJS8ueAbTMw_vzVwDH14pIbxn6Ef2jffcCAAZdbEvyyRUXjavJaGqzH2PE1AJTzRnD1cu_udrF4gPG8r2VDPxCHDa-KDBiXLuZwFPZtuZrUgK65B0EFUNolu4o4ssFREx6i3RnZjXg14j0mQxIRKhPjVJx5qW_xbw3B-GuG6pO1M26pMvGKyyPpfDyoVE_5bd09mtn81nlgLU_2Qby0NZ_Pu1axDN2w1YdYVCo8bAt6PIValayEVUYwregFJJD8QQ_b14mRFLkIiRSC4JhrHOPcJw6pphQgRypV4R0EZwuc3AmjCGo-aXAr5_2LMQbijCE9xQ9Fd8lmMZ&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=komziWEyqIWRj%2FA2amtGUw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3772524546","job_description":"About the job\n            \n \nProject Description: We are a Fortune 500 global IT services leader. In Bulgaria, we are among the largest employers with over 4,000 employees working on the company's entire IT portfolio.We are flexible - we provide everything you need to comfortably work from home, but we also keep our offices open for collaboration, meetings, and building a strong team spirit.We tailor everyone's development path to their individual interests through training and additional certifications.\n Our experience and desire to grow, our mission, and our values \u200b\u200bcreate an environment where ambitious people become successful at home. At home - in Bulgaria.\nDo you have experience with DWH, ETL, SQL and Cloud?Do you want to gain New Skills and Certifications?Learn from the best - join our Analytics Data Engineering team!We are growing our Analytics Data Engineering team which is based in Sofia but also offers fully remote positions! We live in a data-driven world where data can be leveraged for reporting & analyses and for data-driven products and applications. Our team has strong experience in Analytics solutions and Data Engineering based on the latest cloud technologies.\n Here you will gain hands-on experience working with world-famous brands and Fortune 500 companies in a diverse team where everybody has a lot to contribute with - including yourself! The team is constantly growing with over 60 experts in the field.\nResponsibilities: Analyzing, designing, and implementing data warehouses, data lakes, data models and data pipelines Building the code and logic required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL or programming languages, working with big data Building analytics solutions that provide valuable insights for clients and end users Working in an agile project team which has specific goals and deliverables\nMandatory Skills Description:  2+ years of relevant working experience Snowflake experience is mandatory AtScale Experience with ETL tools such as SSIS, Informatica, DataStage, Talend, Pentaho Experience with Data Warehouse technologies Experience with SQL, T-SQL or PL\/SQL Desire to grow skills in the Cloud technologies used for Data Analytics such as Azure Synapse, Azure Data Factory, AWS Redshift, EMR, S3 or Databricks Fluent English\n Nice-to-Have Skills:\n  AWS or Azure Apache Spark or Databricks Python or other programming languages working with data Azure Data Engineer Associate certificat\u0435"}
{"job_title":"Data Engineer","company_name":"EXCELIA","location":"Spain (Remote)","job_link":"\/jobs\/view\/3772070050\/?eBP=CwEAAAGMPGxmqyR9OsNRnD_CGITPrWuEF0TOJWRMR-5fJjuKgDbOrWEWdZ2_QmwHFbm_toLPFVZrV_S4nrpR16e2RtBXqqIaJxxqGqpFqW9s4crhaABa2IsifU_oW9P0I39gThq24sdfdsXLZSfB39zqimO1OWvbd_lI6OJULm-4MqKfsWeiHwz0BKEvkpOCT_Gf_4bZTeZGHz8ksiNOYRd7n6QQRRk-q9EdwEr0PeW4-eC_Ywc-oUKkOLqy-8vcHQ-k0XC-0wtCRmGevjLOHKS1PUGLhVC0Gk6oxTJ-3wO6j-7GiXgU_NByX1SS5TU8o3aaML07LOpfcAcToM1AdaC6FAKXx3ci2KiKf3IU1GAvCwzNIrNRHhEFgGgNO8yUhSrUrlA&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=kCysRRy%2BICfKToJgn1XoUw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3772070050","job_description":"About the job\n            \n \nexcelia es una firma multinacional de Consultor\u00eda, Tecnolog\u00eda y Servicios profesionales con m\u00e1s de 20 a\u00f1os de experiencia. Prestamos servicio en m\u00e1s de 50 pa\u00edses de Europa, Am\u00e9rica Latina y Estados Unidos desde nuestras 10 oficinas propias.Actualmente estamos en b\u00fasqueda de un Estamos en b\u00fasqueda de un talentoso Data Engineer para unirse a nuestro equipo. El candidato ideal debe cumplir con los siguientes requisitos:Habilidades T\u00e9cnicas: Experiencia laboral: 2-4 a\u00f1os.Experiencia en Azure Data Factory.Conocimientos de Azure DevOps.Experiencia en entornos Azure Data Lake.Dominio de DatabricksSpark y Scala o Python.\nResponsabilidades: Desarrollar y mantener soluciones de procesamiento de datos.Colaborar estrechamente con el equipo en proyectos relacionados con Azure.Garantizar la integridad y seguridad de los datos.Participar activamente en la implementaci\u00f3n de procesos ETL eficientes.\nRequisitos Adicionales: Capacidad para trabajar en equipo y comunicarse efectivamente.Habilidad para adaptarse a entornos din\u00e1micos.Fuertes habilidades anal\u00edticas y resoluci\u00f3n de problemas.\nSi cumples con estos requisitos y est\u00e1s buscando un nuevo desaf\u00edo en el mundo de la ingenier\u00eda de datos, \u00a1Haz clic en \"inscribirme\" y forma parte de excelia, una compa\u00f1\u00eda internacional donde desarrollar todo tu talento!"}
{"job_title":"Freelance Data Engineer","company_name":"Orbis","location":"Belgium (Remote)","job_link":"\/jobs\/view\/3766522651\/?eBP=CwEAAAGMPGxmqzinFhhbrMur1SV-wVdILobp9cSWjhg-ob2z4ldVGRZg9Q9Iewf0JLimARb26OhHKHDpMSineNr-4almR66yYFTsoM9PpaGsaWEqRiIz7EJUHBmYXtvsE2fdMV1hGJ_8bEfY76RPop5IUbteZogMkkKckw4ia0I0NfRev4YZKACOdXi1FQ9EcAA0QQ1nQ1_ov4_5HsTW_PXpTHgAhIJg5tJz5JBnUQ95pJA9L6qyGn1UJKvOBxGHSm0gzY3orAfAmCbH6r7O3UjiEzhwQUl4NEzDxUyTs8j3FSvmF8klWFW0a06q28F2Ynpg__bWfN7H4bHOdtc7DBgKwDyWp_s-rMieTuuQ_RDY71gGbkj0n6QOYiwdAuRbejGptreNtQ&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=C%2FA5dDZEh82NpO1mXBL7Lw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3766522651","job_description":"About the job\n            \n \nFreelance Data Engineer - Globally Leading Tech Consultancy \u2013 Azure, Python\/PySpark, ETL\u20ac700 - \u20ac800 per day - 12 Months ContractBelgium (Remote)MUST BE BASED IN BELGIUM AND SPEAK DUTCH TO A PROFESSIONAL\/FLUENT LEVELCompany:Orbis have partnered one of the biggest global data consultancies in existence. They provide data solutions and empowerment through data for a wide variety of their clients. They have over 100,000 employees in over 60 countries, and are looking for an experienced Data Engineer to join their expanding European function.Role:As a Data Engineer, you will be: Designing and deploying both batch and real-time data pipeline for Azure Data LakesImplementing data quality checksCreating and improving data lineage mechanisms (such as monitoring dashboards)Work on data archiving and data recovery projectsCommunicating and working with stakeholders and non-technical employees.\nRequirements: Solid experience with the Azure Ecosystem (preferred)Hands on coding experience with coding with PythonExposure to BI technologies like ETL\/ELT, data warehousing, data lakesHands on experience with other essential technologies such as SQL and Spark\nBenefits: Highly competitive salary with full benefits packageFlexible working hours with the opportunity to work from homeBeing part of an elite team of experts in a collaborative environmentTailored training and development with access to a wide range of online resourcesWorking with modern technology with industry leading firms\nIf you're a Data Engineer wanting to work on exciting, high-value projects who values a strong and progressive culture, please do not hesitate to apply!***SPONSORSHIP IS NOT AVAILABLE FOR THIS ROLE***"}
{"job_title":"Data Scientist \/ ML Engineer (LLMs)","company_name":"Codete","location":"Cracow, Ma\u0142opolskie, Poland (Remote)","job_link":"\/jobs\/view\/3778657373\/?eBP=JOB_SEARCH_ORGANIC&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=U8%2BUzB5qvA%2BP9ro08tB4iA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3778657373","job_description":"About the job\n            \n \nCodete is not just a software company, it\u2019s a place where tech enthusiasts can grow by doing what they love and feel valued for what they are. We\u2019re experienced, agile and versatile: we work with a wide range of technologies in projects from many different industries, and the majority of our team are senior-level specialists. At Codete, there\u2019s always something new to learn!You'll become a part of our Data Science team. At the moment, our primary focus is on utilizing Large Language Models (LLMs) in e-commerce, while also leveraging them to automate and enhance our customers' internal processes. Additionally, part of our team is focused on using machine learning in medicine. We have published two peer-reviewed papers.We offer: Flexible working schedule Working with Natural Language Processing (NLP) Implementing ChatBotsWorking with Large Language Models (LLMs)\nResponsibilities Scrapping and preprocessing dataImplementing Optical Character Recognition (OCR) scriptsPreparing words\/documents embeddingsChatBot implementation based on OpenAI API, LangChain framework and othersChatGPT prompt engineeringUsing LLMs to extract information\/prepare reports based on documents and databases (SQL and NoSQL)Participate in brainstorming\nRequirements 3+ years of experienceKnowledge of Python Understanding of core machine learning conceptsFamiliarity with LLM-based solutions will be a plusEager to learn and cooperativeAble to communicate both in English and Polish\nBenefitsValues & Atmosphere  flexible attitude (including working hours) international business trips social events & awaydays support for your ideas\nPersonal development  external conferences technical & soft skills training switching between projects\/technology English classes internal library\nHealth & Relax  Employee Wellbeing Platform private health care multisport card sports events chill-out room fresh fruits & juicer\nKnowledge & Culture  open source initiatives Codete Mentorship Program R&D department\nThe data controller of your personal data is Codete Global Sp. z o.o. with its seat in Krak\u00f3w (30-527), Poland, ul. Na Zje\u017adzie 11. The data will be processed for recruitment purposes. To learn more please read an appropriate section of our Privacy Policy (Personal data provided for recruitment purposes)."}
{"job_title":"Data Engineer","company_name":"Nexters","location":"Cyprus (Remote)","job_link":"\/jobs\/view\/3765604146\/?eBP=CwEAAAGMPGxmq89ccIm7FU1LlyGFjVlYD5dMMsY3KnIvVfOSTuMtM5YIXqcrSHHA7O2F_KZf3omJrqdi8E3k0ExLny3q-CKlM0b8iZQIsH98pB15NyypRlr8IIKdNkXs0FHkC-3NbtAQNyvMW_j4kbq4iX4pDzpX23L-cRW4h8jxZaG_fSFmyqud06BtBr4uMiXoqzHTFNUQLg4kSwpQq--pYj9jfn5ER2zAQPFe4MEv_LWL8-6UWlSIVoqMP9vWA0W21j_XD2O9HW_L1LrB6VyQwDIYhfzgbdnhN65iHu1PEDQeuoGcRJfIMqJ-cySSWU8Elii2i9fUvClVgFY9j19y6SGJ0Sac4IWpCmRyotkEqXj63UP1-d-qDo5Ievkdz8-8&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=z2lcKVpMb9xs2V75DP5txw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3765604146","job_description":"About the job\n            \n \nNexters is an international game development company that strives to introduce the joy of core gaming experiences to casual players. In 2021 we went public and listed on the NASDAQ (GDEV). Nexters is part of the GDEV holding, which includes not only Nexters, but also Cubic Games, Dragon Machines, Royal Ark, Game Gears, and RJ Games studios. Our people work worldwide from offices in Cyprus, Armenia, and Kazakhstan or remotely. We want brilliant professionals who love building great games in a team with one of the best cultures.About your roleWe are the BI team, and we are looking for a Data Engineer. We currently work with data and visualizations, also dedicating time to process automation in UA. Moreover, we can propose cool projects internally and implement them. Want to become a part of our awesome team? Keep reading.What you\u2019ll be doing Retrieving data from multiple sources, combining and delivering it to various points, mostly in the form of a data source in Tableau Working in a team with another Data Engineer to create necessary aggregated\/served data for different clients Being a backup for BI Analytics in terms of report design in Tableau Assisting\/guiding Analysts who are less familiar with Tableau Promoting a data-driven decision-making culture (dashboards\/scorecards) at all levels of the organization\nWe hope that you have Experience in creating ETL processes (Tableau Prep \/ Apache Airflow \/ etc.) Knowledge of SQL and Python, AWS (ClickHouse) Proficiency in Tableau Experience in marketing analysis: GA, GTM, Yandex.Metrica, Roistat, etc.\nOur stack: Tableau, Clickhouse, AirflowWhat we offer HealthcareMedical care program (including dental service) or medical care compensation are available for you wherever you wish to work. The medical care program is also available for your family members if you choose to work from our official locations \u2013 Cyprus, Armenia, and Kazakhstan.Work, life, and balanceWe offer a fair amount of paid vacation days and sick leave. You can work at one of our comfortable offices in official locations or from home.SportsYou can choose various sports activities like yoga, football, and volleyball in our official locations.Relocation supportA relocation package is available for you if you decide to join us in one of our official locations.Skills improvementLet's learn languages: you can visit online English language courses. Greek and Armenian language lessons are available for everyone who works in Cyprus or Armenia. Our company encourages people of Nexters to take part in game jams, hackathons, and relevant conferences and meetups as expert speakers.EventsOur events are legendary \u2013 ask anyone who already works at Nexters. There are strategic sessions, workshops, parties, contests, and other activities every year.Community & ESGWe are proud of our local communities and support employees\u2019 social initiatives. Dream big, act big: Nexters contribute to gaming\u2019s positive impact on the world, hold a sustainability strategy, and take part in charity projects all over the world.\nWork formatIn one of the company's offices in Cyprus, Armenia and Kazakhstan or remotely."}
{"job_title":"Junior Java Developer","company_name":"Luxoft Romania","location":"Bucharest Metropolitan Area (Remote)","job_link":"\/jobs\/view\/3771905778\/?eBP=CwEAAAGMPGxmq0e9WJ4108kkbzwo5vH3rXJ6eZ6oVrB_9VGvFPEYhFjQJxKLDv8I-b64mW1DFN7HO3hfFfnsmx4kRGDSymlXlJDZALtXiDOuHhQm-7RnSwahqKR-09jjZbupKU9f46niJb783Frwj_N9rMfkpRrM-OHFZwsjkhxgEWAEiFToUQyVhPQg40NlyOa8M9gYKAOAcFE0ijz9PduEUGNzf30xCgEqbn2gBGKNHOkzYmQ9yNtUuOiog2fCwqmv71PFzqvEfuHNHw1MdzpCMEUyy3p0JAqip-xwpGzOkpDSTvaHCX6JyQ397cSGqpcIERpRbbBmBM6Ff-7Sxoe4U-8z_o9nAUb-V9P6CQ9e01X3UGWP5tXnDJMpigFvowiE&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=CUUnD%2BZyzBdSMJhnYJqXtg%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3771905778","job_description":"About the job\n            \n \nProject Description:The project is a rapidly growing engagement with a solid leader in the FinTech industry developing software solutions for trading, risk management and data processing. Join our Development Center in Luxoft Romania and become a member of our open minded, progressive and professional team. The software development is based on SAFe\/Scrum methodology and uses Continuous Integration\/Continuous Deployment processes supported by the adoption of DevOps, best engineering principles and XP practices like TDD and BDD. You will have a chance to grow your technical and soft skills, grow professionally and build a thorough expertise of the industry of our client. On top of attractive salary and benefits package, Luxoft will invest into your professional training including business domain knowledge, and allow you to grow your professional career.Our client software platform is used by the world's leading investment banks, asset managers, hedge funds, commodity houses and corporations to price, analyze and manage their derivative exposures for foreign exchange, interest rate, equity, commodity, inflation and credit derivatives.How we work: - The development processes are completely Agile. We are implementing SAFe, the most widely used scaling agile framework- You will be deeply involved in controlling the development workflow by defining, planning, building, testing and deploying the new solution functionalities- Once every 10 weeks the new business requirements are provided by the clients and development teams clarify, estimate and plan the work needed for the next period- Our strong focus is on building high quality software by investing in Continuous Integration, Continuous Deployment, multi-tier testing, code quality, Non Functional Requirements etc.- The results of your work will be used by the most important organizations in the Investment Banking industry- Every 4 Sprints you will have the chance to work on completely innovative ideas using any cutting edge technologies or frameworks for a whole Sprint- We are investing constantly in your professional, business domain and personal development by offering career path guidance and access to a wide variety of trainings.- You will be supported by our technical mentors, agile coaches, pair working with your colleagues and will benefit on a friendly atmosphere and a dedicated space for games and relaxationResponsibilities:The candidate will work in development team closely with the Paris and Bucharest consultancy teams to develop new functionality, rapidly solve problems and enhance existing aspects of the application.The main purpose is to develop applications in order to integrate with external financial providers and platforms and to model the functional flows involved in the communication between the Client's solution and these external systems.There might be cases when the candidate might go to Paris to work on-site or for training for 1-2 weeks period.Mandatory Skills Description:- Mandatory Computer Science Faculty \/ Cybernetics \/ Mathematics \/ Informatics graduated- Min 1 Years working hands on experience in Java- Java 8- Dependency Injection\/ Inversion of Control (Spring or JBoss)- Unit and Mock Testing (JUnit, Mockito, Arquillian, Cucumber)- Java Message Service (JMS)- Web Services (JAX-RS, JAX-WS)- Strong understanding of Design and Architectural Patterns- Apache Maven- Continuous Integration tools (Jenkins or similar)- Linux operating system- Stash: GIT Repository Management- Spoken English language is a mustLanguages:\u2022 English: B2 Upper Intermediate"}
{"job_title":"PL\/SQL Developer","company_name":"HCLTech","location":"Bucharest, Romania (Remote)","job_link":"\/jobs\/view\/3761437396\/?eBP=CwEAAAGMPGxmq_osVmFGdZP1H3h88Csx7bqk5x5b21-P7UqnHTCd0rTFGZv8XhynDwo8CY3D_aFRH1EnRQ0i4z-13IERNG-6RKrBt4ggMHdRJw5hWrWLfzwcwHcdnarNdH41EKXHjaSezKPTbtwgPWW5g0tDKenREWMr_R7cix_UCptjLQNaY9MM5w__Wohz5pX0Qxzcq9hgLMkFLRPldtWsjzMvKlz4RwVuBA3C5jk0IifQBWYv9DQuFiGU4A23jv8-JE7mbF2Wq83ciGZuAY5pspQqdpVmXvDFqr2mTpsPAi0tyde_-3MjNQMcAfk4cpC7G6dKhTHpmILFPsNhVYKxZ1PxJ3jNgZT3ZNZMVRLbEBkU2zDZ8LfdDSjZA6k6P1Xks5Y&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=iqx4ko1dt5640CC1yLFMYA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3761437396","job_description":"About the job\n            \n \nHello dear (eventually future) colleague,Alexandra here, a friendly recruiter of HCL Tech Romania. Below, I'll carefully let for you some details about this role and I am super excited to meet and get to know you better.About HCLTechWe are HCLTech, one of the fastest-growing large tech companies in the world and home to 225,000+ people across 60 countries, supercharging progress through industry-leading capabilities centered around Digital, Engineering and Cloud. The driving force behind that work, our people, are diverse, creative, and passionate, raising the bar for excellence on a regular basis.We, in turn, work hard to bring out the best in them as we strive to help them find their spark and become the best version of themselves that they can be. If all this sounds like an environment you\u2019ll thrive in, then you\u2019re in the right place. Join us on our journey in advancing the technological world through innovation and creativity.Actual context: We are looking for talented and motivated Oracle PL\/SQL Developers to form a squad ready to be supercharged by receiving comprehensive training and certification from one of the world's leading Banking and Wealth Management product companies in the world.On completion of the certification, you will possess the knowledge and skills required to contribute to the implementation, enhancement, and maintenance of company specific solutions for clients, and you will be deployed in global projects with teams spread across globally.*Desired start date: the 8th of January, 2024 What are the necessary skills? Good communication and interpersonal skills; Ability to take requirements documentation from end users; 2+ years of strong hands-on experience in Oracle. Any knowledge of Banking or Wealth management is a advantage. Experience using Oracle Packages; Must have good verbal and written communication skills, in English; Knowledge of working in Oracle relational databases; PL\/SQL development, PL\/SQL analytics and tuning skills; Understanding of both structured and unstructured data. \nWhat are the responsibilities?  Tune application PL\/SQL queries for performance optimization; Convert user stories into application logic; reports, printed outputs, and interfaces with other systems; Load data into tables; Profile server resource usage, optimize and tweak as necessary; Shadow write and optimize in-application PL\/SQL statements; Collaborate with other team members and stakeholders.\nRecruitment process steps: Phone HR Discussion Online Technical Interview Final arrangements and offer stage \nSpecial thanks for taking the time to read it until this point ;)Please apply with your CV and let's have a chat if you find this role being a fit for the upcomings of your career.*HCLTech is committed to protecting and securing the privacy and confidentiality of the Personal Data which it collects directly or indirectly from you when applying for a job at HCLTech either directly or through a third-party human resources agency. This notice (the \u201cNotice\u201d) outlines and explains how HCL Technologies Limited including its subsidiaries, local employing entities, associates, and affiliated companies [collectively referred to as \u201cHCLTech\u201d, \u201cus,\u201d \u201cour\u201d, or \u201cwe\u201d] will process your Personal Data in accordance with applicable privacy legislation(s).Candidate Data Privacy Notice | HCLTech"}
{"job_title":"Data Engineer","company_name":"Knowit","location":"Poland (Remote)","job_link":"\/jobs\/view\/3768262416\/?eBP=CwEAAAGMPGxmq0_A8qnIlXAwbiJVZ100A0Abige7WeKmzig5KXS6mxI9QVjx4NRIcNSmJPy4noC8LyR5DFdVcuUJHzE-j_Ppdd0dNyMjTG33mvB46jfDwg3k5xaE6wPNq_VdZUSVhwLTZwrfSawV_gRDc8I0wkkc89WJczzBasUFXGHfK4meU07Lgnhwjl0jv5M3a8rC0GclS8WxT6w_6ylEBU7U6kF4QF7Tl6tC5qSn4QpaiTnLE_8H-SJfY2R2oTVvus4TRWRF7y1XcHXpmUb-qqIh95dmrS6EgnAXT2ggyXsiU_AGVzIkr66HzYxGinxGWM13QSECOocbgLFziNl4as3xSfXkL6UaZHv4hyN_4sWnjFKds0q5ts1YM9lcodSQF-M&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=NUhLasHApiSfUA7f2zKfJw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3768262416","job_description":"About the job\n            \n \nJeste\u015bmy Knowit i w oparciu o skandynawsk\u0105 kultur\u0119 organizacyjn\u0105, zbudowan\u0105 na poszanowaniu \u015brodowiska, ludzi i r\u00f3\u017cnorodno\u015bci, razem tworzymy przyjazne i stymuluj\u0105ce do rozwoju miejsce pracy, w kt\u00f3rym zobaczysz technologi\u0119 z nowej, zr\u00f3wnowa\u017conej perspektywy.Nasze firmowe warto\u015bci w codziennej pracy t\u0142umaczymy na gr\u0119 zespo\u0142ow\u0105 i wsp\u00f3\u0142dzia\u0142anie przy realizacji \u015bmia\u0142ych projekt\u00f3w technologicznych, kt\u00f3re zmieniaj\u0105 \u015bwiat na lepsze. Swoimi softwarehouse\u2019owymi mocami wspieramy naszych klient\u00f3w w zr\u00f3wnowa\u017conej transformacji cyfrowej.Obecnie prowadzimy rekrutacj\u0119 do nowego projektu.Projekt:Poszukujemy osoby na stanowisko Data Engineer. Na tym stanowisku b\u0119dziesz pracowa\u0142\/a od surowych danych, poprzez \u0142adowanie i transformacj\u0119 danych, a\u017c po tworzenie raport\u00f3w. Zale\u017cy nam na osobie z du\u017cym do\u015bwiadczeniem w data processing, kt\u00f3ra potrafi (lub chce si\u0119 nauczy\u0107) korzysta\u0107 z Power Bi.B\u0119dziesz pracowa\u0107 w wykwalifikowanym zespole analitycznym, kt\u00f3ry wspiera firm\u0119 w tworzeniu raport\u00f3w oraz podstawowych, jak i zaawansowanych analiz. Data model i budowanie data structure to b\u0119dzie Twoja codzienno\u015b\u0107, dodatkowo urozmaicona wizualizacj\u0105.Oczekiwania: 3-7 lat do\u015bwiadczenia jako Data Engineer\/Analyst i\/lub pokrewne;bardzo dobra znajomo\u015b\u0107 SQL;umiej\u0119tno\u015b\u0107 zbierania wymaga\u0144;modelowanie rozwi\u0105za\u0144 Data Warehouse.\nMile widziane: znajomo\u015b\u0107 Power BI;do\u015bwiadczenie w pracy z rozwi\u0105zaniami chmurowymi Snowflake i\/lub Matillion;znajomo\u015b\u0107 Azure.\nOferujemy: Kontrakt biznesowy B2B (je\u015bli jeste\u015b zainteresowany\/a umow\u0105 o prac\u0119, zajrzyj tutaj - https:\/\/www.knowit.pl\/dolacz-do-nas\/data-engineer-uop\/);Mo\u017cliwo\u015b\u0107 pracy z biura (Warszawa), lub hybrydowo \u2013 w zale\u017cno\u015bci od Twoich mo\u017cliwo\u015bci i preferencji;Elastyczne godziny \u2013 dzie\u0144 mo\u017cesz rozpocz\u0105\u0107 mi\u0119dzy 7 a 10;Kultur\u0119 organizacyjn\u0105 opart\u0105 o dzielenie si\u0119 wiedz\u0105 i feedbackiem;Mo\u017cliwo\u015b\u0107 rozwoju Twoich kompetencji - szkolenia j\u0119zykowe, techniczne, kompetencje mi\u0119kkie, dofinansowanie certyfikat\u00f3w, udzia\u0142 w konferencjach na preferencyjnych warunkach;Mo\u017cliwo\u015b\u0107 skorzystania na preferencyjnych warunkach z benefit\u00f3w takich jak: Karta Medicover Sport, opieka medyczna w LuxMed dla Ciebie i Twojej rodziny, ubezpieczenie grupowe;Sprz\u0119t niezb\u0119dny do wsp\u00f3\u0142pracy."}
{"job_title":"BI Engineer","company_name":"Allianz Direct","location":"Spain (Remote)","job_link":"\/jobs\/view\/3761861332\/?eBP=CwEAAAGMPGxmqzawM8h-SqLYeiy9Jo_P_eoejFMy_DdHZPFfhUN8uMSdWl2j5wpTqgffmKO-6PGtrQW5cZ9UpfitK0G3xlzJ0lFWyHkdg1wHH93IkfNXnNGclrZI1V5qBrcif47Cul_kx2KSK_yLiGbN4PV8sjttNXoMsZRqS-e2ISYZ-__V9yKl8ZF_jVmFxRkNcKyifQn8BUxnFzfRhTgUogg9MBfzb_VKskSGVE0-_VPBNYgAK63pWYTzu_3L_yOEtx-4-HerguRXkbY2IPBwm1sZSJjvhDJJ4oGSOqtVmMu2n75l7onW3paZ3kmYb1bhR2p4u68j6jmGVNvJ0-kK3mrdJLhdz8bA_n33o2U5UOdBI-fVgPpjS0zCHnUMdYIetkA&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=bBbr0czxqbEjdacECj9mDQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3761861332","job_description":"About the job\n            \n \nThe world aound us is changing rapidly and so is the insurance industry. Now\u2019s the right time to make a bold move and shape the future of insurance \u2013 this is Allianz Direct! As a pan-European online insurer of the Allianz Group, launched in 2019, Allianz Direct is on its mission to become the most customer-oriented and efficient insurer on the market. Allianz Direct is truly changing the face of insurance, in customer experience, and in technology, processes, people and culture.  An international team of business experts and engineers who live and breathe an agile way of working, are seeking to improve and change the way you do insurance. Driven by customer obsession and love for data, Allianz Direct strives for delivering an exceptional experience with a personal touch. So, what makes Allianz Direct so unique? We believe in the power of simplicity and convenience and by doing so we have managed to set new standards when it comes to online insurance. We are a fast-growing technology company with an insurance license, and by fast, we really mean it \u2013 our brand ambassador Usain Bolt will agree on that one. Allianz Direct continues to grow, and this time we are looking for a talented BI Engineer to join our team. The ideal candidate will be responsible for designing, building, and maintaining cloud-based Data Products that can support the organization's data analytics needs. Tasks and Responsibilities: Responsible for building highly scalable data pipelinesEnd-to-end responsibility for new data products, including working closely with functional experts to gather requirements & defining KPIs, building & deploying new data products on our Central data platformResponsible for building & managing Power BI reports\/dashboards, KPIsHighly skilled in data modelling techniques, experience with bi-temporal modellingKnowledge of Lakehouse architecture is a plusStrong knowledge of SQL & at least one other programming language e.g. Scala\/Python\/REnsure the security and reliability of the platform by implementing best practices for data governance, data security and complianceDevelop and maintain documentation for Data Products, including data dictionaries, data flow diagrams, technical & user guidesDevOps way of working, build it, own it, maintain it\nWhat we expect from you: University degree in Information Technology, Computer Science or Data Science8+ years of experience in Business intelligence, data warehousing & data modelling5+ years of hands-on experience with cloud platforms, preferably with Azure5+ years of experience in Data visualization tools, e.g. Power BIHighly skilled in DAX & SQL, able to work with complex queriesExperience with Databricks and Kafka is a plusExperience with domain-distributed architecture is a plusFamiliar with the agile way of working Experience in insurance or finance industry is a plus\nSoft skills:  Strong communication skills and fluency with the English language You are a real team player You embrace change and have a problem solving mind-set. You are always looking for simple yet creative solutions Growth mind-set, you are eager to learn and are continuously looking for optimization and improvements in solutions you\/team built.\n In addition to the project, and since not everything is working, we leave you some of our conditions: Competitive salary.We have 26 working days off per year IT Hub is fully remote. Flexible start\/finish time.Meal allowance.You will also have access to the flexible compensation program that will make your life more comfortable: health insurance, public transportation card, Internet rates, and childcare vouchers.\n We at Allianz believe in a diverse and inclusive workforce and are proud to be an equal-opportunity employer. Allianz is committed to employment equality and therefore welcomes applications from all people regardless of gender identity and\/or expression, sexual orientation, race or ethnicity, age, nationality, religion, disability, or philosophy of life."}
{"job_title":"Data Analytics Engineer","company_name":"Workpath","location":"Madrid, Community of Madrid, Spain (Remote)","job_link":"\/jobs\/view\/3772942240\/?eBP=JOB_SEARCH_ORGANIC&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=D10gD64sBqfNQVnuPLtilQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3772942240","job_description":"About the job\n            \n \nWe are a Munich-based SaaS company and support leading enterprises with our software platform at every step from agile goal management with OKR to end-to-end strategy execution centered around outcomes. With the help of our technology, customers develop greater adaptability and effectiveness in strategy execution. This enables organizations to meet the demands of dynamic markets and a new working world. With user-centric workflow tools and its associated analytics suite, we link goals, metrics, and projects to center teams and organizations around shared outcomes. In addition, our international ecosystem of partners, training, events, and enablement content provides the desired culture change and internal knowledge building to holistically guide companies in their transformation.Workpath is backed by industry experts with many years of experience in leadership and technology. Together we shape the future of work. Join us now!YOUR ROLEOn our mission of transforming established enterprises into agile network organizations, we are looking for a Data Analytics Engineer (f\/m\/d) as we prepare to propel ourselves to the next level. By joining our team, you'll get the opportunity to work in a small, but highly efficient team.As a Data Analytics Engineer at Workpath you will actively work with other Data Analysts, Product Managers & Ops Devs to build data models, maintain data pipelines and visualize data in Tableau in order to guide customers to take the right decisions and discover interesting insights.IN THIS ROLE YOU WILL Challenge the concepts and data queries presented to you in order to make the best out of it for the customersDefine, create and document new dashboards that can add new value to our Analytics Suite productClean, transform and process our data to gain insights from itManage our databases and storage solutionsMaintain our pipelines for data transformationActively work on and own pieces of work in a combination of operative and strategic settings, such as conceptualizing and executing reports, defining formats and service products, working on strategic frameworks or support in setting up processes for our growing teamFurther develop our analytics principles and standards of clean data structures & visualizations, efficiency and maintainability\nYOUR PROFILE 2+ years working experience building data visualization (we use Tableau, so that is nice to have)2+ years working experience with SQL data modelling - dbt and version control systems like Git is plusGood expertise in PythonExperience having worked with data pipelinesNice to have - Experience in our data stack: Airflow; Dbt; Metabase; AWS\/Cloud, at least basics like S3, RDS; DockerDemonstrated ability to ensure data integrity and accuracy through regular quality checksHands on mindset and ability in regards to creating and producing output (e.g. presentations, concepts, reports etc.)Previous working experience in fast paced environmentYou feel comfortable with taking ownership for independent projectsGood communication & presentation skills in English\nWhat You Can ExpectSince work is a huge part of your life we want it to be interesting and fun. We work hard, we care for each other and always walk away satisfied. We constantly refine our approach and everyone has a say. If you like a challenge you will love it here. A strong & value-driven team and feedback culture, as well as collaboration in an agile working environment of mutual support and very flat hierarchies. A lot of personal responsibility, autonomy and creative involvement in shaping our growth, check our Youtube Podcast and listen to our team members. Unique insights into a fast growing SaaS startup and have direct impact on the transformation of leading corporates. Enormous growth and development opportunities through internal knowledge sharing sessions beyond the boundaries of your team. Competitive compensation in addition to benefits & perks. \nIf you made it until here you probably want to talk to us. Hit the apply button.About UsWorkpath is a B2B SaaS startup headquartered in the heart of Munich. Our strategic workflow and analytics software drives agile management and business transformation for customers like SAP, Metro and Scout24. Join our fast-growing team that is working on shaping tomorrow's working world by unleashing the potential of millions of employees in businesses all over the world.Apply now!Join our mission of shaping tomorrow's working world by unleashing the potential of millions of employees in businesses all over the world. We are looking forward to meeting you soon. In case you have any questions, don't hesitate to reach out to people@workpath.com"}
{"job_title":"BI Developer","company_name":"team.it","location":"Lisbon, Portugal (Remote)","job_link":"\/jobs\/view\/3759742970\/?eBP=CwEAAAGMPGxmq1WDiAtpHx4L3t3MlDGFJkP1nD1OcVFW1GtEAiLvZMgFDIqYj0CegDo6duPBqoo5WA1iEw99_sk7aZ2DNwbbJzMcL1E13VGimT2w5Sfo4p2QbsVm2ckLnCk1rYlneNwzAPxUtqQFFZvX2MVBgh4kGhZ65Jpx4bVEX2n1H3axcO3-HBap81ZV0zAP0Blrto7DDuhl20uUVvBFKfgWSpwpQ_mPWGQr4lIxPNarSI-y_NOwBD29MY4SFQ-UAAC7y_oOOijgOJZVPETd-g7cuwo3HwrpFgUZEZ9TIXgGLtEFKlhvkiSN6pI-zKnKxpehgenWtzeKNrBSTJy_mb8Srfp87qmP0J95NX3T6Q-BbaHQegievtr9U8zVEyxIH3E&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=PLgDDu7413XMu5fyu2FkIQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3759742970","job_description":"About the job\n            \n \nQueremos fazer diferente com o essencial. Regressamos \u00e0s origens focados numa estrat\u00e9gia de corporativismo sustent\u00e1vel. Work-life balance, beginner\u2019s mind e community involvement s\u00e3o a nossa identidade e o nosso ponto de partida para esta viagem.  team BI Developer, \u00e9s tu?- Tens forma\u00e7\u00e3o superior em engenharia inform\u00e1tica ou numa \u00e1rea similar?- Experi\u00eancia m\u00ednima de 3\/ 5 anos em desenvolvimento com Power BI? - S\u00f3lidos conhecimentos de Power BI, Snowflake? - N\u00edvel B2 ou superior de Ingl\u00eas? Nota: (Localiza\u00e7\u00e3o - Lisboa \/Porto)  team BI Developer, somos n\u00f3s? - Uma estrutura horizontal. Todos temos uma palavra a dizer e todos somos ouvidos. Queremos pessoas ambiciosas que nos ajudem a alcan\u00e7ar o que ainda n\u00e3o foi feito. - Acompanhamento personalizado. Valorizamos e privilegiamos um acompanhamento pr\u00f3ximo e regular, somos uma equipa desde o primeiro dia. - Pacote de benef\u00edcios amplo e flex\u00edvel. Seguro de sa\u00fade, seguro de vida, descontos e benef\u00edcios, plano de telecomunica\u00e7\u00f5es e muito mais. - Apostamos na forma\u00e7\u00e3o e na tua carreira. Forma\u00e7\u00e3o certificada, plataformas de forma\u00e7\u00e3o online, centro de exames Pearson VUE... Apostamos em ti! - Privilegiamos o teletrabalho. Acreditamos que o teletrabalho \u00e9 uma ferramenta muito \u00fatil para a gest\u00e3o das nossas vidas e para o equil\u00edbrio entra a nossa vida pessoal e profissional.  - Sustentabilidade e envolvimento comunit\u00e1rio. Queremos dar significado ao nosso trabalho e investir num projeto de consultoria inclusivo. Para isso, precisamos da tua ajuda. team.it, back to basics! Embarcamos juntos?"}
{"job_title":"Senior Data Engineer","company_name":"GSK","location":"Pozna\u0144, Wielkopolskie, Poland (Remote)","job_link":"\/jobs\/view\/3765414449\/?eBP=CwEAAAGMPGxmq-7hH_3u2cUyvGLO-NccWhrBvNho4tgDZfKTC1pp18IRpbMQEI60k4GLZ107DmbaBAHHDRNU2cEKuKsjcyz6bcgr6ueTnlSjALNJ3URne7x7T4eFEwZQm0NaHVU1xzVa78u3TGvRP6rNpd_gJCwLW4J047sKGd8R4xJV-5ZhHDPPliwTTpX0WeOw8uOpoTjlESrhKc_vauxMMvEC1-b678dGeZ7SuLWUkuPx8-Wn0tChqCKa96FbdiO0a8PhE6cC3-iGsWln1TVt0vsOzFLC4z325QP0GHU2S5B8CCYFfH2DL6g9CttzNxF6RDxlD6IHI_X8eWCUWTwemo_R0Q9CCnOkJHzv0Fw5e1XinbLYjegFaF18Bp0M6LH4G9g&refId=Toz1fZ4qGcmLxfljivNkEA%3D%3D&trackingId=dwHjxVVFZccJ9Hy8TTvP9A%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3765414449","job_description":"About the job\n            \n \nSite Name: Home Worker - POLPosted Date: Nov 15 2023Come join us as we supercharge GSK\u2019s data capability!At GSK we are building a best-in-class data and prediction powered team that is ambitious for patients.As R&D enters a new era of data driven science, we are building a data engineering capability to ensure we have high quality data captured with context and aligned data models, so that the data is useable and reusable for a variety of use cases.The R&D Digital and Tech remit has expanded over the past 2 years, and to position GSK for the future, The change will strengthen R&D Tech, to provide more strategic impact, focus, accountability, and improved decision making in the use of Digital, Data and Analytics (DDA) to strengthen the pipeline.The Senior Data Engineer should demonstrate core engineering knowledge\/experience of industry technologies, practices, and frameworks such as Data Mesh and scaling data platforms, containerization, cloud-based platforms, data analytics, and data streaming.Key Responsibilities: Using Azure cloud services and GSK data platform tools to ingest, egress, and transform data from multiple sources.Produces well-engineered software, including appropriate automated test suites, technical documentation, and operational strategyProvides input into the roadmaps of upstream teams (e.g., Data Platforms, DataOps, DevOps) to help improve the overall program of work Fully versed in coding best practices and ways of working, and participates in code reviews and partnering to improve the team\u2019s standards Adhere to QMS framework, Security & Regulatory Standards, and CI\/CD best practices and helps to guide improvements to them that improve ways of working Supporting engineering teams in the adoption and creation of data Mesh best practices.Maintains best practices for engineering and architecture on our Confluence site. Pro-actively engages in experimentation and innovation to drive relentless improvement \nWhy you?Basic Qualifications:  Proficient with at least 3 of the below skills and can demonstrate knowledge and value with relevant experience in all the following competencies: Data Engineering development, architecture design & technology platforms\/frameworksHands-on experience with Azure Data Analytics services e.g. ADLS, Azure Data Factory, Azure Databricks, Purview, Azure Synapse, etc.Data Platforms and Domain-driven designAgile, DevOps & Automation [of testing, build, deployment, CI\/CD, etc.]Data analytics & data quality\/integrityTesting strategies & frameworks \nFamiliarity with and use of various open-source ecosystems including JavaScript, Bigdata, java, python, etc.Good understanding of various software paradigms: domain-driven, procedural, data-driven, object-oriented, functionalFamiliar with Python\/PySpark, REST APIs, SQL\nPreferred Qualifications: Track record of applying best data and software engineering practices in Pharma CMC and Scientific domains.Known for excellent, rigorous software engineering with full stack role including DevOps on a development teamExperience in applying data curation, virtualization, workflow, and advanced visualization techniques to enable decision support across multiple products and assets to drive results across R&D business operations.Experience in building products with modern Cloud architectures, platforms, and back-end systems\nBenefits: Career at one of the leading global healthcare companiesContract of employment Attractive reward package (annual bonus & awards for outstanding performance, recognition awards for additional achievements and engagement, holiday benefit)Life insurance and pension plan Private medical package with additional preventive healthcare services for employees and their eligible Sports cards (Multisport) Possibilities of development within the role and company\u2019s structure Personalized learning approach (mentoring, online training\u2019 platforms: Pluralsight, Business Skills, Harvard Manage Mentor, Skillsoft and external training) Extensive support of work life balance (flexible working solutions, short Friday\u2019s option, health & well-being activities) Supportive community and integration events Modern office with creative rooms, fresh fruits everyday Free car and bike parking, locker rooms and showers\n#SCDG7Why Us?GSK is a global biopharma company with a special purpose \u2013 to unite science, technology and talent to get ahead of disease together \u2013 so we can positively impact the health of billions of people and deliver stronger, more sustainable shareholder returns \u2013 as an organization where people can thrive. Getting ahead means preventing disease as well as treating it, and we aim to positively impact the health of 2.5 billion people by the end of 2030.Our success absolutely depends on our people. While getting ahead of disease together is about our ambition for patients and shareholders, it\u2019s also about making GSK a place where people can thrive. We want GSK to be a workplace where everyone can feel a sense of belonging and thrive as set out in our Equal and Inclusive Treatment of Employees policy. We\u2019re committed to being more proactive at all levels so that our workforce reflects the communities we work and hire in, and our GSK leadership reflects our GSK workforce.If you require an accommodation or other assistance to apply for a job at GSK, please contact the GSK Service Centre at 1-877-694-7547 (US Toll Free) or +1 801 567 5155 (outside US).GSK is an Equal Opportunity\/Affirmative Action Employer. All qualified applicants will receive equal consideration for employment without regard to race, color, national origin, religion, sex, pregnancy, marital status, sexual orientation, gender identity\/expression, age, disability, genetic information, military service, covered\/protected veteran status or any other federal, state or local protected class.Important notice to Employment businesses\/ AgenciesGSK does not accept referrals from employment businesses and\/or employment agencies in respect of the vacancies posted on this site. All employment businesses\/agencies are required to contact GSK's commercial and general procurement\/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business\/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business\/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses\/agencies in respect of the vacancies posted on this site.Please note that if you are a US Licensed Healthcare Professional or Healthcare Professional as defined by the laws of the state issuing your license, GSK may be required to capture and report expenses GSK incurs, on your behalf, in the event you are afforded an interview for employment. This capture of applicable transfers of value is necessary to ensure GSK\u2019s compliance to all federal and state US Transparency requirements. For more information, please visit GSK\u2019s Transparency Reporting For the Record site."}
{"job_title":"Sviluppatore SQL","company_name":"Engol S.r.l.","location":"Sesto San Giovanni, Lombardy, Italy (Remote)","job_link":"\/jobs\/view\/3778508586\/?eBP=CwEAAAGMPHDBRupm93tzcGIGGMI-WMsW4hmgEDMD6idal7ikzcjQBhZhx-nyYcBr5xFHNtQcEC5IVvo9UPF8m4AzGUemZTCiWO2bHNoe5lSMbQSZvsHCYQ6FzeZ8PdoGbsIs1AoDyKLO7mThM4to8ON9AW3sw2Ewx_w7TNM_zhzlF_Qyhi7ONwhrh9SOx310TvNYjl-gV7cqsxG5MWV3p6lNn42gIao2pTHGTnkE7LjtpO63hKplWna6dgXBk3__xIdiFyFgRi58Ebi0iqC0AzquCA72nUwjqbAO73CaGvV2reXfDmbkDPoLdNi5_LUYnQ0nhkzVGuLyshuvePZDtZp3HGmUbXIkEXg22ySt-34mgf1kP3NaoVKega2GrCdjai4nwAdEugqAtefw1h2vIgu3lrbP&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=aCkjvOr%2FHLrOabM319dlaQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3778508586","job_description":"About the job\n            \n \nStiamo una risorsa da inserire nel team di Milano di supporto globale ad una applicazione per un importante cliente.La risorsa dovr\u00e0 avere una conoscenza approfondita del linguaggio SQL di interrogazione del DB ed avere concetti generali di programmazione in linguaggi tipo Pascal, allo scopo di implementare regole automatiche attraverso la realizzazione di piccoli script sul prodotto.Principali attivit\u00e0 Implementazione di report e statistiche tramite utilizzo del modulo StatisticManagerSupporto customer serviceSupporto ai clientiSupporto alla gestione di audit e complaintsSupporto alla realizzazione della documentazione di Service\nQualifiche Titolo di studio: \u00e8 adeguato un diploma in materie scientifiche o tecnicheConoscenza SQLConoscenza di almeno un semplice linguaggio di programmazioneConoscenza approfondita dell'Inglese scritto e parlato (almeno Livello B1)Ottima capacit\u00e0 di collaborazione in team, dinamismo e voglia di imparare\nVerranno considerati come preferenziali (anche se non imprescindibili) i seguenti requisiti: Familiarit\u00e0 con le tematiche di un Laboratorio di AnalisiConoscenda dell'RDBMS OracleUtilizzo di sistemi per il collegamento remoto (Teamviewer, Any Desk)Utilizzo precedente di sistemi di gestione dei ticket di assistenza\nContratto CCNL di un anno con possibilit\u00e0 di rinnovo e passaggio a tempo indeterminatoPaga in base l'esperienza riconosciuta, tra i 1400 e 1800 euro."}
{"job_title":"Data Engineer | Lead Data | Data Scientist","company_name":"Solers.io","location":"Paris, \u00cele-de-France, France (Remote)","job_link":"\/jobs\/view\/3778375766\/?eBP=CwEAAAGMPHDBRreLRPW1f7e9L5n6eJqOD-V8jvtlWUHltp_Er83xqLhs8NJP3_iQ_08krZs60RwZ4ak4mcGEoRtGKBZaoudM_U7MqYN8Y2BXIw9DZJf39bazH2mgwVMey_hTA4MG-iU2j9Mhj3d4LyOVS1v0lJe_D5QGC6dOzGD6Jqu8DS8_neg5UYUBT20s97p6Ta1W_w1vNSWtqtGAh9tAA7kydSJWUnUprbzXyj9BZU0WgsMtvzD3bSP42i33SQI6vP1OxWiaFGW0DwJWKaoOTHULvkbW3SpMbYlg78Yfim60dw9p3b_dO4s5pzHwGAlIxuU1Bar56Ie2ei_rrMNl9bx1YXE3cYjsRPLPOkHZ-5asTh0AJuRkQyfhhT03pfqthW6BIXa8qAUz52bVwsSj_C4e&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=FtBk7EUYLmujeYDZfRbBmw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3778375766","job_description":"About the job\n            \n \nHello! Quelques exemples d'offres Data Engineer, Data Scientist, Lead Data (on site, Hybride ou full remote) sur solers.io : https:\/\/job.solers.io\/dataN'h\u00e9site pas \u00e0 t'inscrire pour consulter toutes nos offres!Pour postuler ? Inscris-toi sur solers.io, d\u00e9clare tes comp\u00e9tences et passe les tests techniques pour cette offre.Le plus ? Ces tests sont ni limit\u00e9s en temps ni visibles en cas d'\u00e9chec et r\u00e9utilisables pour postuler \u00e0 toutes les autres offres publi\u00e9es sur la plateforme.Si tu as des questions n'h\u00e9site pas !"}
{"job_title":"Senior Data Engineer","company_name":"Vertex Solutions International Ltd","location":"Poland (Remote)","job_link":"\/jobs\/view\/3778380037\/?eBP=CwEAAAGMPHDBRvnVY5Agw6WP0-nISEOf2CRL-dK4sv8IW8xrXjmx1GPtgOxNkMCpOLi9_q5i4sqGa0jFTluXyUpd6FZvdU8q2F_GDZQFvSWAdN6Exdwrk5RQWLcRxwElwhdwDK16x0bvKMjGWFEwBBp15N_9S3att3IZ7SMUEChWIs8cBE-HYkAI1-U8EYQBRRYBUi3H7WdEF5FprK_K8Ri-uv04JKF6SacuL7x8kT4S6qMQC7BrPHA-qbxyt_wu-h5p7Fy7BY33LdbtmnqsRO6X8vHQqItqJVCgRDo-iWNwSNfyauWtnlFqnKl7RrGNknJngsM2SapIGY7GQxD_t76ctjEcvMopeNwJoXBiqklXewzylFrNbQCZOd8o3FMulx5h&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=6eg%2FhXFP2PggYt0ZDtYbzw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3778380037","job_description":"About the job\n            \n \n\ud83d\ude80 Join Us as a Senior Data Engineer \ud83d\ude80Are you passionate about shaping the data landscape and driving business growth through insights? We are looking for a Senior Data Engineer to be a key player in advancing our Data Architecture.Your Mission: \ud83c\udfafAs our Senior Data Engineer, you'll dive into the world of product data, collaborating closely with product teams and data analysts. Your focus will be on extracting valuable insights to enhance decision-making and critical business processes.What You'll Be Doing: \ud83d\udee0\ufe0f Own and expand our tracking plan with our awesome Product teams \ud83d\ude80Implement pipelines to feed business applications with key data insights \ud83d\udcc8Design and implement data models for analysts to query \ud83e\udd16Support Product Data Analysts with key insights into our data models \ud83e\udde0\nWhat We're Looking For: \ud83d\udc40 Experience: Minimum 6-7 years in Data Engineering.Expertise: Proven skills in product-focused data work, with proficiency in tools like Mixpanel and Amplitude.Tech Stack: Mandatory proficiency in AWS, the heart of our tech stack.Responsibilities:Active participation in data co-creation.Monitoring user interactions within software products.Tech Savvy: Familiarity with technologies similar to Mixpanel and Amplitude.Focus: Internal collaboration with stakeholders, not external client interactions.Additional Plus: Proficiency in data architectures, ETL pipelines, prior experience in a B2B SaaS company, familiarity with distributed data processing technologies, and expertise in cloud computing \u2601\ufe0f\n\ud83d\udcdd Apply now and unlock an exciting future!\ud83d\udce7 Contact: v.choudhary@vertex-solutions.com\ud83d\ude80 #DataEngineer #TechJobs #JoinUs"}
{"job_title":"Senior Data Modeling Engineer (80% part-time possible)","company_name":"SentinelOne","location":"Brno, South Moravia, Czechia (Remote)","job_link":"\/jobs\/view\/3663863123\/?eBP=CwEAAAGMPHDBRghECBjBQaTAYuPLcWX7a1v7tSPH8Lskl9d8H44jCfo2q47Ip_YMZGSQ06hEosmvv4F5Q5vA4-VyG-BBnJQEucUwyZlehcypvPA3g8A_GdjxBPgpO8vVOeW2vOUvZrtiPINT2wXX0NSeuwyw7-1_S7VIS7ScjUvH26g0dqUCoI0Fuqs-NIkJfiTMMo6EV13qaY3zb8xvu-oebDGpa7zZw5jfh6cIbZz57Nhm0epINhYNOzAbCzo7d0_V-HK46A2p6zT1d8QxK_kztBaWt26SJt88LuR1m180TJgz62aqsWheNtstER4hvu0rpHrMe_hmAPEfNlXQwoj45FA4gu2OsokaQJqO9h5BEharAGS--Rox3gvIDzYrlw&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=aqPazDfq24eXZZU%2Bk2%2FwDQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3663863123","job_description":"About the job\n            \n \nAbout Us:SentinelOne is defining the future of cybersecurity through our XDR platform that automatically prevents, detects, and responds to threats in real-time. Singularity XDR ingests data and leverages our patented AI models to deliver autonomous protection. With SentinelOne, organizations gain full transparency into everything happening across the network at machine speed \u2013 to defeat every attack, at every stage of the threat lifecycle.We are a values-driven team where names are known, results are rewarded, and friendships are formed. Trust, accountability, relentlessness, ingenuity, and OneSentinel define the pillars of our collaborative and unified global culture. We're looking for people that will drive team success and collaboration across SentinelOne. If you\u2019re enthusiastic about innovative approaches to problem-solving, we would love to speak with you about joining our team!About The RoleSentinelOne is seeking a talented data modeler to assist with designing and implementing data products. As a data modeler, you will work closely with architects, data engineers, and data analysts to implement data modeling solutions to streamline and support stakeholder reporting and enterprise business intelligence use cases.To ensure success as a data modeler at SentinelOne, you should have in-depth knowledge of data warehousing, excellent communication skills, and an understanding of how to turn raw data from various sources into easily consumable data products using tools within the data ecysostem, and operate under a philosophy of writing code as a last resort. Ultimately, a top-notch data modeler should be able to design models that reduce data redundancy, streamline data movements, and improve enterprise information management and time to insight.What will you do? Analyzing and translating business needs into long-term solution data models.Regularly engage and consult stakeholders on solving business problems through data, guiding the conversation rather than simply taking orders.Perform data profiling\/analysis activities that help to establish, modify and maintain data models.Evaluating existing data systems.Working with the development team to create conceptual data models and data flows.Developing best practices for data coding to ensure consistency within the system.Reviewing modifications of existing systems for cross-compatibility.Implementing data strategies and developing physical data models.Updating and optimizing local and metadata models.Evaluating implemented data systems for variances, discrepancies, and efficiency.Troubleshooting and optimizing data systems.Ability to take on additional tasks and responsibilities as the organization needs.\nWhat skills & knowledge should you bring? Several years of hands-on experience with physical and relational data modeling.Must have - proven experience working with Google Cloud Platform, BigQuery, and related technologies.Experience working with infrastructure as code (Terraform, Pulumi, etc.) Expert knowledge of metadata management and related tools.Expert SQL skills.Knowledge of mathematical foundations and statistical analysis.Strong interpersonal skills.Excellent communication and presentation skills - in both written and spoken English.Advanced troubleshooting skills.\nWhat We Offer You We're able to accomodate 80 - 100% of permanent fulltime employment (e.g. Mon-Thu and 4 day work week)Flexible working hours, In Prague & nearby we're working in a hybrid model with offices in Karlin, remotely in the rest of CZ or SK, with optional Brno offices (Clubco Vln\u011bna) for those who like to meetGenerous employee stock plan in the form of RSUs (restricted stock units) not options; 4 years vesting with 1-year cliff and then quarterlyYearly bonus depending on the performance of the company, paid out in 2 installmentsFlexible Time Off (on top of the standard 5 weeks of vacation)Flexible Paid Sick DaysFully Paid Short Term Sick\/Short Term Nursing LeaveGlobal gender-neutral Parental Leave (16 weeks, beyond the leave provided by the local laws) & Grandparent LeaveVolunteering paid day off & Additional paid Company holidays off (e.g. 4 days in 2022)Pension insurance contributionPremium Life Insurance covered by S1Cafeteria points (5.000 CZK\/month), which you can spend on leisure & sports (e.g. discounted MultiSport card), kindergarten\/school fees, travel etc. Private medical care membershipGlobal Employee Assistance Program (confidential counseling related to both personal and work life matters)High-end MacBook or Windows laptop, Home-office-setup gear & on top of that additional WFH AllowanceUdemy Business platform for Hard\/Soft skills Training, internal mentoring 'MentorOne' & Support for your further educational activities\/trainingsAbove-standard referral bonusOn top of RSUs, you can benefit also from our attractive ESPP (employee stock purchase plan)Refreshments, snacks, massages at the offices & weekly yoga at Prague office\/via ZoomOptional company events for those who like to meet outside of work too (sport, BBQ, charity etc.)DEI&B programs that promote employee resource groups like SentinelWIN (Women Inclusion Network), Blk@S1, Latinos@S1, Pan-Asian@S1, Out@S1 (LGBTQIA+) and Sentinels Who Served\nSentinelOne is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.SentinelOne participates in the E-Verify Program for all U.S. based roles."}
{"job_title":"Junior Data engineer","company_name":"WA.Technology","location":"Crouseilles, Nouvelle-Aquitaine, France (Remote)","job_link":"\/jobs\/view\/3776414546\/?eBP=JOB_SEARCH_ORGANIC&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=uBdfgDrO3PBWnEZk0uWezA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3776414546","job_description":"About the job\n            \n \nWA.Technology is a B2B supplier of iGaming solutions with rapidly growing clients and partnerships in emerging markets. We offer a state-of-the-art iGaming platform, turnkey solutions, and standalone products that empower operators to enter or expand into emerging markets quickly and easily.The WA.Platform is a fully scalable and customisable solution, featuring over 75 game providers, 6,400+ games, and support for multiple currencies, along with access to over 80 payment methods. WA. Technology enables operators to build their own casino, sportsbook, lottery, fantasy, or poker business precisely as they envision it.About The Role,We are seeking a highly skilled and motivated Data Engineer to design, implement, and maintain efficient and scalable data pipelines on the Google Cloud Platform (GCP). In this role, you will be responsible for managing data from MariaDB and Kafka sources, ensuring seamless integration into BigQuery, our primary data destination. Collaboration with cross-functional teams is crucial to understanding and meeting diverse data needs.In this role, you will need to: Design, implement, and maintain robust data pipelines on Google Cloud Platform. Integrate MariaDB and Kafka as primary data sources for seamless data flow into BigQuery. Collaborate across departments to address unique data requirements aligned with organizational goals. Utilize Dataflow and Dataform for efficient data processing and transformation. Ensure data integrity through rigorous validation and cleansing processes. Optimize cloud-based infrastructure for speed and scalability. Implement monitoring tools for proactive system performance tracking and issue resolution. Provide ongoing support for data integrity and availability. Maintain comprehensive documentation of data architecture, updating regularly. Stay informed about the latest data technology trends. Evaluate and recommend new technologies\/methodologies to enhance processing and analysis capabilities. \nWhat are the key experience and personal attribute requirements? Bachelor's degree in Computer Science, Information Technology, or a related field. 2+ Hands-on experience relational databaseProven experience in developing data pipelines and ETL processes. Strong SQL skills. Knowledge of data modeling and database design. Excellent collaboration and communication skills. Strong problem-solving and troubleshooting abilities. Ability to work independently and as part of a team. Continuous learner, keeping up with emerging trends in data engineering. \nWhat are some of the benefits of working at WA Technology? 100% remote opportunityFlexible work environmentAttractive remuneration packageOpportunity to work with well-connected industry leaders. A leadership approach that fosters innovation, creativity, and trust. Opportunity to experience the buzz of highly driven and motivated work colleagues. Experience a start-up feel in a fast-paced growth-driven environment."}
{"job_title":"Data Engineer","company_name":"Veeva Systems","location":"Germany (Remote)","job_link":"\/jobs\/view\/3647473173\/?eBP=CwEAAAGMPHDBRhNtMuJ_hD2crNcJjecb7Urbhu6C5ueCZ4HhONHm-4TA7WEmPMeqQBlmDI4zSQIiKyICTcPIhmvGxbez8sqr5B4RNSYdLyySx_GKLp0LFXdvund8lSjpJN5pnEN08kkaRDg75uvUWsNsAaQTYel5l7iHcarELHQVaoap5ZMwauWTKW7yOilNcvKMMhiX_r6x6jTPNOlwKgjOFoUIDqBbaf7v8J15wkWHVL0nMASqs68AoV3Ss-B5QM6Vox8yZafl2tCa72ebgUnlc8PZY7ga6XarvtlrqcvRehi6u6clTVHdBxH7ZAJj8bJRCzz6oqTikIFA6fhr65QHW2Kk_T_ldPlrpNbfvm8e-2-v6URhg5Yr_4QxMSgZPw&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=%2BpHlfLTrhB%2FsFoUHgBg6Rw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3647473173","job_description":"About the job\n            \n \nVeeva Systems is a mission-driven organization and pioneer in industry cloud, helping life sciences companies bring therapies to patients faster. As one of the fastest-growing SaaS companies in history, we surpassed $2B in revenue in our last fiscal year with extensive growth potential ahead.At the heart of Veeva are our values: Do the Right Thing, Customer Success, Employee Success, and Speed. We're not just any public company \u2013 we made history in 2021 by becoming a public benefit corporation (PBC), legally bound to balancing the interests of customers, employees, society, and investors.As a Work Anywhere company, we support your flexibility to work from home or in the office, so you can thrive in your ideal environment.Join us in transforming the life sciences industry , committed to making a positive impact on its customers, employees, and communities.The RoleVeeva OpenData supports the industry by providing real-time reference data across the complete healthcare ecosystem to support commercial sales execution, compliance, and business analytics. We drive value to our customers through constant innovation, using cloud-based solutions and state-of-the-art technologies to deliver product excellence and customer success. The OpenData Global Data Tools team delivers the tools and data processing pipelines to build the global data core for life sciences in 100+ countries.As a Data Engineer of the Global Data Tools team, you will take responsibility for the OpenData processing workflows. You will be developing complex algorithms, building and maintaining data relationships through data processing pipelines, ensuring data quality in our reference data, and working closely with Product and Data Operations teams to adapt our reference data to changing demands in the market.What You'll Do Build and maintain data processing pipelines using state-of-the-art technologiesDevelop algorithms to build complex data relationshipsWork with Python on Spark-based data pipelinesBuild analytical data structures to support reporting toolsAutomate quality control processes\nRequirements Fluent in Python programming language and PySpark (3+ years of experience)3+ years of experience developing data pipelines using cloud-managed Spark clusters (e.g., AWS EMR, Databricks)Proficient with SQL \/ SparkSQLExperienced algorithm developerHands-on experience working with a Data Lakehouse\nNice to Have Experience running data workflows through DevOps pipelinesDevelop data pipelines with cloud orchestration tools (e.g., Airflow, AWS Steps, or similar from other cloud vendors)Valuable experience working with Scala or Kotlin programming languagesPrevious experience in the Life Sciences sector\nPerks & Benefits Benefits package including Restricted Stock Units (RSUs), family health insurance, and contributions to private pension plansAnnual allocations for continuous learning, development & charitable contributionsFitness reimbursementWork anywhere\n#RemoteGermanyVeeva\u2019s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world.Veeva is committed to fostering a culture of inclusion and growing a diverse workforce. Diversity makes us stronger. It comes in many forms. Gender, race, ethnicity, religion, politics, sexual orientation, age, disability and life experience shape us all into unique individuals. We value people for the individuals they are and the contributions they can bring to our teams."}
{"job_title":"Software Engineer","company_name":"ON3 WORKS","location":"Spain (Remote)","job_link":"\/jobs\/view\/3778374679\/?eBP=CwEAAAGMPHDBRmKOb9cRnXF7l0_T_xV4u1fgzEEBMjPuVtp7z0zMqi27MRJdwyOnjrzHHDOWXL4utKlinW95ObuHHj8tIbTT203F4Xaw0isRk92YaeOftVpTxtRN1MCyrnnXgWyhHAx6LB0GmY0TWneP90NUPVyljkPV8ZYnQnMPZ_ZLC4ifBrOmY6_mgSmZRF6b5vaeJYnfvXV43_kO7Q6CP1SErZLSatZzaMRJ0ACL2K4Y0_noqIIadlEdZP5JfUix8K4TSWcWC6ia7VkqSW8BkeV4nPtdfwlRTXdoYvqcoyCj8uDmh1-fVfUuUDmYcx1AfcdcpxXtgD4yxHTTUGJRbg&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=h7tKixdx333tzDHCDPQEmw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3778374679","job_description":"About the job\n            \n \nJob Title: Full-Stack Software EngineerLocation: RemoteJob Type: Full-timeSalary Range: \u20ac30-40KCompany Overview:Our client is seeking a talented Full-Stack Software Engineer to join their dynamic team. They are in the process of building a robust application and need a skilled developer to help them grow and maintain their platform.Key Responsibilities: Adopt and extend the existing codebase of our application.Develop and implement new features on the platform.Maintain and improve the performance of the existing application.Work with Python for orchestrating data pipelines and CICD processes.Deploy applications using FastAPI in an ArgoCD environment.Develop front-end components using REACT and JavaScript.Manage and maintain PostgreSQL databases, including writing and optimizing SQL queries.\nRequired Skills and Qualifications: Proven 3 years experience as a Full-Stack Developer.Strong knowledge and experience in Frontend development with REACT and\/or JavaScript.Proficient in Backend technologies including SQL, FastAPI, Python.Experience with Argo, CICD\/Git workflows for deployment.Familiarity with PostgreSQL or similar relational databases.Ability to quickly learn and work with existing codebases.Strong problem-solving skills and attention to detail."}
{"job_title":"Data Engineer","company_name":"SII Romania","location":"Bucharest, Romania (Remote)","job_link":"\/jobs\/view\/3766502183\/?eBP=CwEAAAGMPHDBRvHRQnhpJ-9-nk827ED9RaIAH9KrIWgjfIg2p5ExMh7usz6uQt08ojyBg0BU7Cus43Gm7dm2dhm7VPXlD9p--ttT8IP73twwNzy9SlNbrHpAp8Ngo4gX7uflclvKMufcoJV36L-nn3KDxB2oHEGLTRCzP1YDbI1DpTqEOzQhb_idxBpVPnASnLcZXEadosueRZvWn084QGlKLzWxh5LQzSkvBlAf1f8Eupy-Hu5Vm3jHnv_tK3l8Gr2FL3H_SnmGKYfK7ljLhW-FRaB7BoD9VY6aypZAmZOEPT_-rMTOE_3Zv135XqqySORwIlwUhcf6qCfXGhHpMQUWJLtBC03EBhRw7vfgJkwUm0jBVvdO9DngZ8z91uP3LXjy&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=ouJxkNAx5Bq4rTaQW8NDzA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3766502183","job_description":"About the job\n            \n \nWho we are:Open-minded intellectuals who embrace emerging technologies on our mission to create innovative Software Engineering Solutions that will impact millions of users around the world.What you must have: Mastery in SQLKnowledge of Elastic SearchExpertise in the implementation of end-to-end data processing chainsMastery of distributed developmentBasic knowledge and interest in the development of ML algorithmsKnowledge of the ingestion frameworkKnowledge of Spark and its different modulesMastery of Scala and \/ or PythonKnowledge of the AWS or GCP ecosystemKnowledge of the ecosystem of NOSQL databasesKnowledge in the construction of APIs of data productsKnowledge of Dataviz tools and librariesAbility to debug Spark and distributed systemsPopularization of complex systemsKnowledge of algorithm complexityMastering the use of notebooks dataExpertise in data testing strategiesStrong problem solving, intelligence, initiative and ability to withstand pressureExcellent interpersonal skills and a great sense of communication (ability to go into detail)\nWhat you will do:During project definition Design of data ingestion chainsDesign of data preparation chainsBasic ML algorithm designData product designDesign of NOSQL data modelsDesign of data visualizationsParticipation in the selection of services \/ solutions to be used according to the usesParticipation in the development of a data toolbox\nDuring the iterative realization phase Implementation of data ingestion chainsImplementation of data preparation chainsImplementation of basic ML algorithmsImplementation of data visualizationsUsing ML frameworkImplementation of data productsExposure of data productsSetting up NOSQL databasesImplementation in distributed mode of treatmentsUse of functional languagesDebugging distributed processes and algorithmsIdentification and cataloging of reusable elementsContribution to the evolution of labor standardsContribution and opinion on data processing problems\nDuring integration and deployment Participation in problem solving\nWhat's in it for you: Extended compensation and benefits package;Continuous learning opportunities to enhance your professional and soft skills;A great working environment with people who put their heart, mind, and soul into everything they do and understand the importance of team spirit.\nWe really welcome open-minded and committed people: Eager to take on new challenges and learn new things;Who put their heart, mind, and soul into everything they do;Who enjoy sharing knowledge and understand the importance of team spirit."}
{"job_title":"SAP BI\/BW Data Engineer*","company_name":"BAUMLINK","location":"Germany (Remote)","job_link":"\/jobs\/view\/3779075113\/?eBP=CwEAAAGMPHDBRlXV7UXFB5beJX3gTLSOTVki2VQqzLzMiRng0TzIyyHaz4odZE5mqcruUxASSwOZP7lubFg0l2yM6O1UYDEiKMzmfkXzn0RgZKQ5yzZs2Z6HuQBLh_hFxVR4t9Bes8iIPaXmIwb4dR6V82EHdq36ljvWI6Ts0vf1FsUVfJ0GwjmF3dVAalOjz5M8I8yQEIMcU7vk8nd5lz_WXxoQrwyJbVE3EoptH1KndLsWSyVqC_vTsUMzMUnBDoIEAbH0YwcBQtczILhkZXQCG1XTGWO8tQzuIthHA806SD3hu8FULDQlqW1oxzSS7dBxCU9rf-bXXWtVEiXGxQylJ8cEv7yn8-1_iSjlgxfAJNqW4--jPLvKb-PqtQ5OHGdw&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=9cqh2DCDbHMEkxt%2B9yqMxA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3779075113","job_description":"About the job\n            \n \nProfound knowledge of the SAP BI\/BW world and ideally in combination with AzureExperience in Snowflake is a bonusThe Senior position requires strong stakeholder Management skills and a proven track record in understanding of turning Data into value\nPlease do not apply if not fluent in German and are based currently within Germany.Applications not matching those parameters won't be processed."}
{"job_title":"Data Engineer","company_name":"Glocomms","location":"Paris, \u00cele-de-France, France (Remote)","job_link":"\/jobs\/view\/3767643940\/?eBP=CwEAAAGMPHDBRsWiSrL8P-UZXyUKzvGQp7h37MMmYi8e2k5Mr8EbK1cVW1yjvlYBq0kBxg6rYP8Ewv1sCHez4zDHn0EA8PNRgpgsUVvauZKk9vmRQySHBBDqFf50MqdvSHZT4AA3CK4wLuADeioDEF4GXOczu7PTR0ZS_yMf6-kMEmfWkpyK2KQbdkSumEUajbr_k-jbImqsHFWkIWdhWU-6hMz9rW-EGdUTQNUSR7Yc4W7D44d3az4O1zVrx3ss5kVtJZuFjRjBN4GWHnbPYyMHsh0NOKe0nck5YTLe1Tsujh03bha2NioaIx8CNwwYv8NkSqqQDudkuvCwiJrCBtRehTuPCzpVi1wujGLqS1IC1aaMo8uK6NRth3lufrtiog&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=Ail8%2F7Ew3p4%2FFA2ehPQ71Q%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3767643940","job_description":"About the job\n            \n \nOur customer is looking for a Freelance DATA Engineer with skills in Python & GCP.  Cloud : Architecture cloud  \u00ab Infrastructure as code \u00bb avec Terraform  FinOps   Software:Expert PythonSoftware Architecture & Data ModelsCode Quality, Testing, and MaintainabilityImplementation of code, documentation and testing best practices in the team to ensure maintainability and reliability. Development of various micro-services and tools   DevOps : Architecture CI\/CD Full automation from push, testing, and validation to production deployment.  Deployment of services\/software packages, etc.  Built or helped build many GitHub CI\/CD pipelines   This is a remote freelance mission.   If you consider yourself to be an expert in Python &"}
{"job_title":"Data Engineer - Stream Data Processing - Distributed Data Processing","company_name":"Pathway","location":"Paris, \u00cele-de-France, France (Remote)","job_link":"\/jobs\/view\/3686098013\/?eBP=JOB_SEARCH_ORGANIC&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=WAIjJ6k1Iovcd7uc9FO8UQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3686098013","job_description":"About the job\n            \n \nAbout PathwayDeeptech start-up, founded in March 2020. Our primary developer offering is an ultra-performant Data Processing Framework (unified streaming + batch) with a Python API, distributed Rust engine, and capabilities for data source integration & transformation at scale (Kafka, S3, databases\/CDC,...)The single-machine version is provided on a free-to-use license (`pip install pathway`)Major data use cases are around event-stream data (including real-world data such as IoT), and graph data that changes over timeOur enterprise offering is currently used by leaders of the logistics industry, such as DB Schenker or La Poste, and tested across multiple industries. Pathway has been featured in Gartner's market guide for Event Stream ProcessingLearn more at http:\/\/pathway.com\/ and https:\/\/github.com\/pathwaycom\/\nPathway is VC-funded, with amazing BAs from the AI space and industry. We have operations across Europe and in the US. We are headquartered in Paris, with significant support from the French ecosystem (BPI, Agoranov, WILCO,...).The TeamPathway is built by and for overachievers. Its co-founders and employees have worked in the best AI labs in the world (Microsoft Research, Google Brain, ETH Zurich), worked at Google, and graduated from top universities (Polytechnique, ENSAE, Sciences Po, HEC Paris, PhD obtained at the age of 20, etc\u2026). Pathway\u2019s CTO is a co-author with Goeff Hinton and Yoshua Bengio. The management team also includes the co-founder of Spoj.com (1M+ developer users) and NK.pl (13.5M+ users) and experienced growth leader who has scaled companies with multiple exits.The opportunityWe are searching for a person with a Data Processing or Data Engineering profile, willing to work with live client datasets, and to test, benchmark, and showcase our brand-new stream data processing technology.The end-user of our product are mostly developers and data engineers working in a corporate environment. Our development framework is one day expected to become for them a part of their preferred development stack for analytics projects at work \u2013 their daily bread & butter.You WillYou will be working closely with our CTO, Head of Product, as well as key developers. You will be expected to: Implement the flow of data from their location in client's warehouses up to Pathway's ingressSet up CDC interfaces for change streams between client data stores and i\/o data processed by Pathway; ensuring data persistence for Pathway outputsDesign ETL pipelines within PathwayContribute to benchmark framework design (throughput \/ latency \/ memory footprint; consistency), including in a distributed system setup. Contribute to building open-source test frameworks for simulated streaming data scenarios on public datasets\nRequirements Inside-out understanding of at least one major distributed data processing framework (Spark, Dask, Ray,...)6 months+ experience working with a streaming dataflow framework (e.g.: Flink, Kafka Streams or ksqldb, Spark in streaming mode, Beam\/Dataflow)Ability to set up distributed dataflows independentlyExperience with data streams: message queues, message brokers (Kafka), CDCWorking familiarity with data schema and schema versioning concepts; Avro, Protobuf, or othersFamiliarities with KubernetesFamiliarity with deployments in both Azure and AWS cloudsGood working knowledge of PythonGood working knowledge of SQLExperienced in working for an innovative tech company (SaaS, IT infrastructure or similar preferred), with a long-term visionWarmly disposed towards open-source and open-core software, but pragmatic about licensing\nBonus Points Know the ways of developers in a corporate environmentPassionate about trends in dataProficiency in RustExperience with Machine Learning pipelines or MLOpsFamiliarity with any modern data transformation workflow tooling (dbt, Airflow, Dagster, Prefect,...)Familiarity with Databricks Data Lakehouse architectureFamiliarity with Snowflake's data product vision (2022+)Experience in a startup environment\nBenefitsWhy You Should Apply Intellectually stimulating work environment. Be a pioneer: you get to work with a new type of stream processing frameworkWork in one of the hottest data startups in France, with exciting career prospectsResponsibilities and ability to make significant contribution to the company\u2019 successCompensation: contract of up to $150k (full-time-equivalent) + Employee stock option plan. Inclusive workplace culture\nFurther details  Type of contract: Flexible \/ remote Preferable joining date: early 2023 Compensation: contract of up to $150k (full-time-equivalent) + Employee stock option plan Location: Remote work from home. Possibility to meet with other team members in one of our offices:Paris \u2013 Agoranov (where Doctolib, Alan, and Criteo were born) near Saint-Placide Metro (75006)Paris Area \u2013 Drahi X-Novation Center, Ecole Polytechnique, PalaiseauWroclaw \u2013 University area\nCandidates based anywhere in the United States and Canada will be considered."}
{"job_title":"Data Engineer","company_name":"Capco","location":"Warsaw, Mazowieckie, Poland (Remote)","job_link":"\/jobs\/view\/3770921558\/?eBP=CwEAAAGMPHDBRhWu8ACfUX667Ys-3sWEFdC1YUu4GCWUE5vOadYDIRQqvkAPq28jIbrgAQ9y0Al9N1XAyoHFGFaf5bjYa_0LRG_G4MtJi6OnagmZGYDG-yuTn1Qg0DOfWthSku3wR8uE17Rbkho4TZqJpcsaHZBdI17D2W9QP_2w5GgK2bhWNH6dkKxSlTo9CgVcm5ANo5ff6vlarURn1YiPnsbKSeqrIsax0D-jvNJhM1TOOOofcwiS576g1g_S7b_fKahFeT2_ezl0I3CHPWINHUBSfcXDm9TfMv6jyyNcfLBXnm4GxerXQduPVeWSXbEGy7piu1_ldaS743rXbgYyzdIZR30uqQIRDmQlOqcZXmEbhIhM8AhtQd_1VzeZjw&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=UAFdKXXJf%2Ftc9jt20qYeLQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3770921558","job_description":"About the job\n            \n \nCAPCO POLANDCapco Poland is a global technology and management consultancy specializing in driving digital transformation across the financial services industry. We are passionate about helping our clients succeed in an ever-changing industry.We also are experts in backend, frontend, mobile, data engineering... focused on development, automation, innovation, and long-term projects in financial services. In Capco, you can code, write, create, and live at your maximum capabilities without getting dull, tired, or foggy.We are looking for Data Engineers to support one of our best-in-class clients from financial services. You'll be working on different projects starting from on-premises solutions, migration to cloud. Our clients' Big Data Lake is the largest aggregation of data ever within financial services with over 300 sources and a rapidly growing book of work.  THINGS YOU WILL DO Transform the business and system requirements into solution designs and functional requirementsDeliver an ecosystem of curated, enriched, and protected sets of data \u2013 created from global, raw, structured, and unstructured sourcesData development process: design, build and test data products that are complex or large-scalePromote development standards, code reviews, mentoring, testing, scrum story writingCooperate with customers\/stakeholders, product owners, business users and other subject matter experts\n TECH STACK: ETL, Hadoop-Based Analytics (Hbase, Hive, mapReduce, Kafka, Spark, BI, ETL, Database, etc), Java\/Scala\/Python, Spark, GCP (cloud storage, Big Query, Pub\/Sub, Data Flow), Jenkins, GitHub, SQL SKILLS & EXPERIENCES YOU NEED TO GET THE JOB DONE Experience in Scala, Python, or JavaExperience in Unix\/Linux environment on-premisesExperience with developing RESTful APIsExperience in ElasticsearchExperience building data pipelines using Hadoop components (Apache Hadoop, Scala, Apache Spark, YARN, Hive, SQL)Knowledge of industry-standard version control tools (Git, GitHub) and automated deployment tools (Ansible & Jenkins)Knowledge of SDLC and SQLUnderstanding users\u2019 requirements and functional specificationExcellent communication, interpersonal, and decision-making skillsGood English knowledge\n WHY JOIN CAPCO? Employment contract and\/or Business to Business - whichever you preferPossibility to work remotelySpeaking English on daily basis, mainly in contact with foreign stakeholders and peersMultiple employee benefits packages (MyBenefit Cafeteria, private medical care, life-insurance)Access to 3.000+ Business Courses Platform (Udemy)Access to required IT equipmentPaid Referral ProgramParticipation in charity events e.g. Szlachetna PaczkaOngoing learning opportunities to help you acquire new skills or deepen existing expertiseBeing part of the core squad focused on the growth of the Polish business unitA flat, non-hierarchical structure that will enable you to work with senior partners and directly with clientsA work culture focused on innovation and creating lasting value for our clients and employees\n ONLINE RECRUITMENT PROCESS STEPS Screening call with the RecruiterTechnical interview with Capco Hiring ManagerClient InterviewFeedback\/Offer"}
{"job_title":"Data Engineer (M\/F\/D)","company_name":"Ascent","location":"Germany (Remote)","job_link":"\/jobs\/view\/3761061168\/?eBP=CwEAAAGMPHDBRl031J79_0BZaaDh_fqQAOWepdukyJYhf6pxO1jCnz49gNCFWxh4Rg7RNvDOshfdxwCu45iToWbsakxQkGkOz_lXgs9EmytmIdBHTxRIsD0FP8lEFRRcOjRU7UhMAF08DUL9gSmw3wbj29b9FczUcpZVtctNcA0BkcIvE7cDms6Ym4CqaIPjkYCibyPfello6ydkJzMl3m0gVgBEgNXDm0_tapuxKUjijBCLHOtzjHuLC1sfCm34OLse6zks6TOUaya4teomnrXRoS6VHSYy28XZnZU40T442ZFgdv23dEf_n5S8VUESyASu8k2qFu7yaKbnlHzcmEux5n0_qd3DUjbbBv1LirPawzuAtsiA_Z0CrKv3ycMpiZoV&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=MYeYYDKo3IMpERZscFdERg%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3761061168","job_description":"About the job\n            \n \nIf you like providing efficient, effective solutions to complex challenges, join us at Ascent! Be at the heart of helping achieve extraordinary things with software and data for our customers! About usAscent is a design-led software, data and cloud business that specialises in advanced analytics and AI. We are an engineering business. We design, build and manage cloud-native products, solutions, platforms & experiences on Azure.Our pan-European community of engineers, architects, data scientists and digital consultants helps customers take on challenges and opportunities, so they can do something new, or do existing things better.From global insurance, pharma, healthcare and retail to smart home devices, space exploration and cricket - we get to work with some of the sharpest minds in the brightest businesses.We are now currently looking to hire a Data Engineer to join our Team. Skills and Qualifications Finished studies in Computer Science or other relevant fieldGood organizational \/ project management skillsT-SQLData Warehouse ModelingSSISPowerShellideally SSASideally PowerBIFluent German (at least C1) and good English language skills\n What you will do Further development of an enterprise data warehouse solution at one of our most important customersIntroduction of new data analytics technologiesData modelingDesign and implementation of ETL processesPerformance tuningAgile project work in a team with our data engineersContact with business units for requirements gathering\n Working at AscentAt Ascent we promote a healthy work-life balance by offering flexibility in where you work. We also promote well-being and provide access to Well Being Coaches.Your development and learning will be taken seriously, and we'll support your professional development with training and certification, with regular feedback and review. It is a fun, supportive and modern workplace where we live by our company values of Empathy, Energy and Audacity! Ascent also offers a variety of benefits in each of our countries.Ascent is an equal opportunities employer. We take intentional steps to ensure inclusion and belonging are something real here, not just something we talk about. No person will be treated less favourably because of their gender, pregnancy, and maternity status, marital or civil partnership status, sexual orientation, race, nationality, ethnic origin, age, religion or belief, or disability status. If you require any reasonable accommodation, please let us know when you apply."}
{"job_title":"Experienced Data Engineer","company_name":"EY","location":"Thessaloniki, Central Macedonia, Greece (Remote)","job_link":"\/jobs\/view\/3689319818\/?eBP=CwEAAAGMPHDBRjdgib8W9TKLEWhyvGLoT2ylBGzimduNxwBWVECijEg3SUpXNwO7ufft0WLaLdwNfrucCt9H2IoJwsmbIustlwssY1WxNxJlFxAxInB9EZTtS4alx9s5ZhyT2bxX6HX1Ow67eZOwjPiluP69pRfjIHFveMYfOw0DUDhpPkD-QuYKrJrlu33Zoo4tUfEWpmjT1Y9s9fhSZxQ49s9neaNHHvqN8lWYvPjhSMtiRp9ycaOM8UtGTsCoChCxONaA24kToQez9_i-kF-69o6MMCRooMTkPg4LdydxIPlerVUYt2tQpENw4bIG-gzaWwDTAOZZRacPFOTdlNJKTY6dqTsAgjeniAHRU_2Wrpbgz4EW4GEE2jj9xzDRzndR&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=L8%2BezrifV9gN17fmftvsSA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3689319818","job_description":"About the job\n            \n \nAt EY, you\u2019ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we\u2019re counting on your unique voice and perspective to help EY become even better, too.Join our continuously growing team, which employs over 2.200 professionals in Greece, and is listed in Greece's Top Employers for 2023! Experience great flexibility, under our hybrid operating model across our offices in Athens, Patras, and Thessaloniki, while benefiting from personalized learning and career development opportunities. We prioritize diversity, equity, and inclusion, fostering an environment where everyone's unique perspectives are valued, that supports you in building an exceptional experience for yourself, and a better working world for all.The opportunityModern technology produces more data than ever before, but also provides the tools to store, organize, analyze and share this data, resulting in new opportunities and substantiated business insights in support of new and deeper insights and more informed decision making. EY delivers leading services and solutions in the area of big data, business intelligence and data engineering built on a blend of tools and custom-developed methods.As part of our Data and Analytics team of the Technology Consulting practice, you will work with multi-disciplinary teams to support clients in a wide range of data initiatives aiming to generate and present new, useful and actionable insights. You will have the opportunity to work and take responsibilities in challenging engagements, gaining exposure to clients in various sectors both in Greece and abroad.Your Key Responsibilities Participation in large-scale client engagements.Contribution towards, or even leading delivery of innovative and engaging data engineering solutions.Understanding of business and technical requirements, provision of subject matter expertise and implementation of data engineering techniques.Designing innovative data engineering solutions. Conducting data discovery activities, performing root cause analysis, and making recommendations for the remediation of data quality issues.Putting into practice good organizational and time management skills, with the ability to prioritize and complete multiple complex projects under tight deadlines.\nTo qualify for the role you must have: A BSc or MSc degree in Computer Science, Engineering or other equivalent subjectAt least 3 years of relevant working experienceKnowledge of Data Management, Data Warehousing concepts & methodologies (familiarity with at least one of the following databases & design principles: DWH, DataLake, Lakehouse, Delta etc.)Working experience in complex SQL querying and development (Joins, Stored procedures\/functions, Aggregations\/Window Functions, CTEs, Indexes, optimization)Experience in ETL\/Pipelines design & development using industry tools (e.g. SSIS, Azure Data Factory, Databricks, Airflow, dbt etc)Excellent command in English both oral and written\nIdeally, you will also have: Working experience in Python programmingExperience with Cloud Data Platforms (Snowflake, Azure, AWS etc.)Experience with Apache Spark, Big Data Infrastructure and tools (e.g. Kafka)\nWhat We Look For Strong analytical, problem solving and critical thinking skills.Desire to investigate and try-out new tools and technologies as they are released.Ability to work under tight timelines.Good interpersonal skills and ability to work effectively within high-performing teams.Confidence to convey technical advice and guidance to clients.Self-motivation and continuous development.\nWhat We Offer Competitive remuneration package: You\u2019ll be rewarded for your individual and team performance. Depending on your experience, our comprehensive rewards package includes benefits that suit your needs including cutting-edge technological equipment, ticket restaurant vouchers, a private health insurance scheme, life insurance, income protection and an exclusive EY benefits club that provides a wide range of discounts, offers and promotions. Flexible working arrangements: We operate under a hybrid working model, which is defined based on both your own preferences and team\u2019s needs, and we enjoy our summers with short Fridays. Personalized learning experience and career development: We provide free and unlimited access to educational platforms and EY Badges, support certifications, and provide coaching and feedback, as a part of our Leadership & Development process, all of which can lead to a meaningful impact and success as defined by you. Transformative leadership: We\u2019ll give you the insights, coaching and confidence to be the leader the world needs.Diverse and inclusive culture: You\u2019ll be embraced for who you are and empowered to use your voice to help others find theirs.International Experience: Become part of international projects and work along multicultural teams, through our global network.Above all, you will be working in one of the Top Employers in Greece for 2023, awarded by the Top Employers Institute.\nIf you can demonstrate that you meet the criteria above, please contact us as soon as possible.The Exceptional EY Experience. It\u2019s Yours To Build.EY | Building a better working worldEY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.#betterworkingworld"}
{"job_title":"Data Engineer (m\/w\/x) Cloud\/Data\/Analytics","company_name":"K\u00f6lner Stadt-Anzeiger Medien","location":"Cologne Bonn Region (Remote)","job_link":"\/jobs\/view\/3741797138\/?eBP=CwEAAAGMPHDBRtwB8Bdwh7pRH5Jp021NRjMKKAU26vgq5_xzCCDNHe0JWral144TWM6FyKmtdA9YfZrgXJic6L8fJR1RPW98L9C13_ZNxFiqKpcAveDmJAQTTukrw1xl2WAKLj-qcvZnaeAq0hUcpnm7iWBCB1OgsYJZSH0n2DcCW9qYlTwsBSeExKoIoYoirJsu8_yOeTOZv2nEo8W2fbIWIUyCjtpteiXJE7LVBtkmIiDMSr23kARLGQX0lHiPZV-RnYtgVyLtCXAcmkwuriJKCcNaI5_5_VuVNsAI-peRsZbnmGljz0HxETXvU31MU6EtDTD2bwy96VVLYd946wP_i7p_Pf7SFX_FzRtNFX9AA9grn5h_ZMazg5A7TtaEX8qp&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=aVtdyQtWpnDXYxDbsC6qqw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3741797138","job_description":"About the job\n            \n \nDie \u201eK\u00f6lner Stadt-Anzeiger Medien\u201c stehen f\u00fcr Produkte, die mit publizistischer Qualit\u00e4t und lokalem Zuschnitt \u00fcberzeugen: K\u00f6lner Stadt-Anzeiger, K\u00f6lnische Rundschau und EXPRESS sind in der Region die f\u00fchrenden Titel mit klarem Fokus auf Regionalit\u00e4t, Aktualit\u00e4t und Authentizit\u00e4t. Die Digitalangebote unserer Regionalmedien geh\u00f6ren mit insgesamt 60 Millionen monatlichen Visits zu den reichweitenst\u00e4rksten News-Portalen in Deutschland. Unsere regionalen Anzeigenbl\u00e4tter und Radiosender begleiten viele Menschen jeden Tag als erste Informations- und Unterhaltungsquelle.Deine Aufgaben Du verantwortest die Application-Entwicklung in der Cloud und verf\u00fcgst idealerweise \u00fcber \u201eFull-Stack\u201c-Ambitionen.Du setzt gemeinsam mit Team Data durch Einsatz von Machine-Learning die Personalisierungsstrategien und -applikationen der Zukunft auf.Du konzipierst mit unserem Data Engineer Architekturen \u00fcber Micro-Services\/REST und erschaffst Automatisierungsl\u00f6sungen sowie Schnittstellen auf Basis von Echtzeitdaten und Data Science.Du entwickelst eine performante und offene Data-Architektur in der Cloud.Du bist verantwortlich f\u00fcr die Abstimmung der Anforderungen der IT-Architektur und beratest bei der Auswahl geeigneter L\u00f6sungen und Technologien.Du evaluierst im engen Austausch mit unseren Entwicklern und DevOps neue Technologien im Hinblick auf eine Optimierung unserer Systeme und Vorgehensmodelle.\nDein Profil Du verf\u00fcgst \u00fcber sehr gute Kenntnisse in Analyse, Design, Entwicklung und Integration komplexer Anwendungen und Softwarel\u00f6sungen in der Cloud.Du besitzt Erfahrungen im Umgang von Cloud-Werkzeugen wie Docker, Kubernetes und anderen Cloud-basierten Projekten.Du konntest schon mit Tools und Technologien wie Python, nodeJS, REST, JSON, SQL, Git, Jira und Confluence Erfahrung sammeln.Du hast Kenntnisse im Bereich Datenbankdesign und DevOps Du schaust gerne \u00fcber den Tellerrand und hast Spa\u00df daran aktiv neue Ideen und Verbesserungsm\u00f6glichkeiten im Team einzubringen und umzusetzen.\nBenefits GesundheitsaktionenMobile OfficeJobticketBetriebliche AltersvorsorgeNetzwerkDigitale WeiterbildungJobradMitarbeiterverg\u00fcnstigungen"}
{"job_title":"Junior Data Backend Engineer (Clickstream Analytics) (Remote - Ireland)","company_name":"Yelp","location":"Cork, County Cork, Ireland (Remote)","job_link":"\/jobs\/view\/3778941998\/?eBP=CwEAAAGMPHDBRiUk9f674O7NDKvAkRU9smv0IogDgprzwWz5SrSUINmvlXC43aa--eRyI-d_afWCCu8SHrVBF5HvtOyBAQYqJ1HWY05PqA66dLpOxooWrPj5dT8ez6iyykErRSnkoE0zxagFA47s1Gyj_f5Z6Vkl2Ygt_ZygCGS90QnEGWGt9-__uxlFSiSrQoCcT4XdwZ7ZMn-R7NH32KsGZD59GxQbg0IwyyxSiQyvjOhn8cOgSnDJsZt-OjdFsas9ASc9dUZcJnLfOeybCGPeq-UwhE2MifMiCNEqYcYh9Pmo6KGzOuYL-vEwh3MWcIrXLR2RljoNGPYVBDxNv7FQCj--f4q_EaB0ufLOp7noDciCP_LkX-E4wOhi-elQRw&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=o44If44pz1U22cMKZX0ZCw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3778941998","job_description":"About the job\n            \n \nSummaryInterested in exploring data and finding innovative ways to collect it, curate it, and make it easily accessible for others to use? How about doing that at an enormous scale? Yelp\u2019s datasets contain billions of interactions between users and local businesses around the globe. If working with our vast amount of data sounds exciting, come and join us!The Clickstream Analytics team is responsible for creating, managing, governing, and monitoring some key user journey metrics to support our product teams and also support offline analysis that aids in making long term company decisions. We also build tools that help us to better understand our data quality, and we strive to uncover data issues before they impact our consumers.As a Data Backend Engineer on this team, you will be responsible for building elegant and scalable data products that serve critical, up-to-date, structured information to support different types of analytics within Yelp. As a core contributor to our growing data modeling and data warehousing engineering efforts, you will help design and own mission-critical data flow pipelines and datastores to enable decisions including effective A\/B testing and company investments.Yelp engineering culture is driven by our values: we\u2019re a cooperative team that values individual authenticity and encourages creative solutions to problems. All new engineers deploy working code their first week, and we strive to broaden individual impact with support from managers, mentors, and teams. At the end of the day, we\u2019re all about helping our users, growing as engineers, and having fun in a collaborative environment.This opportunity requires you to be located in the Republic of Ireland. We\u2019d love to have you apply, even if you don\u2019t feel you meet every single requirement in this posting. At Yelp, we\u2019re looking for great people, not just those who simply check off all the boxes.What You'll Do Build systems that can effectively store and crunch terabytes of data.Design and develop data models for efficient data storage, retrieval, and reporting.Create and maintain conceptual, logical, and physical data models using industry-standard modeling tools.Collaborate with cross-functional teams, including engineers, data analysts, business analysts, and data scientists, to understand data requirements and translate them into effective data models.Participate in data integration efforts, including ETL processes and data migration.Stay up-to-date with industry best practices, emerging technologies, and trends related to data warehousing.Support on-call rotations as needed to operate the team.\nWhat It Takes To Succeed Understanding of high performing and scalable data systems.Experience in building and orchestrating ETL pipelines.Experience with Data Lake or Data Warehouse landscape.A hunger for tracking down root causes and fixing them in systematic ways.Ability to communicate effectively to technical and non-technical cohorts alike.Exposure to some of the following technologies: Python, AWS Redshift, AWS Athena \/ Apache Presto, Big Data technologies (e.g S3, Hadoop, Hive, Spark, Flink, Kafka etc), DBT.\nWhat You'll Get Full responsibility for projects from day one, a collaborative team, and a dynamic work environment.Competitive salary, a pension scheme, and an optional employee stock purchase plan.25 days paid holiday (rising to 29 with service), plus one floating holiday.\u20ac150 monthly reimbursement to help cover remote working expenses.\u20ac95 caregiver reimbursement to support dependent care for families.Private health insurance, including dental and vision.Flexible working hours and meeting-free Wednesdays.Regular 3-day Hackathons, bi-weekly learning groups, and productivity spending to support and encourage your career growth. Opportunities to participate in digital events and conferences.\u20ac95 per month to use toward qualifying wellness expenses. Quarterly team offsites.\nClosingYelp values diversity. We\u2019re proud to be an equal opportunity employer and consider qualified applicants without regard to race, color, religion, sex, national origin, ancestry, age, genetic information, sexual orientation, gender identity, marital or family status, veteran status, medical condition, disability, or any other protected status.Note: Yelp does not accept agency resumes. Please do not forward resumes to any recruiting alias or employee. Yelp is not responsible for any fees related to unsolicited resumes.Recruiting and Applicant Privacy Notice"}
{"job_title":"HQ - Senior Data Engineer (EMEA Remote)","company_name":"Job&Talent","location":"Madrid, Community of Madrid, Spain (Remote)","job_link":"\/jobs\/view\/3682749047\/?eBP=JOB_SEARCH_ORGANIC&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=UoCckPfQujtsl%2B5sqYbTkw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3682749047","job_description":"About the job\n            \n \nJoin us to work on the future of work: your next adventure awaits!The roleWe are looking for a highly skilled, organized, and self-motivated Senior Data Engineer who is passionate about building modern, cloud based and scalable self-service data platforms to join our Data Engineering team.You will be responsible for maintaining the current data platform and helping to create the new data platform based in the modern data stack. You will be working directly with engineers, data analysts, product managers, and other stakeholders to build out our analytics platform. We are serious about best engineering practices and writing quality software that is clean, easy to maintain, secure, and scalable is a priority.This is an outstanding opportunity to have a high impact on a fast-growing environment with unlimited potential for learning, responsibility, and career development.Responsibilities Collaborate with different stakeholders to define, develop, and implement our data platform, with an eye towards growth.Design and implement resilient ELT pipelines from a wide range of data sources and tools.Help maintaining our Airflow infrastructure and ensure efficiency in our orchestration processes.Contribute to the implementation of engineering best practices, including documentation, code review, unit tests and integration tests in a CI\/CD environment. Advocate for improvements to data quality, security, and performance.Serve as a technical lead on our data engineering team, providing training and mentorship to help develop the skills and talents of others\nRequirements 5+ years of relevant experience in data engineering Solid background in DWH solutions such as Redshift Experience with ingestion pipelines like Meltano, Airbyte, Stitch\/Singer.io or similar Experience developing production-grade ELT\/ETL pipelines (Dbt, Airflow\u2026) Experience with Data Observability Experience with streaming data pipelines (Spark Streaming, Flink, KsqlDB\u2026) and Kafka High-level experience with Python A high level of proficiency in SQL Highly valuable having experience with Spark (with Python or Scala) Understanding of software development best practices such as documentation, version control, testing, and CI\/CD\nNice to have Experience with cloud providers, specially with Amazon Web Services (Glue, EMR\u2026)Ability to build and optimize data pipelines using cloud engineering platforms such as Google Cloud Platform or Amazon Web ServicesExperience with technologies like: Hudi, DeltaLake or IcebergComfortable working with modern data technologies (Docker, Kubernetes, etc.)\nWhat We\u2019re AboutAt Job&Talent, we're revolutionising the employment market globally. Our mission is simple and clear. We\u2019re empowering the people who do essential work - from delivery drivers and warehouse workers, to cooks and cleaners - to get work and get paid on their terms.We match these people with companies we\u2019ve verified through our powerful tech platform. Apps, AI, web-based tools, innovative matching solutions and more. We create seriously smart technology, made for humans, by humans.And the numbers show we're doing things right. 340,000 people got work with over 2,500 companies globally last year, with clients spanning industries from logistics to retail, hospitality and more. We generated \u20ac1.9 billion in revenue in 2022. And we\u2019re grateful to our top tier investors at Atomico, Kinnevik and Softbank.We're headquartered in sunny Madrid, but we're a remote-first company operating in 10 countries across Europe, the United States and Latin America.But there\u2019s a missing piece. You.Join our communityIf you\u2019re looking for a company that values innovation, high standards and data, you\u2019ve found it. We\u2019re also good listeners, because everyone\u2019s voice is heard at Job&Talent. These values help us make good decisions and keep momentum. That\u2019s how we operate. Standard.When it comes to our people, we\u2019re all uniquely different. And it\u2019s that difference that makes us stronger.We encourage everyone to bring their true selves to work. Being real and empathic means we can build better products, services and workplaces for our workers and our clients. And dare we say it, we think that makes us all happier humans.What\u2019s In It For YouWe're building the world\u2019s leading digital marketplace for essential work. You\u2019ll hear 10x experience, AI, technology and human-centred design quite a lot. We strive for that across the entire company, from finance, to supply, to product.Make an impact through extreme ownership of the work you do. You create something and you help drive it forward. At Job&Talent, you\u2019ll make an impact across borders with cross-functional teams, wherever you are.Be rewarded financially. It\u2019s ingrained into our company philosophy. We offer our employees competitive salaries and benefits. Our Talent team can tell you a lot more about the perks in your region.Grow professionally by doing, not just watching or talking. We\u2019re completely hands-on and we\u2019re bootstrappers, making the most of our resources. And don\u2019t be surprised to find yourself on a call with one of our founders. They like the details as much as the big picture.Proud to champion equalityAt Job&Talent we value diversity and we're an Equal Opportunities employer. We welcome applications from all suitably qualified people regardless of national origin, race, disability, religious beliefs or sexual orientation. Come join us. We look forward to your application."}
{"job_title":"Data Driven | Data Engineer","company_name":"Devoteam","location":"Lisboa, Lisbon, Portugal (Remote)","job_link":"\/jobs\/view\/3766359405\/?eBP=CwEAAAGMPHDBRsxkPLrkPFKfmySepb3Cfu0XOZ3iIkkqMGIdmOitw0Iqaq6KjD-HPjMuCtczY4UTD5AvbUVlpsmoPs9FVleNi5RI6unJjjdtoIZFLLjysUIoFx35RYGsRpdxqEVe_nbZ1j_BgvnjdRbN6ovIVvER141FpY8h8K_VOxOeu95arMhDeDfNJLxCM76q8x8T_L5ZwrEZ81lC3RFDMgzkoMhDLXxA_pafyxmpB2sEolHNH3TrVRJGi5nxXYsMzQd3S7dXofbAhjshh_HUlj4pp1z50gGaddrhV1w8rZpeUYYtqoVVDOqLd-nBJ9zuV2JSCC4dKcLxGInphGug_7iAWPWHos5MpbNTfrDqAT8M7v2DWQ15tv64O-Fa4g&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=ApPS9P7xgflwCIsmJq7X5Q%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3766359405","job_description":"About the job\n            \n \nCompany DescriptionAt Devoteam, we believe that technology with strong human values can actively drive change for the better. Discover how Tech for People unlocks the future, creating a positive impact on the people and the world around us. We are a global leading player in Digital Transformation for leading organisations across EMEA, with a revenue of \u20ac1B. We believe in transforming technology to create value for our clients, partners and employees in a world where technology is developed for people. We are proud of the culture we have built together. We are proud of our people at the service of technology. We are proud of our diverse environment. Because we are #TechforPeople. Join our multidisciplinary team of Cloud experts, Designers, Business consultants, Security experts, Engineers, Developers and other extraordinary talents, spread across more than 20 EMEA countries. Become one of our +10.000 tech and business leaders on cloud, data and cyber security. Let\u2019s fuse creativity with technology together and build innovative solutions that actively change things for the better.  Job DescriptionWe are currently looking for a Data Engineer to work with us.  Qualifications  Bachelor\u2019s or Master\u2019s degree in IT or equivalent;At least 3 years of experience as a Data Engineer;High level of experience with the following programing languages: Python and SQL;Working experience with AWS or Azure;Proficient Level of English (spoken and written);Good communication skills;Knowledge in Airflow will be a plus."}
{"job_title":"Azure Databricks Data Engineer","company_name":"Nordcloud, an IBM Company","location":"Warsaw, Mazowieckie, Poland (Remote)","job_link":"\/jobs\/view\/3745339267\/?eBP=CwEAAAGMPHDBRjvlxp2wZDDLJY625bLTDJ3Kahh8n_Sl14ZQTcjNpT5vMv4djT9Se6HW7qNlyHzJnyE9dez896fxIVqzvmcaKIdtf7iQcPw-xyrLJX0sk10pe0DFjut6pm1iCOiNOua-V41lv4ZIl8ysXoT_ws5Dx0uTHcKG9gKGcczJdazP8kiUQU6mWdOevpkX8QCCSpef7kNL4znPyi-dd2P8vrErnzgZDwkSfTQ24IXm_saBXl-hN65ZnoMwZbDoGzsffsxuQuAvApSxgG2CVlpTLO_DNjib_cdkYpciGFdXdR268el8YdP9Lhy1Y_maOF14G17jt2Ga-W48oQxcyde9eSSyZ55a3cRGyWI_UGI3VyKMgWebNg4mssQfnJw0&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=R3XFsclxrZqUHRuFZFMyVw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3745339267","job_description":"About the job\n            \n \nJoin Nordcloud and make your mark on the European IT industry. Help our clients thrive on their cloud journey in solution areas such as infrastructure, migration, data, and security.Currently, we are looking for an Azure Databricks Data Engineer for our team in Poland.Your daily responsibilities: Designing, architecting, and implementing modern cloud-based pipelines for our customersMaking data accessible and usable for a new wave of data-powered apps and services\nYour key skills: 5+ years of professional programming experience and hands-on experience in building modern data platforms\/pipelinesAt least one programming language: Python\/Scala\/JavaExperience in job orchestration (Airflow, Composer, etc.)Experience in DatabricksExperience in Azure; (AWS, Google Cloud would be a plus) Experience in Data Engineering related technology stack (Azure Synapse, ADF, Dataflow, Pub\/Sub - this is not an exhaustive list)Good knowledge of data storage and processing engines in the selected Cloud provider\nConsultancy experiencePrevious experience gained in mid-size\/large, international companiesFluent communication skills in English \nWhat sets you apart (we\u2019d consider any of these a big plus): OPS knowledge - Kubernetes\/Docker\/CI\/CD - how to efficiently put things into prodBasic IaaC skills (Terraform or similar tools)Testing skills (writing automated tests\/data quality checks)Basic low-tech data analytics skills - Excel\/pandasExperience in SQL Data modeling (Kimball, Inmon, Data Vault, etc.)Advanced SQL in any SQL dialect ANSI SQL\/specific database specific dialectsSpark SQLHive\/ImpalaPresto\/Trino\nExperience in building ETL processes for data warehousing solutions\nExperience with MongoDB or CassandraFamiliarity with data lake architecturesExperience with SnowflakeActive (knowledge-proven) certificates\nWe encourage you to apply, even if you don\u2019t meet all of the requirements. We value your growth potential and enthusiasm!What do we offer in return? Individual training budget and exam fees for partner certificationsFlexible working hours and remote working modelLaptop and equipment of your choiceLocal package such as health care, life insurance, a cafeteria system, and a virtual assistant (AskHenry)\nPlease read our Recruitment Privacy Policy before applying. All applicants must have the right to work in Poland.About NordcloudNordcloud, an IBM company, is a European leader in cloud advisory, implementation, application development, managed services, and training. We are triple-certified across Microsoft Azure, Google Cloud and Amazon Web Services, and we are recognized as a 'Visionary' by Gartner for Public Cloud IT Services. With 10 European hubs and over 1300 employees, we are known for our innovative cloud-native solutions and we have delivered over 1000 successful cloud projects.Learn more at nordcloud.com and follow the #NordcloudCommunity."}
{"job_title":"Data Engineer (m\/w\/d)","company_name":"nexMart GmbH & Co. KG","location":"Germany (Remote)","job_link":"\/jobs\/view\/3763182804\/?eBP=CwEAAAGMPHDBRqbZDcT7McbQ0RnDrHwDsRqCybL1wu2bIaMnkrhdJ3T2_q0nlh3hqpnpZ1vbeU4UtZyR5u-T9lmEsS79sTJzsYS-9dgcq0J6RBhMHPLd1zOG3gcinjpSqLvu3ZOjfYS0TA8QXQi5tFmdOqNbFoIjDvH3URTLY4T78oL9nJDHjRelzksJLzK_QYGvPreAol1fBg1nT1Kr-A4XZsPGOJ2NdJh-Ry0aIw1BW4x06v044mTdtixG1YnylxuA3oyXY3jSOCu9BrF1ZUOkxrk-oeSoE2Szrfm_05QYz0EP3ac5WlNSylbI6A3ayCDl68MI6mD4o6yD1k3z5_bQnpmMEvbaX4avQ_A1u6kxzIAxP2y1gDGOHv1p7c36Do7d&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=kTpDlh0xAvU9t9RRNiiUSA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3763182804","job_description":"About the job\n            \n \nAls (Senior) Data Engineer (m\/w\/d) \u00fcbersetzt du Gesch\u00e4ftsanforderungen in technische Datenanforderungen, erstellst Priorisierungen und unterst\u00fctzt den Datenbedarf mehrerer Teams, Systeme und Produkte.Bremen, Stuttgart oder Homeoffice \u00b7 Vorort \/ Hybrid \/ Remote \u00b7 40h\/Woche  Du analysierst, organisierst und erweiterst Rohdaten und die Datenpipeline-Architektur.F\u00fcr verschiedene Anwendungsf\u00e4lle optimierst du den Datenfluss und die Datenerfassung.Du identifizierst, entwirfst und implementierst interne Datenprozesse: Dazu geh\u00f6ren Automatisierung manueller Prozesse, Optimierung der Datenbereitstellung, Neugestaltung der Infrastruktur f\u00fcr bessere Skalierbarkeit usw.Der Aufbau eines Monitoringsystems f\u00fcr Datenpipelines und die Messung der Prozessleistung geh\u00f6ren ebenfalls zu deinen Aufgaben.Du arbeitest mit anderen Teams\/Kollegen zusammen, z. B. mit dem Daten- und Infrastrukturteam, um gemeinsam an der Festlegung von Datenstandards zu arbeiten, Datensysteme aufzubauen\/zu pflegen oder die f\u00fcr eine optimale ETL von Daten erforderliche Infrastruktur aufzubauen.\nDas bist du:  Du hast Erfahrung im Aufbau und in der Optimierung von Datenpipelines, Architekturen und Datens\u00e4tzen aus unterschiedlichen Quellen.Du bringst fortgeschrittene Kenntnisse in SQL und in der Optimierung von Datenabfragen mit.Praktische Erfahrung mit Datenbankdesign sowie gute Programmierkenntnisse und Detailorientierung zeichnen dich.Du bist erfahren im Aufbau von Prozessen zur Unterst\u00fctzung von Datentransformation, Datenstrukturen, Metadaten, Abh\u00e4ngigkeits- und Workload-Management.Zudem bringst du Kenntnisse \u00fcber Leistungssteigerungs- und Optimierungsm\u00f6glichkeiten f\u00fcr gro\u00dfe Datens\u00e4tze und Automatisierungsm\u00f6glichkeiten f\u00fcr Prozesse mit.Du hast sehr gute Englischkenntnisse.\nUnsere Benefits: Flexibel statt Nine to Five - Mobiles Arbeiten und Workation, flexible Arbeitszeiten, unterschiedliche Teilzeitmodelle \u2013 all das ist bei uns m\u00f6glich.Wir leben die Vereinbarkeit von Beruf-& Privatleben - z.B. mit 30 Tagen Urlaub plus auf Wunsch 5 weiteren Freizeittagen.We #takecare - Dein ehrenamtliche T\u00e4tigkeit unterst\u00fctzen wir mit einem zus\u00e4tzlichen Urlaubstag und unterst\u00fctzen aktiv Klimaschutzprojekte.Komm\u2018 wie du bist - Ganz ohne Dresscode in eine humorvolle, wertsch\u00e4tzende Teamkultur.Feier mit uns gemeinsam - Nexie-Teamabende, ausgefallene Sommer- & Winterevents und die kleinen Erfolge direkt im Office.Top Tech-Stack - Arbeite mit modernen Technologien und Methoden wie z.B. Vue.js, Java & Kotlin, Docker, OpenShift, PostgreSQL, u.v.m.!F\u00fchl dich wohl im Office - Quiet Space, Kickerrunden, gemeinsame nexMampfs, frisches Obst und der Latte Macchiato sind bei uns selbstverst\u00e4ndlich.Deine Gesundheit ist uns wichtig - Sei unterwegs mit BusinessBike und werde Mitglied bei EGYM Wellpass mit \u00fcber 6.500 Trainingsm\u00f6glichkeiten.Entwickle dich mit uns weiter - Wir f\u00f6rdern deine pers\u00f6nliche & fachliche Entwicklung \u2013 mit Schulungen inhouse & extern, Coachings und Sprachtrainings.\nHaben wir dich neugierig gemacht? Dann freuen wir uns auf deine vollst\u00e4ndige Bewerbung. Bitte nutze f\u00fcr deine Bewerbung unser Online-Bewerbungsformular. Erfahre unter www.nexmart.com\/karriere mehr \u00fcber nexmart als Arbeitgeber.Mach's einfach - im Team nexmart.Angefangen haben wir vor 20 Jahren in Stuttgart als digitaler B2B-Marktplatz f\u00fcr die Werkzeugbranche. Heute agieren wir mit \u00fcber 100 Mitarbeitern an 8 Standorten als international ausgerichteter eBusiness-Spezialist.Unser Antrieb ist Wachstum. Um dies zu erreichen, gewinnen wir neue Kunden f\u00fcr unsere digitalen L\u00f6sungen und entwickeln bestehende Kunden erfolgreich weiter. Unsere Zielgruppe sind Hersteller, H\u00e4ndler und Systemh\u00e4user. Durch unsere langj\u00e4hrige Marktkenntnis sind wir in der Branche sehr gut vernetzt. Wir verkaufen nachhaltig und bauen auf langj\u00e4hrige Kundenbeziehungen.nexMart GmbH & Co. KG \u00b7 Gropiusplatz 10 \u00b7 70563 Stuttgart I Konsul-Smidt-Stra\u00dfe 8 s \u00b7 28217 Bremen \u00b7 Telefon 0711\/ 99783300 \u00b7 hr@nexmart.com"}
{"job_title":"Data Engineer (f\/m\/d)","company_name":"CHARACTERS CONNECTION LTD","location":"Germany (Remote)","job_link":"\/jobs\/view\/3765010716\/?eBP=CwEAAAGMPHDBRpOXXrNfvTSvtGpaMKsynAjUDbHXyryaGsqMVs5RRPDvAQZU8bWMQRdUtfss5qNWJu1LbF4TrmO1lpOGyU_gyODZMg1pRmRGlmQ_vLRxu7cBotQnm76D4fiWbVRyIClxPLE_EPlMuKF63LoIxAo8ZVoklmtDD_qfDKSbFO5bZCoKdPRNIV973NaAHTs-qEATq9bdFGhHDaLc8fb5IvlZh7U63ITy2GYfZJy3Hzyo-2S3wVpgnbHlARkp4p0JiuXgRcrAv24MSwcl3YbWQbEQ6ZmxnHBh0nWJMsU1x7sqLtZOhjxUVV0g-MTfLoj4x6IPRuvmd1bGqaScuvKzDP-_5P3RDd4-YDt72iLAyQ1KcJvk6kLTYMmdiw&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=hXkhad0OkWY1y6CCwfEdLA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3765010716","job_description":"About the job\n            \n \nHere\u2019s your opportunity to revolutionize the construction industry. We\u2019re looking for our leading and international client for a Data Engineer (f\/m\/d) to become a future team member. You\u2019 ve the freedom to choose a remote\/mobile or office work, mixed up with regular on-site team event sessions.YOUR ROLE: Design, develop, and maintain data pipelines using AWS, Postgres, RabbitMQ, Kafka and other relevant technologiesBuild and manage data storage solutions to support analytics and reporting needsDevelop and optimize RESTful APIs for data access and integrationProvision, configure and maintain cloud infrastructure defined as codeUsing and extending our existing code base working together with our colleagues as well as external development teamsCommunicate efficiently and collaborate with peer engineers to create state of the art productsEye on documentation, consistency, and modularity of our code baseAdvancing our development best practices and implement and improve testing and automation\nYOUR PROFILE: Experience as a Data Engineer with a strong track record of building and maintaining data pipelinesSubstantial experience utilizing and maintaining cloud services, preferably AWSProficient in Python, SQL, Postgres, Kafka, Kubernetes, and RESTExperienced in Infrastructure-as-Code (e.g. Terraform, Ansible etc)Versatile, curious minded and you enjoy expanding your areas of expertiseCommunicating and working independently as well as part of a teamProficient in English and comfortable with remote teamwork\nInterested yet? Feel free to send us your application letter!"}
{"job_title":"Data Engineer","company_name":"TUI","location":"Porto, Porto, Portugal (Remote)","job_link":"\/jobs\/view\/3771218876\/?eBP=CwEAAAGMPHDBRnXBx2gD3lDJmZIRokSS5ExbESgbfyD2Lv1SLzPT0PBZw2le66yv-GkzPa6oCNIn5qqBW5W8qGyrybNdLhTzKmVsDtYhdBy337u2XCjPxmoUuD_fb1gg36CmEnA60s-U0pXLUxTiNrGBnlwmx2JoJe1foDfq0tlF8T3DRVQiFSj_A1PL5L5_bRyRxJStmxph1ptZfKnR8pem8Zd8CpjAjbGsk4tTKGAgSIyx8IYjjlKf1qGQ2-IO56KuYD8fKRqkcUL1LYws-6lGFpeWFu-yJN7AjhYuFl0aF_PdV0W5ZqyR4WV40El_ZKID-XqS8-jxUfuwcmCXfQvl7q0yFkXDHJ989cvissmTigdZ5OsRM56qSQVeO0Ub4_te&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=Xz3m7oQ9G7spLF2pL5Tbdw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3771218876","job_description":"About the job\n            \n \nTUI Group is the world\u2019s number one integrated tourism business. CVM technology analytics is a team responsible for ingesting, modelling and extracting data in the TUI Central Region for CRM purposes. We are a multi-disciplinary team of experts across Architecture, Engineering, DevOps and Agile Delivery providing services across the UK, Ireland, Sweden, Norway, Denmark, Finland, Germany, Belgium and The Netherlands.At TUI we\u2019re ambitious to become the leader in technology within the travel industry and to achieve this we are looking to build a capable, creative team who want to be a part of accomplishing that goal.We never stop looking ahead, seeking new ways to delight our customers and grow our business. We recognise the power of digital and the massive contribution this brings to creating a truly unique and differentiated customer experience.We are looking for a talented and dedicated technical enthusiast to join the Analytics Master Domain organisation which provides state of the art data products. ABOUT THE JOB: As a Data Engineer, you will be part of a cross-functional team that enables data engineering skills and capabilities across a whole domain. Being an enthusiast in data engineering, with a strong DevSecOps mindset, you\u2019ll use your excellent collaboration skills to work with your team to deliver the best answers to our customers\u2019 needs with full responsibility for its data flows from design to operation. You will use your deep technical skills to work closely with your colleagues to ensure an optimal data delivery architecture which is consistent throughout ongoing projects. You will work on data collection, data pipelines, data delivery to other systems and building a strong core data warehouse. You will Support your fellow Data Analysts and Data Scientists on data engineering tasks and work as a team to deliver data driven solutions.You will Build and maintain data processing systems, including data ingestion, data quality control, and data warehousing.In addition to ensuring operational and analytical excellence you will be working on connecting on-premise data with cloud computingPerform root cause analysis to identify and resolve data quality issues.Demonstrate meticulous attention to detail in ensuring the quality of your work, encompassing comprehensive documentation and stringent security measures.\nABOUT YOU: Work experience as a Data Engineer or similarStrong SQL and data profiling skills \u2013 enjoy working with data, process analytics and development, understanding of common architectures. Experience in data modelling with ETL (e.g., usage of Informatica) and scheduling (e.g., UC4, airflow).Knowledge of BI applications such as Power BI, Tableau or Spotfire.Able to work with GitLab or similar tools for code management.Preferred experience with AWS and SnowflakePreferred experience with Big Data projectsGood communications and influencing skills, with the ability to explain technologies and solutions to technical and non-technical stakeholdersCritical thinker and able to provide constructive feedbackBachelor\u2019s Degree or equivalent in Computer Engineering or similarExperience in the Tourism Industry is a plusFluent in written and spoken English, German skills is a plus.\nAbout Our Offer Working in the leading global tourism group: We stand for intercultural cooperation and offer the opportunity to work in international projects and teams.Fantastic holiday benefits including discounts, special offersMobile working, flexible working hours and working from abroad: We believe that work is something you do, not where you go. Our offer: TUI Way of Working Health and Wellbeing support in five key areas \u2013 Health, Social, Community, Career and FinancialDevelopment and career opportunities: We offer a wide range of digital training and international career opportunities.Additional benefits relevant to the local market that you'll be based in\nAt TUI, we know people are as diverse as the destinations we send our customers to. We love to see your uniqueness shine through and inspire the future of travel. If you would like to read more about what Diversity & Inclusion means to us simply visit our Smile page Click hereIf you have any questions, please contact the Recruiter for this role via the contact information included in the advert.Please Note: These vacancies will be managed by an International Recruitment Team and therefore your application may be viewed by TUI colleagues outside your home country.#TUIJobs"}
{"job_title":"Data Engineer","company_name":"Flywheel","location":"Dublin City, County Dublin, Ireland (Remote)","job_link":"\/jobs\/view\/3773897710\/?eBP=JOB_SEARCH_ORGANIC&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=BYCPzvu11QbrL9llox0R1w%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3773897710","job_description":"About the job\n            \n \nAbout FlywheelFlywheel\u2019s suite of digital commerce solutions accelerate growth across all major digital marketplaces for the world\u2019s leading brands. We give clients access to near real-time performance measurement and improve sales, share, and profit. With teams across the Americas, Europe, APAC, and China, we offer a career with real impact, endless growth opportunities and the support you need to be the best you can be.OpportunityWe're looking for a Mid\/Senior Data Engineer to join our team. The best candidates will hit the ground running and contribute to our data team as we develop and maintain necessary data automation, reports, ETL\/ELT, and quality controls using leading-edge cloud technologies. You will have a deep knowledge and understanding of all stages in the software development life cycle. The ability to self-start, mentor and manage less experienced data engineers, desire to learn new technology, manage multiple priorities, and strong communication are all in your wheelhouse!What you'll do: Write high-level, well-documented code in Python and SQLBuild data pipelines that range from simple to complex, using technologies like Apache Airflow and AWS Lambda, Step Functions, and EventBridge, and other AWS serverless technologiesBuild ETL pipelines with Snowflake, AWS Glue, pyspark and other ETL toolsWork with a mix of structured and unstructured data across cloud-based batch and streaming architecturesEngage directly with technical analysts, project managers, and other technical teams to help build concise requirements and ensure timely completion of projectsWork with Git, CI\/CD, and version control to maintain code and documentationDesign and vet solutions for technical problems, and solicit team feedback during the design processMentor, manage, train, and participate in paired programming in a lead capacity\nWho you are: Must have experience with version control, GitHub, and software development life cycle4 years experience with SQL and data modeling4 years experience developing with PythonDemonstrated experience interacting with RESTful APIsExperience with data pipelines \/ batch automation in at least one major technology (e.g. Apache Airflow)Experience with one of the major cloud providers (AWS-preferred)AWS Serverless (lambda, eventbridge, step functions, sqs)Experience working in an agile development environmentStreaming experience (kafka, kinesis, etc.)Familiarity with JiraExperience with other AWS technologies: EC2, Glue, Athena, etcExperience with additional cloud platforms beyond AWSExperience developing CI\/CD, automations, and quality of life improvements for developers\nWorking at FlywheelWe are proud to offer all Flywheelers a competitive rewards package and unparalleled career growth opportunities and a supportive, fun and engaging culture.  We have office hubs across the globe where team members can go to feel productive, inspired, and connected to others Vacation time will depend where you're located Great learning and development opportunities Benefits will depend on where you're located Volunteering opportunities Learn more about us here: Life at Flywheel\nThe Interview Process:Every role starts the same, an introductory call with someone from our Talent Acquisition team. We will be looking for company and values-fit as well as your professional experience; there may be some technical role-specific questions during this call.Every role is different after the initial call, but you can expect to meet several people from the team 1:1 and there might be further skill assessments in the form of a Take Home Assignment\/Case Study Presentation or Pair Programming\/Live Coding exercise depending on the role. In your initial call, we will walk you through exactly what to expect the process to be.Inclusive WorkforceAt Flywheel, our goal is to create a culture where individuals of all backgrounds feel comfortable in bringing their authentic selves to work. We want all Flywheel people to feel included and truly empowered to contribute fully to our vision and goals.Flywheel is an Equal Opportunity Employer and participates in E-Verify. Everyone who applies will receive fair consideration for employment. We do not discriminate based upon race, colour, religion, sex, sexual orientation, age, marital status, gender identity, national origin, disability, or any other applicable legally protected characteristics in the location in which the candidate is applying.If you have any accessibility requirements that would make you more comfortable during the application and interview process, please let us know at recruitment@flywheeldigital.com so that we can support you.Please note,\u202fWe do not accept unsolicited resumes."}
{"job_title":"Senior Data Engineer (f\/m\/x)","company_name":"Mercedes-Benz.io","location":"Portugal (Remote)","job_link":"\/jobs\/view\/3770464431\/?eBP=CwEAAAGMPHDBRul-_N7kdmWR9pP_pHHWsAY0pIJpTcvw05OfS87YDtyDYeqkEEyHMp8_SL1BaC2lliCNxCn7CVl3MXvh-HQvMXahLjqYe8JkO830uqLDXqKFRPEEto6ii9thVx8jcd6r_RpMbiUr8kgZUXUHikiilYWROityXleGoFM4tOEPdXOirbkYgNqDXJVb1zVsgcrSTzJDKQul6Mu8Dg-S2JnI2stkxFDetcBInKmG1mOYjRPX3c3C4Yq8iIGNgQ826LVIxg1XqTV9XMziOkG_nxslmTrKMDDe4ldagD8W9T-wB0XLVcpuDOHaOvePxw0hq2nR5OtfQj9DZRkoYZ5xDKREXHaLv0eRPoblijz4zUlFrsxgKM2t8tR2bA&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=9J%2FaTVOI2PD6w76ZH3OV6w%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3770464431","job_description":"About the job\n            \n \nHEY THERE!We are Mercedes-Benz.io. Our mission is to Ignite and build the digital solutions for Mercedes-Benz by forming a tribe of digital enthusiasts that drive Mercedes-Benz digital future.Therefore, we offer 100% flexibility! You can choose if you want to work from your mobile office in Portugal, or from our offices in Lisbon or Braga. It's up to each of us to decide according to our needs.We don\u2019t care about your shoes, as long as you are wearing the right attitude. At Mercedes-Benz.io we walk the talk and make things happen. We do not digitize for the sake of being digital but for a better tomorrow for our customers. That\u2019s not our job; it\u2019s our passion. Therefore, we love to reflect and challenge everything \u2013 the status quo, Mercedes-Benz, and ourselves. We share the same beliefs and stand up for each other and this is why we hire unique people to join our Tribe of digital enthusiasts.WHAT IS OneDNA?If you join us, you would be a part of our OneDNA team. OneDNA creates a cutting-edge data platform for KPI reporting, data analyses, and data science for the digital business of Mercedes-Benz.io.We are responsible for building, maintaining, and enhancing a comprehensive data models that covers relevant data sources for more efficient reporting and analysis of our stakeholders.We define and maintain KPI frameworks to ensure governance and enforcement. Our team builds and maintains dashboards with a defined business impact for stakeholders based on an aligned style guides and offer trainings. We ensure an efficient data sharing process in eXtollo for our data models, including documentation.Our team also offers consulting and enablement around to our stakeholders and finally, we build data science use cases to support data-driven product development.IN THIS ROLE YOU WILL Create and maintain scalable and efficient data processing infrastructure to ensure a reliable and high quality data supplyDeveloping, setting up and maintaining scalable data processing infrastructureDefining, implementing and maintaining complete data pipelines (including data cleaning and integration)Setting up and maintaining storage infrastructure that serves the needs of Digital Analysts and Data ScientistsSupporting deployment and monitoring of machine learning pipelines serving models in productionCommunicating with data owners and the team to ensure adequate data supply and collect feedback\nTO SUCCEED YOU NEED 5+ years of experienceHands-on software engineering experience and the ability to write efficient, well-tested and maintainable code with a focus on performance and scalabilityExperience with Python and SQLKnowledge in relational databases and big data technologies like Apache Spark and PySparkStrong understanding of Data WarehousingExperience crafting data solutions and deploying data pipelines in production using Cloud solutions (Azure Databricks, Data Factory, Azure DevOps)Understanding of Data Governance, Data Quality and Data monitoring\nTHERE WILL BE BIG SMILES IF YOU Have experience working with scheduling tools such as Apache AirflowExperience working with Google AnalyticsKnowledge about Kubernetes and Docker\nYOU WILL BE HAPPY WITH Open source softwareNo top-down hierarchy. We trust in your self-organizationColleagues that are as smart, hardworking and driven as youAn amazing open-minded and informal culture with the backup of a giant company like Mercedes-BenzIPhone, MacBook Pro or Dell (your choice) and noise-cancelling headphonesHealth insurance for you and your familyLife insuranceProactive self-development in international Trainings and ConferencesLanguage Training coursesWellbeing actions (massages, nutrition sessions, happy hour and more)Brand Connection PerksMuch more cool stuff \u2026\nTHIS IS WHAT OUR PROCESS LOOKS LIKE Screening call with our recruiter to get to know your motivation & your experience1st Technical interviewTake Home Technical Challenge2nd Technical interviewFinal InterviewOffer\nWHAT YOU'LL NEED TO KNOW ABOUT USMercedes-Benz.io develops software and technology for the digital platforms of Mercedes-Benz. Our main products are the Mercedes-Benz Website worldwide, the e-commerce platform, digital services and aftersales solutions.We have a fantastic team with people from all over the world. We encourage frequent collaboration and pairing across disciplines. English is the main working language.Mercedes-Benz.io is an equal opportunities employer. We believe that diverse experiences and a broad collective perspective lead to a better company culture and better products.Interested in engaging with a continuously evolving company to work hard, play hard and party hard? If so, please send your resum\u00e9 (in English and PDF)."}
{"job_title":"Data Engineer BI (FULLREMOTE)","company_name":"Capitole","location":"Greater Madrid Metropolitan Area (Remote)","job_link":"\/jobs\/view\/3778374503\/?eBP=CwEAAAGMPHDBRnKbLXXxh9mccKsrfeLzh660VtAfBVsGt7ctkRb1gLsojqCreY9DfzOJF35uRPOLF4UZVaB4SdHmEnEssZ84g7JwzvR1eAxvRFpZx2jamT4ULMufBl9cFlnj6q8I5LyjzHoBXx6azx1gy_X1vVWhp3zqeJH7HggtG9wXjvr3rApA8JCQ0zhS5FE3iee6Vw-VADumBKFdIG3mWc9LWvOzl1RDvgyOE0MDeCsWu3kicn8Tazz3f2x-IWaLAN5mGaLYwFUZgcbbSvjXXolLgXU8VgRIzmomhX2a1W1Qb5qZzo_PrEtbKX_zXm17MI_Rhm6uDfBdESEYVbM8VC1fWeQgfA0Dnw_PhD39p07DASmvoKKzpGRggvdrRVvb&refId=gBSgqWRcx9M1PJj%2FSl75eg%3D%3D&trackingId=JxIcaUtAsKkXrU8oKiymnA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3778374503","job_description":"About the job\n            \n \n\u00a1En Capitole seguimos creciendo y queremos hacerlo contigo! \u00bfQuieres unirte a nuestro equipo?Por ello queremos incorporar un Data Engineer BI (100% TELETRABAJO), para una compa\u00f1\u00eda multinacional perteneciente al sector servicios, dentro \u00e1rea de Data Management & BI. \u00a1Se trata de un proyecto internacional, totalmente estable!\u00bfQu\u00e9 buscamos?\u2022 Fuerte experiencia en el desarrollo de flujos de datos, con SQL.\u2022 Al menos 5 a\u00f1os trabajando en desarrollo de ETLs, para movimiento de informaci\u00f3n entre fuentes de datos con Data Services (SAP DS).\u2022 M\u00ednimo 5 a\u00f1os de experiencia en el uso de la plataforma de reporting SAP Business Object (SAP BO).\u2022 Haber gestionado Datasets en PowerBI.\u2022 Haber trabajado para repositorio de datos, con SAP IQ.\u2022 Nivel de ingl\u00e9s m\u00ednimo B2.Condiciones:Modalidad: FULLREMOTE.Ubicaci\u00f3n: Comunidad de Madrid y alrededores.Horario: L-J horario de oficina (Flexible) \/ V jornada intensiva.\ud83c\udf89\u00bfPor qu\u00e9 Capitole?Somos geniales, pero contigo lo seremos m\u00e1s \ud83d\ude0a Para ello tendr\u00e1s: Seguro m\u00e9dico Privado, pagado \u00edntegramente por Capitole \ud83e\ude7aPresupuesto de 1200\u20ac en formaci\u00f3n individual para que lo utilices en lo que t\u00fa quieras (eventos tecnol\u00f3gicos, libros, formaciones, certificaciones etc.) \ud83d\udcdaSeguimiento con tu equipo todos los meses para tener un continuo feedback.Formato de trabajo 100% TELETRABAJO al mes, para una mejor conciliaci\u00f3n.Flexibilidad horaria para ayudarte a conciliar tu vida profesional \/ familiar.Retribuci\u00f3n Flexible (Tickets Restaurante, Tickets Transporte, Guarder\u00eda).Andjoy (Gymforless) \ud83d\udcaaDescuentos en grandes marcas para emplead@s (Club Capitole).\nPara que conozcas a toda la familia: Team Buildings todos los meses, \u00a1no te puedes perder la Pool Party o la cena de Navidad!Comunidades tecnol\u00f3gicas para que compartas tus conocimientos e ideas con los dem\u00e1s equipos. \u00a1\u00a1\u00a1Compartir el conocimiento interno es fundamental!!!Equipo de f\u00fatbol patrocinado por Capitole.\n\u00a1Por \u00faltimo y no menos importante un EQUIPAZO! \u00bfA\u00fan no nos conoces? \u00a1\u00a1Desc\u00fabrenos!! https:\/\/capitole-consulting.com\/Somos Originales, \u00bfsabes que tenemos un videojuego para explicarte nuestros valores?https:\/\/capitole-consulting.com\/game\/Mira lo que opinan de nosotros: https:\/\/www.glassdoor.es\/Opiniones\/Capitole-Consulting-Opiniones-E2060890.htm No dudes en enviarnos tu perfil, \u00a1estamos deseando conocerte!\n\u00bfEncaja con lo que est\u00e1s buscando? \u00danete a la familia #CAPITOLE, \u00a1Te esperamos!"}
{"job_title":"Data Engineer - Settore MediaIT&Telco","company_name":"Kineton","location":"Italy (Remote)","job_link":"\/jobs\/view\/3767371649\/?eBP=CwEAAAGMPHUb1AoXEgRHzx3UG5FpSjsXNFtB7pZKLY555vQ4ipGrGeIkbaKu6OqFucboEzrVImHPcw5JFCdNp39rDsTJ63QWpwQMXr1u_fgOJ2_lWkwkgKhMGGdyMj2qcppt9lrLL3I1LDzfJ3XBKaXK-WKhqgzmSK2an_LnDzVboh-yW9LwWqGVghej3BbdTfncZyeP2PDz0eLp_nk_2XpgiqQ0C9Pm0q_C87j54x2K7U_jAo8GBaqFTE8njvS47wXOLAv_O4nOAFSezyD4bCZcyf0fCANqODOnXpQVNt9Kq__m9VtyRJS9sqAduA88bdd5_JVWwXnCPay-jOvWl8O3VKLKe-_-cZiXUYMbKsMMW3di2rH5jTiGcvxGTcFfMbs4&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=SWGEfrtXPD8TIVQgolUltA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3767371649","job_description":"About the job\n            \n \nKineton \u00e8 alla ricerca di un \u201cData Engineer\u201d da inserire nel Team Media IT & Telco, sarai coinvolto in attivit\u00e0 di acquisizione, gestione e trasformazione dati nell\u2019ambito Media e Telco e nella progettazione di applicativi Big Data con l\u2019ausilio di servizi cloud.Requisiti fondamentali: laurea magistrale in ingegneria informatica, informatica o studi affini;programmazione orientata ad oggetti e Python;conoscenze in gestione e query su DB SQL e\/o NoSQL;conoscenza dei principali tool per Big Data Processing: Spark, Hive, Hadoop.\nRequisiti ideali: conoscenza delle principali piattaforme cloud: GCP, AWS, MS Azure;piattaforme di stream processing Kafka;conoscenza dei principi di Machine Learning;conoscenza di Scala, Java, C\/C++;\nCosa Offriamo: ticket restaurant;lezioni di inglese con madrelingua;inserimento in un contesto inclusivo, collaborativo e premiante.\nKineton \u2013 #High-Tech Humanity"}
{"job_title":"Analytics Engineer, Finanace & Fintech","company_name":"Wolt","location":"Berlin, Berlin, Germany (Remote)","job_link":"\/jobs\/view\/3779714649\/?eBP=CwEAAAGMPHUb1JTopTFwpvQpPjVIAy_yD0W-ISYTv4tsscbRXz6mIgYY2Jd5tI-0HY2tWj3fDmcao9wRd-pWhBlWjHWfL8KaTcR9kEEWRkZSgQeo1N0sLqPW3zeO3CHbTfAfgsqDShifzW3bI2nvB4ssfIa0Sk7f47U01b3HOSCCeJNpIQv1RtzDFZGazyZNLmI-kUoRqzqAt6_9srlaAsImNSQv5SSu0POOiUzPltT7riBgwUs73b-kumhf8QHYxFS17M5prp8B0GCcnQ2mljYCiW8swqhs5ipduXLkYOSMEFAdDJnW2J97FFG3sUUIFEFvY_Zqdv_OnyDRvlAtFTJqF8efsQ5C917dNtHLZHxNG88gbu0vzEacRRbfbOH_tfoR&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=yqruxBWfbsqqeW6XC6q9Ng%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3779714649","job_description":"About the job\n            \n \nJob DescriptionYour daily work will include:  Developing reporting as a whole, from understanding the needs of the business to providing easily understandable and actionable data. Working on our centrally maintained data integrations and data pipelines powering our Data Warehouse, our Looker data models and dashboards. You'll get to utilize our modern BI stack as part of your work (Python, Looker, Snowflake, Airflow, AWS, Kafka, Github).\nWhat we offer:  Complex environment with tons of data just waiting to be utilized \u2014 you\u2019ll get hands-on experience in working on various projects, tools, and datasets. You can choose the ways of working - you can work 100% remote, hybrid with occasional visits to our tech hubs in Helsinki, Berlin, Stockholm or onsite. You would get to work in a company culture where we take ownership beyond the obvious, do common things uncommonly well, think big but stay humble, do right by people, treat others kindly and justly, and recognize that if we don\u2019t learn, we won\u2019t stay still but fall behind and keep in mind that Luke was Yoda\u2019s greatest achievement. Read more about how we work.\nOur humble expectationsOur humble expectations  Plenty of experience working as a BI Developer, Analytics Engineer or Data Engineer. Strong hands-on experience with data integrations, data pipelines, data models, and dashboards. Tech skills: Python, SQL, Airflow, Kafka, AWS, and one of the modern BI tools (Tableau, Power BI, Looker or similar). Since you\u2019ll be taking care of our internal stakeholders, we\u2019re looking for someone who truly enjoys interacting with people on a daily basis. The ability to search for information and ask relevant questions from various teams will be crucial.\nFAQ:  I\u2019ve never worked with workflow automation tools like Airflow or Azkaban before. Is this a blocker for me to be an Analytics Engineer?\nYou\u2019ll get to build and maintain data pipelines, which will require you to work with Airflow on a regular basis. Experience with such tools is highly appreciated but not a must as we are willing to teach you. All you need is the desire to learn, and learning will be even easier if you have worked with Python before.  What is the split of dashboard development and data plumbing tasks? \nFocus of this role is on building the basis for reporting needs, hence majority of the tasks will be related to creating datasets, wrangling data and implementing metrics. At the same time, there will be opportunities to create dashboards in order to serve the needs of stakeholders.  Will I work with raw data or participate in data collection?\nNext StepsOur offering to you Lots of room to build the direction of analytics at Wolt. Our Product and Operations organizations will be growing too, meaning that you have the chance to build the team around you and shape the way the organization works with data and analytics. You can choose the location from our tech hubs Helsinki, Berlin or Stockholm. You have the chance to decide the ways of working - a hybrid, at the office, or remote within the locations above. \ud83d\udc99 Read more about our remote setup. In addition to our country-specific benefits, our compensation package includes a monthly salary based on your expertise and equity. The latter makes it exceptionally easy to be excited about our company growing and doing well, as you'll own a piece of the pie. \ud83d\ude80You would get to work in a company culture where we take ownership beyond the obvious, do common things uncommonly well, we think big but stay humble, do right by people, we treat others kindly and justly, recognise that if we don\u2019t learn, we won\u2019t stay still but fall behind and keep in mind that Luke was Yoda\u2019s greatest achievement. Read more about how we work. \ud83e\udd29 \nNext stepsThe position will be filled as soon as we find the right person, so make sure to apply as soon as you realise you really, really want to join us!If you want to check up on your application or have any further questions about the position you can turn to Group Talent Acquisition Partner \/ Analytics, Michal Szafraniec at michal.szafraniec@wolt.comAbout WoltWolt is a technology company that makes it incredibly easy to discover and get the best restaurants, grocery stores and other local shops delivered to your home or office. Wolt is not just a delivery app \u2013 we\u2019re a technology company building a commerce platform to seamlessly connect our millions of customers with thousands of merchant and courier partners, in real-time across 23 countries and 250+ cities. Our apps (iOS and Android) have the industry\u2019s highest ratings, largely thanks to our customer-first-mindset, which shows in how we build products and run operations. In June 2022 we officially joined forces with DoorDash. Combined, we have a presence in 27 countries, 23 of which operate with the Wolt brand and app. Wolt and DoorDash continue largely independently, with Wolt\u2019s name, brand, product, technology and team.Our Commitment to Diversity, Equity & InclusionWe want to have all sorts of people in our team \u2013 people like you and me, and people different from you and me. To be able to work with diverse teammates \u2013 when it comes to gender, age, ethnicity, life background, sexual orientation, political views, religion, or any other personal trait \u2013 we consciously aim to offer equal opportunity for everyone to work with us. This is because we believe diverse teams make the most thought-through decisions and build things in the most inclusive way.Join us today to build Wolt together!The position will be filled as soon as we find the right person, so make sure to apply as soon as you realize you really, really want to join us!The compensation will be a negotiable combination of monthly pay and DoorDash RSUs. The latter makes it exceptionally easy to be excited about our company growing and doing well, as you\u2019ll own a piece of the pie.For any further questions about the position, you can turn to Product+ Talent Acquisition Partner - Michal SzafraniecAbout WoltWolt is a technology company that makes it incredibly easy to discover and get the best restaurants, grocery stores and other local shops delivered to your home or office. Wolt is not just a delivery app \u2013 we\u2019re a technology company building a commerce platform to seamlessly connect our millions of customers with thousands of merchant and courier partners, in real-time across 23 countries and 250+ cities. Our apps (iOS and Android) have the industry\u2019s highest ratings, largely thanks to our customer-first-mindset, which shows in how we build products and run operations. In June 2022 we officially joined forces with DoorDash. Combined, we have a presence in 27 countries, 23 of which operate with the Wolt brand and app. Wolt and DoorDash continue largely independently, with Wolt\u2019s name, brand, product, technology and team.Working in Product Development at WoltAt Wolt, we\u2019re about getting things done. You\u2019ll probably enjoy it here if you like taking ownership, developing yourself and being around friendly, humble and ambitious people.The behind the scenes of Wolt is run by an awesome bunch of over 400+ planners, builders, designers and data crunchers. We call ourselves Product+, as we\u2019re the very core of Wolt\u2019s products, tools and platforms. To build our products, we work in over 40 cross-functional, independent and autonomous teams. Teams are made up of a mix of talented individuals: engineers, designers, data scientists, analysts, and product leads. Each team takes ownership for solving customer problems in the best possible way.Our Commitment to Diversity, Equity & InclusionWe want to have all sorts of people in our team \u2013 people like you and me, and people different from you and me. To be able to work with diverse teammates \u2013 when it comes to gender, age, ethnicity, life background, sexual orientation, political views, religion, or any other personal trait \u2013 we consciously aim to offer equal opportunity for everyone to work with us. This is because we believe diverse teams make the most thought-through decisions and build things in the most inclusive way.Join us today to build Wolt together!"}
{"job_title":"Big Data Engineer","company_name":"SII Romania","location":"Bucharest, Romania (Remote)","job_link":"\/jobs\/view\/3772517377\/?eBP=CwEAAAGMPHUb1PKxH9MMyychXchwxpc2N0p032HLgMAupIRY8ojVq05A5gd4suleM2CftxFEpzZIMnMUsbM7D1UgsNv3FHfVPxa1UxDM0jlkZmsoKOt8-o3a3BARJWhO9iE_xbm_Zc35FpPo6bh49xXIYgz0ZKQ-XPd-0lHq8x8c1tmJaoya_rdxBWtqcy4lzMd20z3GJF0ALd1rlVqANBHfNRYqMqu81K2LwttFURJAYUVgi5bK48Zekh7E2WWMu69XXjfFcDBplg1z7_9k-ex2z5UEpwl9l0YtVXnDUksYKgnr86ZAQI5XUaXndFIeyzIhiY7QG4pcXa3E2UhXRzT0XAo2xX-6uYIkLkmu06U3itASIHutXXRJC_tNaKU0SA&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=6NNo7zGwkFZX6fmWnaONVA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3772517377","job_description":"About the job\n            \n \nWho we are:Open-minded intellectuals who embrace emerging technologies on our mission to create innovative Software Engineering Solutions that will impact millions of users around the world.What you must have: 5+ years of experience in data engineering, ETL design and implementation.Spark and Scala are mandatory.Solid experience with batch processing.Experience in data analysis, profiling, integration and reporting.Good knowledge about SQL and Scala.Experience with Apache Spark, Kafka, Flink and HDFS.\nWhat you will do: Designing and developing ETL solutions to process big amount of medical data.Ensuring high quality by creating comprehensive and automated tests.Continuously improving our data platform and reducing technical debt.Supporting introduction of new tools and migration to Azure cloud.\nHow to stand out from the crowd: Extensive knowledge about database design and modeling.Demonstrate experience with Databricks and Azure cloud.Fluency in Java or Python.Analytical and troubleshooting skills.\nWhat's in it for you: Extended compensation and benefits package;Continuous learning opportunities to enhance your professional and soft skills;A great working environment with people who put their heart, mind, and soul into everything they do and understand the importance of team spirit.\nWe really welcome open-minded and committed people: Eager to take on new challenges and learn new things;Who put their heart, mind, and soul into everything they do;Who enjoy sharing knowledge and understand the importance of team spirit."}
{"job_title":"Senior Data Engineer","company_name":"Brainly","location":"Poland (Remote)","job_link":"\/jobs\/view\/3767474301\/?eBP=CwEAAAGMPHUb1FpWt2wNqxh9ZU820kpvoDq7qcPcOJUWIZuLJYaLfc3gMS6axHQBtOGyT82SPaee7hirmPxfPMFWrBrIEbta9Bi66QthDlCM0v_oaSys-pBEIQH75jYbAQAuATETjP2jsjzPMLcMpm4IMBSpHYy6K96ZR8NXkLkwxo-ZwIza8uGpzSvlo2FikTQ3Pgjtlshxd8zzJ8Rp0VsGanLpkenbFMRTZg3PKJsQLcDykxv1jndfcyAIqH9tLG8hPHZifOEN-1bXORhf6JFo_XZaK8u1LvHezLegBFMwkJr4FHWYGMNIeX25W3jQFZYDD2Cj0-w-XiMckrJlRZp0NXWXa2ZWoIrINmOIhfYJRdQMFvHICJWrp1RgI-AFnVjT&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=Qe1NLEbmHtvHvknDs8Uyjw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3767474301","job_description":"About the job\n            \n \nNOTICE: ONLINE RECRUITMENT PROCESSSALARY: 20 000 - 28 000 PLN gross\/monthlyThere are more than 300 million reasons to join Brainly \u2014 one for every student you\u2019ll help go from questioning to understanding. Team up with us as we build and continue improving one of the most popular ed-tech products on the planet. In a world of questions and uncertainty, you can be part of the answer as we shape the future of learning and change lives, one student at a time. If this excites you, you know what to do next.Let\u2019s get to know each other. And get ready to make a difference!ROLE OVERVIEW We are looking for an experienced, highly motivated Data Engineer to join our Data Engineering Infra Team and help us build data infrastructure that will enable scaling and improvement of Brainly\u2019s data ecosystem.You will be one of the Data Engineering Infra team members - advocates and champions of the best practices, standards, conventions, and tooling that the Data Engineers in Brainly are using in their daily work. You will work mainly with Snowflake and AWS technologies, playing a crucial role in the creation of our new Data Platform.Your areas of expertise will help us mostly in these areas: Developing efficient data ingestion and transformation from multiple sourcesBuilding and enhancing data pipelinesMigration of our legacy system to the new Data Platform\nAre you a goal-driven team player? Do you like tackling new challenges using leading-edge industry tools? Can you adapt to rapidly changing conditions while learning and bettering yourself? Are you a detail-oriented expert who loves focusing on quality? If you answered yes to these questions, you might just be the perfect candidate for this role!WHAT YOU'LL DO Building best practices, standards, conventions, and selecting tooling for the Data Engineering team in BrainlySupporting strategic initiatives through identification of opportunities and implementing solutionsSolving complex challenges such as performance, scalability, and securityDesign, implementation and maintenance of end-to-end data flows for various product teams within BrainlyUnderstand business context and translate stakeholder needs into data pipelines and dashboard requirementsWork cross-functionally with analysts and various engineering and data science teams to identify and execute new opportunitiesConducting code reviews, contributing high-quality documentation\nWHAT MAKES YOU THE PERFECT CANDIDATE 4+ years experience developing and maintaining data processing workflows and applications using one of few solutions like Snowflake, AWS Glue, Apache Spark, EMR, or similarStrong knowledge of database systems, both relational and NoSQLFamiliarity with data warehousing solutions and conceptsProficiency in programming languages (Python preferred)Strong SQL skills for data manipulation and queryingExperience in working on streaming and batch processingDesigning and implementation of ETL, ELTSolid understanding of object-oriented and functional programmingSolid understanding of concepts like ELT, ETL, streaming, batch processingAbility to learn quickly and understanding technical and business requirements and be able to translate into technical design and implementationHigh level of self-organization and ability to make your own decisionsExcellent problem-solving skills and attention to detailsFluency in English (B2\/C1 level) \nWHAT WILL BLOW OUR MINDS Experience with Terraform, Github and AWS EcosystemExperience with Snowflake, AWS Glue, AWS Kinesis, AWS RedshiftFamiliarity with DataOps conceptsMS degree in Computer Science, a similar technical field of study, or have equivalent practical experienceYou are passionate about education\nWHAT YOU GET BY JOINING BRAINLY We want to see you grow along with us \u2013 you will have 800$ per year for personal development, extra time for attending conferences and workshops, and unlimited access to an online learning platform (courses from Coursera, Udacity, Udemy, Harvard ManageMentor, Busuu, and many others!)Health is important, which is why at Brainly, we fully cover private health & dental care packages for you and your family and provide you with a sport card (Multisport Plus)You will also get an access to online individual psychological consultations with professionals in English, Polish & Ukrainian via the Mental Health HelplineYour personal concierge AskHenry will support you in your daily duties, eg. planning your dream vacationYou can join internal communities and contribute to charity, diversity and inclusion initiatives, take part in great internal events or represent Brainly at conferences or meet-upsWe also provide stock options\nWHAT IS BRAINLYBrainly is a leading global learning platform with the most extensive Knowledge Base for all school subjects and grades. Hundreds of millions of students, parents and educators rely on Brainly as the proven platform to accelerate understanding and learning. Based in Krak\u00f3w, Poland, with U.S. headquarters in New York City, Brainly apps and websites are visited by users from over 35 countries. We are backed by Prosus, Point Nine Capital, General Catalyst, Runa Capital, Learn Capital and Kulczyk Investments.Learn more about Brainly at www.brainly.comBy sending us your application you agree that Brainly sp. z o.o. will process your personal data to participate in this recruitment process. If you want to know more about how Brainly processes your personal data please click here."}
{"job_title":"Data Engineer","company_name":"Strattmont","location":"Amsterdam, North Holland, Netherlands (Remote)","job_link":"\/jobs\/view\/3756663597\/?eBP=JOB_SEARCH_ORGANIC&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=8RwrcHCS2E%2BT3L%2BkV90aUQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3756663597","job_description":"About the job\n            \n \nAbout UsWe are not just another tech company; we are a hive of Python specialists committed to delivering excellence for our private governmental clients. With us, you're not just another cog in the machine; you're a vital part of our ecosystem. We take pride in nurturing local talent and contributing to their career trajectory, all while fostering a collegial environment.Why Should You Join Us?  Flat organizational structure without corporate bureaucracyAmple room for self-growth and career development5 days for professional education with a \u20ac5000 budget4 hackathon days, totaling 9 days focused on your developmentEmphasis on work-life balance, team engagement, and social activitiesBe a key player in determining the company's direction\nWhat You Will Do Pipeline Development: Design, develop, and maintain large-scale data pipelines, using Python, Kafka, and Spark.Data Platforms: Work with cutting-edge data platforms like Databricks, Azure Data Factory, and Glue.Quality Assurance: Implement rigorous testing protocols to ensure data accuracy and integrity.Automation: Manage CI\/CD pipelines to deploy data solutions efficiently.Cloud Management: Maintain and optimize cloud-based solutions in Azure, AWS, or Google Cloud.\nSkills And Qualifications Experience: 3+ years of hands-on experience.Language: Fluent in Dutch (B2 level).Technical Skills: Expertise in big data environments, Kafka, Spark, testing methodologies, and CI\/CD practices.Cloud Savvy: Hands-on experience in cloud operations (Azure, AWS, Google Cloud).\nBenefits Salary Range: 100% Based on experience.Profit Sharing: Bonus potential up to 25% of profits of the Company.Work-life Balance: 26 holidays and an 8% holiday allowance.Future Security: Pension scheme with a 66% contribution from us and a 33% contribution from you.Additional Perks: \u20ac700 travel allowance, or lease a car up to \u20ac900, and allowances for Internet (\u20ac30), hobbies (\u20ac30), and phone subscription (\u20ac50) etc.\nTo ApplyIf you are passionate about working in a company that values your skills, experiences, and contributions, then we are excited to hear from you. Leap and join our hive of Python experts by applying now!Skills: data bricks,googlecloud,python,testing methodologies,aws,kafka,ci\/cd,ci\/cd practices,spark,azure"}
{"job_title":"Analytics Engineer 100x100 REMOTO","company_name":"PrimeIT Espa\u00f1a","location":"Spain (Remote)","job_link":"\/jobs\/view\/3770422163\/?eBP=CwEAAAGMPHUb1fOyy8GDbvVikkHOGqV-PsC1p0hwCRuM8E8VSO1owrAx9ut8DHztnK30n6fgiaIk6PSHH1OzCXJgnngLRBZdi6fiKRD9PhuUTph92T6YYs7n7TwgpFyaLUxwGFP2_b2jIoHtbEnbi7nWiXBPWktFWcylLGKdkkBurYPsjH9gj7qXZR7kXM5DUGx2hldajySYbVFYMv36EPP2ew_0DBj1m3_YGmMm2HIbQVSaFN9ioys87Y8e_CcTQ_YKWdrOVLCr1Oi3170k0tmdD6wZ8qhhFEAkzcuB0xCFL5gL3UiLVMmFxDaGGarGsyoxB9dl94QsU9MnW6K3lyz_4ebbk9RuOAa5H9yQllNFZCgx-VPo9HEl7iVgW2pqZw&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=ranAkiH%2FMAlsO03mcFrccg%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3770422163","job_description":"About the job\n            \n \n\u00bfEst\u00e1s preparado\/a para un cambio y explotar tus habilidades como nunca? \ud83d\udc49\ud83c\udffc Sigue leyendo porque tenemos lo que buscas\u2026\ud83d\udef8 \u00bfQui\u00e9nes somos? \ud83d\udef8Somos una empresa internacional con m\u00e1s de 16 a\u00f1os de experiencia en consultor\u00eda e ingenier\u00eda inform\u00e1tica.Con m\u00e1s de 2.300 Primers operando en 4 sectores principales en todo el mundo: IT, Telecomunicaciones, Energ\u00eda e Infraestructuras.Nos puedes encontrar en m\u00e1s de 50 ciudades en todo el mundo:ESPA\u00d1A | PORTUGAL | FRANCIA | REINO UNIDO | ITALIA | SUIZA | POLONIA | BRASIL\ud83d\udd75\ud83c\udffd\u200d \u00bfQu\u00e9 buscamos? \ud83d\udd75\ud83c\udffd\u200dQueremos ampliar nuestro equipo con un T\u00e9cnico BI en un proyecto 100x100 remoto: Al menos 3 a\u00f1os de experiencia en definici\u00f3n e implementaci\u00f3n de soluciones BI, con herramientas tipo Power BI, MicroStrategy o IBM Cognos. Experiencia s\u00f3lida en ingesta y transformaci\u00f3n de datos con Azure Datafactory. Conocimientos en lenguaje Transact-SQL. \n\u00a1\u00a1Y lo m\u00e1s importante de todo que realmente est\u00e9s motivado para un cambio!!\ud83d\ude80 \u00bfQu\u00e9 ofrecemos? \ud83d\ude80Podemos asegurarte que contamos con el mejor equipo de todo el sector. Desde el proceso de selecci\u00f3n, tu incorporaci\u00f3n y hasta nuestro desarrollo profesional te ofrecemosun acompa\u00f1amiento y un seguimiento personalizado en todo momento. Y a todo esto s\u00famale transparencia total en todos los pasos. Pinta bien, \u00bfverdad?Estamos seguros de que ya sabes qu\u00e9 es lo que muchas empresas te ofrecen y como nosotros estamos a la altura:\u00b7 Vas a contar con un plan de carrera, crecimiento, proyecci\u00f3n y desarrollo profesional personalizado\u00b7 Tendr\u00e1s acceso a formaci\u00f3n continua para que puedas estar al d\u00eda.\u00b7 Podr\u00e1s participar en proyectos nacionales e internacionales con opci\u00f3n a movilidad.\u00b7 No todo va a ser trabajar, por eso disfrutar de la tarjeta restaurante y seguro m\u00e9dico nos parece esencial.\u00a1\u00a1\u00a1Teambuildings, afterworks y muchas m\u00e1s sorpresas!!!"}
{"job_title":"QA Manual\/Automation Engineer (with Python)","company_name":"Luxoft","location":"Poland (Remote)","job_link":"\/jobs\/view\/3772394089\/?eBP=CwEAAAGMPHUb1Y4NxWcN-or6mryEznYxET_4Ar3AVo4zWptxps0xLoRkXCueSuaWpGBP9qnrxWJzH6ewe_AfbJGazXh1nEuTF5S8WH60TLVmaFn57tVqxeuFriTMM97FHtOQCsbbFxQvg_AwNMBPLtbW4xkL6RhG1pe9TvANCojn__RXpNWO08zO9OSfntlLrWKJzWLjJVhwPi7ErbmOBb4dAzvk5P9jOSJ-tTfiTVwvknajFAkVDRGYV8Y9m-h6YGdidFNV1D8YL93UJSsydLTnhd34hcMlEGXgWCPX95asz0RJTFTEjir_UoxJuR2uJQy_dDV1h_TUvNP8B2XAv348bk2yo8biTRsDzl-I8bKthMfdPNaiCetog2oOAfg3zado&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=CSgPCJaMLO8L99FmWnIIvw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3772394089","job_description":"About the job\n            \n \nProject DescriptionDevelopment of monitoring and diagnostics system. It fulfils both local and remote data access and analytics requirement, as well as local and remote troubleshooting purpose.ResponsibilitiesWork with the Product Owner to define test cases that prove the acceptance criteria for incoming user stories for the Web apps.\u2022 Create functional and non-functional UI\u2022 Communicate clearly in English with the development engineers regarding test expectations and defects.\u2022 Use defect tracking tools to log and clearly describe defects and conditions for reproducing them.\u2022 Contribute to design and estimation conversations.\u2022 Contribute to the quality of the solutions by identifying issues in architecture, design and implementation\u2022 Contribute to our Agile development process as a scrum team member from requirements analysis and design up through final feature acceptance and deploymentSkillsMust have\u2022 At least 4 years of creating and executing test cases\u2022 Working knowledge of functional and non-functional software testing, the software test life cycle, and various test design methodologies (function, performance, accessibility, scenario etc.).\u2022 Test cases creation and execution based on Customer and Software requirements\u2022 Python 3+ years of experience\u2022 Experience of setting up testing framework from scratch\u2022 Experience in testing of Backend (API) and data quality\u2022 Knowledge of API testing tooling like Postman, Swagger\u2022 DBs basics and SQL database usage expert\u2022 Familiar with IoT OR Time series data handing knowledge\u2022 Linux knowledge\u2022 Experience with AWS services\u2022 CI\/CD (Jenkins)\u2022 Experience with Performance testing\u2022 Good soft skills in communication.\u2022 Exemplary verbal and written communication skills (English).\u2022 Creative problem-solver capable of creating and reproducing interesting software bugs.Nice to have- Experience in cooperation with QA automation team- AWS Green Grass- Experience or knowledge of Industrial protocols (Modbus) LanguagesEnglish: B2 Upper Intermediate"}
{"job_title":"Junior Data Backend Engineer (Clickstream Analytics) (Remote - Ireland)","company_name":"Yelp","location":"Galway, County Galway, Ireland (Remote)","job_link":"\/jobs\/view\/3778941999\/?eBP=CwEAAAGMPHUb1QZRDRc-EIIce1cbMlFGz99OiLdS2FjUBiO7I_ERebDCroAqghBmqsv4CW6nvY1lqpJvaBsMF0BVVhcNrV0zFcKeLtB9svXk8dqgzMdPu3K2nrD4StqItArSPVd-I_Zjg4a5l2mdneaNHBBTQJYLyO0gPP2bDiZreDJ6n8yMJBY1MIk-C3vZ0UvDMKIngx2_aca0WtX0aLnc0eI7V-3-1Z2D-eryf7yQihUuJ2bJn3405as5V7DnK_mLDhrl-tQMRg-4PF5em2GYOaDT1B1KLVdd_ZKGa68FFMfZ-DYZUXoCOhFqf25wlH0gN-SVhwvuhxX_aHeiWA5Hp7SuGgmZFJCpR7jj5ajBhgRl6YaUrjGFYyQCGbtXYpY0&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=Tk6%2FhijY%2FbdfucpZzAAAOQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3778941999","job_description":"About the job\n            \n \nSummaryInterested in exploring data and finding innovative ways to collect it, curate it, and make it easily accessible for others to use? How about doing that at an enormous scale? Yelp\u2019s datasets contain billions of interactions between users and local businesses around the globe. If working with our vast amount of data sounds exciting, come and join us!The Clickstream Analytics team is responsible for creating, managing, governing, and monitoring some key user journey metrics to support our product teams and also support offline analysis that aids in making long term company decisions. We also build tools that help us to better understand our data quality, and we strive to uncover data issues before they impact our consumers.As a Data Backend Engineer on this team, you will be responsible for building elegant and scalable data products that serve critical, up-to-date, structured information to support different types of analytics within Yelp. As a core contributor to our growing data modeling and data warehousing engineering efforts, you will help design and own mission-critical data flow pipelines and datastores to enable decisions including effective A\/B testing and company investments.Yelp engineering culture is driven by our values: we\u2019re a cooperative team that values individual authenticity and encourages creative solutions to problems. All new engineers deploy working code their first week, and we strive to broaden individual impact with support from managers, mentors, and teams. At the end of the day, we\u2019re all about helping our users, growing as engineers, and having fun in a collaborative environment.This opportunity requires you to be located in the Republic of Ireland. We\u2019d love to have you apply, even if you don\u2019t feel you meet every single requirement in this posting. At Yelp, we\u2019re looking for great people, not just those who simply check off all the boxes.What You'll Do Build systems that can effectively store and crunch terabytes of data.Design and develop data models for efficient data storage, retrieval, and reporting.Create and maintain conceptual, logical, and physical data models using industry-standard modeling tools.Collaborate with cross-functional teams, including engineers, data analysts, business analysts, and data scientists, to understand data requirements and translate them into effective data models.Participate in data integration efforts, including ETL processes and data migration.Stay up-to-date with industry best practices, emerging technologies, and trends related to data warehousing.Support on-call rotations as needed to operate the team.\nWhat It Takes To Succeed Understanding of high performing and scalable data systems.Experience in building and orchestrating ETL pipelines.Experience with Data Lake or Data Warehouse landscape.A hunger for tracking down root causes and fixing them in systematic ways.Ability to communicate effectively to technical and non-technical cohorts alike.Exposure to some of the following technologies: Python, AWS Redshift, AWS Athena \/ Apache Presto, Big Data technologies (e.g S3, Hadoop, Hive, Spark, Flink, Kafka etc), DBT.\nWhat You'll Get Full responsibility for projects from day one, a collaborative team, and a dynamic work environment.Competitive salary, a pension scheme, and an optional employee stock purchase plan.25 days paid holiday (rising to 29 with service), plus one floating holiday.\u20ac150 monthly reimbursement to help cover remote working expenses.\u20ac95 caregiver reimbursement to support dependent care for families.Private health insurance, including dental and vision.Flexible working hours and meeting-free Wednesdays.Regular 3-day Hackathons, bi-weekly learning groups, and productivity spending to support and encourage your career growth. Opportunities to participate in digital events and conferences.\u20ac95 per month to use toward qualifying wellness expenses. Quarterly team offsites.\nClosingYelp values diversity. We\u2019re proud to be an equal opportunity employer and consider qualified applicants without regard to race, color, religion, sex, national origin, ancestry, age, genetic information, sexual orientation, gender identity, marital or family status, veteran status, medical condition, disability, or any other protected status.Note: Yelp does not accept agency resumes. Please do not forward resumes to any recruiting alias or employee. Yelp is not responsible for any fees related to unsolicited resumes.Recruiting and Applicant Privacy Notice"}
{"job_title":"Software Engineer","company_name":"Foxtek","location":"Netherlands (Remote)","job_link":"\/jobs\/view\/3774173467\/?eBP=CwEAAAGMPHUb1Tlm50kx39EnGkhedN-djcVPVgaxyNJ6EnNODXdx3YL-GgaRZ0WNW8stkJxeB-vYcgoCo9urcVXCHBAcPpBBXKmY2wQxRBBOMoXnsSoSDwLHjtqEpp3MJv4ftGbD9_fpd8mmXhHKFBGM0hK8fNIee6ymvmiToZMFvUWJ4dA08f9VMxhLfS904Zx-szZFhWm05_hva4T36cQq6fLcnuhho5pql3ahXFuCChhQ4ApXDgfmbeJ0x8sqxD9k41ljcSOqFBx44LpwCOeZ1aEiD7HkcQWpK_emUTb3W5-_SvgoCnr32kDt-lpxtxZEkyJSi11mgsYMz-0eMNpWK6waZcIM1sWHLpjMXPnjfbHTmCbVKnng9HyRowhhcw&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=yuJJ3g9iqSdWwQnP4MUn1w%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3774173467","job_description":"About the job\n            \n \nYOUR code engineering a better future \ud83d\udd1cThis Dutch start-up has a positive mission set to transform the world on an economic & and environmental level. Having received new funding last year as well as support from the European Union, they're expanding their team to keep up with the growing demand for their tech-for-good, blockchain product.You'd work on greenfield projects in a cross-functional team using Python.You'd receive fantastic support for personal development - it's key to their core values and the company actively builds a personal progression plan with bi-annual check-ins and targets.Why work for this company?\ud83d\udcc8 Generous equity package to grow with the company\ud83c\udfe1 Office attendance optional - work entirely remotely within the Netherlands if preferred\ud83e\udd1d Strong advocates of cultural diversity & international teams\ud83d\udcaa Tech-for-good company with solid funding & product market fitEssential Experience:\ud83d\udc49 Senior level w\/ Python\ud83d\udc49 Exp building APIs or integrating into other products\ud83d\udc49 Experience working in small company\/start-up\ud83d\udc49 FastAPIBeneficial Experience:\ud83d\udc4c Event Driven Architecture exp\ud83d\udccd Location \u2013 work from anywhere in the Netherlands\ud83d\udcb0 Salary \u2013 Up to 70-80K (dependent on experience)\ud83d\udcc6 Start Date \u2013 FlexibleSound good? Then send me your latest CV to explore this opportunity further!Alternatively, if you are not interested in this role but you know a friend or a colleague who is, we will reward you with \u20ac1,000 if they are placed \ud83d\udcb5Remember to follow our LinkedIn page to keep updated on the latest Full Stack Roles in the Netherlands \ud83d\udc47https:\/\/www.linkedin.com\/company\/foxtek\/ \ud83e\udd8aKeywords: Django, FastAPI, React, React.js, Fullstack, Full-Stack, Software engineering, Scale-Up"}
{"job_title":"Junior\/Professional ETL Developer","company_name":"ASTEK Polska","location":"Poland (Remote)","job_link":"\/jobs\/view\/3771901303\/?eBP=CwEAAAGMPHUb1YRgBZYfTE9ABjMN6Vs_27zfeJf-XMJtlPOmSiaj5HV8ChKtkqlF--QGkn7sCw4sV9aDwyqO6TBw0uUaDZDYPv723zzkR78iRo4_vuT37TDg-6YSdR50q-WASrP39InitFYZiGYy4yhZHReNeWH05SJw0I5KtiBFDmOrw0ZpNrIwBCYMo1nZdE076GvV77xXaN7Q50Z5e5D9N7gnQ6I9o3zbZnAfi-HPtUnUpFAuY2XLW60dic7zDl16GJBvC3hiRlw-xPLK6NonIKJq92alBZAJ1sB6eH4EDatQjhBkOyEQ0LPQTqRKiKCNcP_b28MRZNO6pM7wkQZL94MiUOxPx5Z7D5w1gmtQj9HSd5M8brZigZNHgqWV5SBd&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=0NKHHeYtkxZWqE1%2BU0pP%2BA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3771901303","job_description":"About the job\n            \n \nASTEK Polska jest oddzia\u0142em mi\u0119dzynarodowej Grupy ASTEK, specjalizuj\u0105cej si\u0119 w realizacji projekt\u00f3w IT oraz outsourcingu in\u017cynier\u00f3w i specjalist\u00f3w IT.Poszukujemy osoby na stanowisko Junior\/Professional ETL Developer.Lokalizacja: Wroc\u0142aw (hybrydowy model pracy)Stawka: 600-720z\u0142 netto + VAT\/dzie\u0144 (B2B)Obowi\u0105zki:Jako specjalista uzyskasz mo\u017cliwo\u015b\u0107 zdobycia wiedzy i do\u015bwiadczenia w budowie i rozwoju nowoczesnych system\u00f3w automatycznej oceny kredytowej. W szczeg\u00f3lno\u015bci b\u0119dziesz uczestniczy\u0107 w pracach zwi\u0105zanych z: definiowaniem wymaga\u0144, wsp\u00f3\u0142tworzeniem analizy biznesowej i systemowej dla proces\u00f3w kredytowych,implementacj\u0105 algorytm\u00f3w i regu\u0142 decyzyjnych w silniku decyzyjnym,przygotowaniem test\u00f3w jednostkowych i automatycznych,utrzymaniem zaimplementowanych regu\u0142 na produkcji,zarz\u0105dzanie aspektami danych w architekturze bazy danych,monitorowanie zasile\u0144 baz danych.\nWymagania:  Znasz dowolny j\u0119zyk programowania, a samo programowanie nie sprawia Ci trudno\u015bciWykazujesz ch\u0119\u0107 do nauki nowych technologiiZnasz narz\u0119dzie ETL i SQLPosiadasz do\u015bwiadczenie w pracy z modelami danych \/ hurtowni\u0105 danychMasz wykszta\u0142cenie informatyczne lub pokrewne: automatyka, matematykaMasz umiej\u0119tno\u015b\u0107 analitycznego my\u015blenia i szybkiego wyci\u0105gania wniosk\u00f3wWykazujesz ch\u0119\u0107 kreatywnego i aktywnego poszukiwania rozwi\u0105za\u0144 rozwijaj\u0105cych systemy zarz\u0105dzania ryzykiem w bankuJeste\u015b samodzielny w dzia\u0142aniu a ka\u017cdy napotkany problem to tylko kolejne wyzwanie do pokonania.\nMasz pytania?  Napisz do mnie na LinkedIn lub na okapkowska@astek.plZapraszam do aplikowania! AO17663"}
{"job_title":"Senior Data Engineer","company_name":"Acast","location":"Stockholm, Stockholm County, Sweden (Remote)","job_link":"\/jobs\/view\/3699945312\/?eBP=JOB_SEARCH_ORGANIC&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=NjV7HUSoFQeAG%2FNggP36aw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3699945312","job_description":"About the job\n            \n \nSince 2014, Acast has been creating the world\u2019s most valuable podcast marketplace, building the technology which connects podcast creators, advertisers and listeners.Its marketplace spans more than 100,000 podcasts, 2,300 advertisers and 400 million monthly listens. Crucially, those listens are monetized wherever they happen - across any podcasting app or other listening platform.The company operates worldwide and is headquartered in Stockholm, Sweden. Acast is listed on the Nasdaq First North Premier Growth Market (ACAST.ST)About The RoleWe are looking for an experienced and skilled Senior Analytics Engineer that will work on an autonomous, purpose-driven team that develops and maintains ETL pipelines. The role empowers you with freedom for initiative and ownership, spanning across a large spectrum of areas. It starts from consolidating the data warehouse with scalable data pipelines, to implement anomaly detection systems for improving the data quality, to data mining and data science techniques to build insights. We are a remote, and diverse team that follows agile principles and has a DevOps-first culture. We also value a pragmatic mindset and the ability to make trade-offs on what to optimize for and when to ship.Who you are  You have experience in building and optimizing \u2018big data\u2019 data pipelines, architectures and data sets. Experience in Python and Java or Scala You have worked with workflow management tools such as Airflow You have pragmatic mindset and can reason around trade-offs on what to optimise for in your solutions You have product analytics skills and experience in data modelling and you are used to cross-team collaboration It would be also great if you have experience in AWS cloud environment: Glue, Athena, Redshift\nIf you do not have direct experience with some of the tools, no problem! We are happy to develop you in these areas. Success will be measured by the increase in the data products usage, new product development within the team, feasibility, and innovation.Where You\u2019ll Be  Most of our teams are hybrids with some members co-located in offices and some working fully remote. With a remote-first way of working we want you to feel productive regardless of work location! Where in the world? For this role, it can be within the UK or Sweden Working hours? We want to avoid teams distributed over time zones, so this team will operate within the CET time zone for collaboration. This setup allows us for more flexibility and work-life balance.\nAcast is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment regardless of race, gender, sexual orientation, religion, ethnicity, national origin or any of the other wonderful characteristics that make us different.Culture is our number one priority as a business. We believe people come first, and we work every day to enable autonomy, continuous improvement and bring out the best in people. We\u2019re global and have remote teams, so it\u2019s even more important that we strive for an open, inclusive and caring environment where everyone feels visible and welcome. We consider ourselves a modern organization driven by strong values to create the best, most fulfilling and nurturing culture.We very much look forward to finding the next great person to join our cause!"}
{"job_title":"Senior Database Developer - Oracle RevElate","company_name":"Oracle","location":"Romania (Remote)","job_link":"\/jobs\/view\/3779080609\/?eBP=CwEAAAGMPHUb1S55J14xulIgLqDWQgQxOXpoR7VEP6ITS05UJx67msANsyApopGmXQAnClhU4GNlnI57KC9EEgo_to30gMnmC6zDjUjVRgvLLOHaaJG6nJoOD3t6_IjkqF0csGBTAbTWYJ_T1zu8x0N_yTuIeGrNJEmcP6IJSca8SgGbaAzOzLtDhxOZ77ciTBmc0y4wDcnFHccLSRJcOwzsuAGNLHUTmnG78bQSUWBRdxsxufXihI4XI03zrcG4cVYdpHMDBuD-SBPIuDutkLWUxqiZt7cj1ez9sMFczaJjnyXhSFrTbuV6Ihj1Pfe-ccy1JBWnG1Ocf-2yDWwVO6Hai7sMUXe6iApWZtVQuk4MQ8PZb3IKjaYZcvgXQcwA-JL5&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=zO5t8ux6zCuUu7paQIBYrQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3779080609","job_description":"About the job\n            \n \nLooking for a Software Engineer in the area of Database Cloud, to join our Oracle\u2019s Health and AI global team. We are building new healthcare services that operate at high scale in a broadly distributed multi-tenant cloud environment. Our customers run their businesses on our cloud, and our mission is to provide them with best-in-class services which will help reduce the overall healthcare spend.Building off our Cloud momentum, Oracle has formed a new organization - Oracle Health & AI. This team will focus on product development and product strategy for Oracle Health, while building out a complete platform supporting modernized, automated healthcare. This is a net new line of business, constructed with an entrepreneurial spirit that promotes an energetic and creative environment. We are unencumbered and will need your contribution to make it a world class engineering center with the focus on excellence.Why?Oracle Health & AI is a new line of business that aims to leverage our expertise in IaaS and SaaS to transform the health care industry, provide patient-centric care and make the best clinical tools available around the world (https:\/\/www.oracle.com\/industries\/healthcare\/). We are looking for the best and brightest technologists as we build the next generation of Health platform that will change the industry. This is a greenfield effort with an entrepreneurial spirit that promotes energetic and creative environment. We like to move fast and innovate, and we want your help to make it a world class engineering team that makes a large impact.RevElate is building the next generation of health care platform using cloud native solutions to provide superior patient experience. It elevates the clinically driven patient accounting approach by focusing on automation and extensibility while accelerating the Oracle Health platform convergence strategy. We are expanding our talented team so come join us while we embark on this exciting journey.What?We are seeking Senior Software Engineers in database area that share our passion and excitement of operating distributed systems at hyper scale using cloud native best practices. You will have part in the disruption of the health care industry and will help deliver better patient care.As engineer in our team, you\u2019ll be responsible and lead efforts in designing and building database services under OCI to support RevElate's functional, performance, availability and security needs. We believe in ownership and expect you to think long term, mentor, and empower other engineers. Desired Qualifications  4+ years of developing and shipping enterprise distributed and\/or cloud native systemsStrong grasp of database design and distributed systems architectural best practicesExperience with working on RDBMS (Oracle 19c, MySQL, SQL Server), experience with performance tuning, coding PL\/SQL, TSQL.Experience with cloud platforms (OCI, AWS) and cloud-based database services (ADB, MDS\/MySQL, RDS)Experience with containers and container orchestration technologies (Kubernetes, Docker) is a plusExperience with Python scripting is a plusExperience on Linux systems is a plusStrong desire to make an impact and thrive in collaborative and energetic environmentsAbility to effectively communicate technical concepts verbally and through design aspects \nResponsibilities displayed in the job postingThe Database Architecture team is responsible for the design, development and deployment of RevElate's database layer. We're using various RDBMS (Oracle, SQL Server, MySQL), technologies and tools (utPLSQL, Python scripting, Liquibase, Kubernetes & Docker, Oracle Autonomous Database, Oracle GoldenGate). Qualifications displayed in the job postingDuties and tasks are varied and complex needing independent judgment. Fully competent in own area of expertise. May have project lead role and or supervise lower level personnel. BS or MS degree or equivalent experience relevant to functional area. 4 years of software engineering or related experience."}
{"job_title":"Data Analytics Engineer","company_name":"EPAM Systems","location":"Hungary (Remote)","job_link":"\/jobs\/view\/3774396412\/?eBP=CwEAAAGMPHUb1asUUUW7caYInUnmVnHVZGz4InRCPrx9F_XhdUvLobmrYipvYmFf0xujqpsJhkYYhNSpSKk2J05MUbwrX4me9eGZrPLHF6hVwLIrYcw18Nwp1p32TuDa08XuaQWlIVQ7DN8kJrBstecluhSqaiRs12jDsWFTBg1Otpeym26r3-orVYR-gQifqF7MIyXsnXTkIWXK6F5Bwk2ZVpglBBqwEg61bNxTqMBbme17er8DRo7Vo9XwvfBqcj4y_vRAPqsaBzHvGZHaANnrVi0qDVkEOm-D5YE2Z2-3yBjfmX5l10OqWeWkTtlbf5BuKPDiAYZbcnGrqtY21Lz5L5giXXveWpNfEF9t_GiRS-oiR1s8PhckKuK3C1IXRgg5&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=nK7qZ9kqgnFe03Ppc4v9YQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3774396412","job_description":"About the job\n            \n \nDescriptionEPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.No less important is the safety, well-being, and experience of our applicants. Therefore until further notice, all EPAM employment interviews will be conducted remotely. Our recruitment professionals and hiring managers are standing by to ensure a robust and engaging virtual candidate experience. We look forward to speaking with you! For further information please check our web site at www.epam.com.We are looking for a talented Data Analytics Engineers to extend our team of professionals who can help our customers achieving their digital transformation through data in variety of industries. We are passionate about delivering value from data and are searching for people with the same mindset to join our team!Learn more about our Data Practice\u202fhere.What You\u2019ll Do Designing and implementing production-ready data solutions using classic data technologies and tools (BI platforms, Databases, ETL\/ELT technology & tools, etc.) or modern cloud data technologies\/componentsWork with product and engineering teams to understand requirements, evaluate new features and architecture to help drive decisionsMaintain collaborative partnerships with architects and key individuals within other functional groupsPerform detailed analysis of business problems and technical environments and use this in designing high-quality technical solutionsActively participate in code review and testing of solutions to ensure it meets best practice specificationsSupport a high-performance engineering cultureWrite project documentation\nWhat You Have Good knowledge of Data Analytics, Data Visualization concepts. Practical experience with at least one database platform and one BI platform (Internal POC \/ project or external engagement)General experience in developing solutions with Data Analytics & Visualization technologies both: using classic BI tools and modern Cloud Data componentsGood knowledge of Databases (SQL optimization, Relations, Stored Procedures, Transactions, Isolation Levels, etc.)Expected experience working with at least one Relational Database (RDBMS: MS SQL Server, Oracle, MySQL, PostgreSQL)Understanding of storage layer, data formats, batch integrationUnderstanding of Data Platform concepts (Data Lake, Data Warehouse, Delta Lake\/Lakehouse). General understanding of Landing, Staging area. Data CleansingBasic understanding of Data Governance aspects (Data Ownership, Data Privacy, Data Lineage, etc.)Good understanding of Data Security (object\/system level grants, etc.)Proved skills in data solutions troubleshooting, monitoring, support, and bottleneck problem analysisTesting: Component \/ Integration TestingUnderstanding of CI\/CD principles and best practices. Following release processes on a projectMotivated, independent, efficient, and able to work under pressure with setting prioritiesAbility to work in a fast-paced (startup-like) agile development environmentAnalytical approach to problem-solving; excellent interpersonal, and communication skillsExperience in direct customer communications is a plusEnglish proficiency\nWe offer Dynamic, entrepreneurial, high speed, high growth corporate environmentDiverse multicultural, multi-functional, and multilingual work environmentOpportunities for personal and career growth in a progressive industryGlobal scope, international projectsWidespread training and development opportunitiesUnlimited access to LinkedIn learning solutionsCompetitive salary and various benefitsSport and social teams support, recreation area, advanced CSR programs\n Apply"}
{"job_title":"AWS Cloud Engineer","company_name":"Kripson Tech Ltd","location":"Germany (Remote)","job_link":"\/jobs\/view\/3774185040\/?eBP=CwEAAAGMPHUb1Vm6nhz5k4x1GQZcHQ5Y-_a7Vhy_3e0uqxWIlAYoCpsWD-HLMQaP3LemUbe_10w4lPvr4Uf2MSbUTF_zhNX2Qj7Aprlnuoi9xa_niGwz8YDRhTH-4IUTFudN7p5xz22Rzqd8Ptdg-Ml-b9MMcLLcKomircIkNw3gjau7lp9U0SgPNaL-UVHxfsyr55DTWisYF8XW_bh1GCry1WtMtKYXwmpalQXDRmFEQLog1Nc4hygIBKvDHQLrGL8JERsg3cp1CrAhIDIsoMyL6OEkXF5Mml3oxK7mWcGfK9bNG2WTsIEhXpGEq5USHaYFk7TegXW0_L2wkrON4mo4JDlGS-3fZ7uW_Xuw6g8v6Mc3a4-W-Sr4-v8HH0ZKlgK0&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=RfcdP1zmbQysrjGCNMGTSg%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3774185040","job_description":"About the job\n            \n \nRole- CLoud Engineer\/ArchitectLocation-Remote (Germany) Hiring Type- ContractGerman & English Speaking Mandatory AWS Cloud Developer of DevOps CertifiedGerman & English SpeakingBased out of GermanyMinimum 8+ years overall experience in IT industry3+ minimum experience working on AWS2+ year experience on Terraform 1+ year experience application migration"}
{"job_title":"Junior Java Developer","company_name":"Luxoft Romania","location":"Romania (Remote)","job_link":"\/jobs\/view\/3771904757\/?eBP=CwEAAAGMPHUb1QvkBBBoM5RUlghm7ibXmVAMTw1ABm205JAzQac6P0ORJvfTIfu81y9GAogaRyH5XcNX94G-s3mXTeubSRnppuNfqxwxzORccwafCjk5A-FqI2eIqCvhCBl8VmIADoy9WVBAddnJXcf21_XUTkXSMZbhb5ymNWCXlLNkqsur2-w8fFXQ_dzGfea4A5i9GO_33l2-2HIzbrzKnAUCMK3v-kLVoag4Ayn36BD1UsoawOqie8usjXsIBOzoHfW6okysYkXpG1GRh9DuLcGWyx4UrRB0_d2u1oWqLZ8W7XTtFuf6QTM-9oHyu7ehQ1JqXJ5mrFh2n7tm5mIb8EGtCTNJtvC-QvcjN2dvQFVZN_gyx4FqW70VaPbtFg&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=IS8mkmB%2Fm4lwABL0J8HVqw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3771904757","job_description":"About the job\n            \n \nProject Description:The project is a rapidly growing engagement with a solid leader in the FinTech industry developing software solutions for trading, risk management and data processing. Join our Development Center in Luxoft Romania and become a member of our open minded, progressive and professional team. The software development is based on SAFe\/Scrum methodology and uses Continuous Integration\/Continuous Deployment processes supported by the adoption of DevOps, best engineering principles and XP practices like TDD and BDD. You will have a chance to grow your technical and soft skills, grow professionally and build a thorough expertise of the industry of our client. On top of attractive salary and benefits package, Luxoft will invest into your professional training including business domain knowledge, and allow you to grow your professional career.Our client software platform is used by the world's leading investment banks, asset managers, hedge funds, commodity houses and corporations to price, analyze and manage their derivative exposures for foreign exchange, interest rate, equity, commodity, inflation and credit derivatives.How we work: - The development processes are completely Agile. We are implementing SAFe, the most widely used scaling agile framework- You will be deeply involved in controlling the development workflow by defining, planning, building, testing and deploying the new solution functionalities- Once every 10 weeks the new business requirements are provided by the clients and development teams clarify, estimate and plan the work needed for the next period- Our strong focus is on building high quality software by investing in Continuous Integration, Continuous Deployment, multi-tier testing, code quality, Non Functional Requirements etc.- The results of your work will be used by the most important organizations in the Investment Banking industry- Every 4 Sprints you will have the chance to work on completely innovative ideas using any cutting edge technologies or frameworks for a whole Sprint- We are investing constantly in your professional, business domain and personal development by offering career path guidance and access to a wide variety of trainings.- You will be supported by our technical mentors, agile coaches, pair working with your colleagues and will benefit on a friendly atmosphere and a dedicated space for games and relaxationResponsibilities:The candidate will work in development team closely with the Paris and Bucharest consultancy teams to develop new functionality, rapidly solve problems and enhance existing aspects of the application.The main purpose is to develop applications in order to integrate with external financial providers and platforms and to model the functional flows involved in the communication between the Client's solution and these external systems.There might be cases when the candidate might go to Paris to work on-site or for training for 1-2 weeks period.Mandatory Skills Description:- Mandatory Computer Science Faculty \/ Cybernetics \/ Mathematics \/ Informatics graduated- Min 1 Years working hands on experience in Java- Java 8- Dependency Injection\/ Inversion of Control (Spring or JBoss)- Unit and Mock Testing (JUnit, Mockito, Arquillian, Cucumber)- Java Message Service (JMS)- Web Services (JAX-RS, JAX-WS)- Strong understanding of Design and Architectural Patterns- Apache Maven- Continuous Integration tools (Jenkins or similar)- Linux operating system- Stash: GIT Repository Management- Spoken English language is a mustLanguages:\u2022 English: B2 Upper Intermediate"}
{"job_title":"Data Application Developer","company_name":"KCS iT","location":"Portugal (Remote)","job_link":"\/jobs\/view\/3774830087\/?eBP=CwEAAAGMPHUb1QnOfPypoXn9XoUBTkeXk3E0wmFDjXR_jnTAsCpqnKXUnNe1VgBROEpELbF1FJtKUD_jL6gtXH9bXShcvfcSTuYTb_tqLhrw68as0KSH5mQQyRzCiiO6rV72KN5PR6tfKjtiRX3QXt1f5Bn7tlWWFNLA1uu7z-TzsFjAqH4dVb837aUGi2oclp7RoNIlaB7tiEtbA6OcxkqDPOpeRAgZsMCvgfpoqw4pkPc__Pr2aWfSlqYNzr0GF5PMaftcaBjplPsuJTjDIaBRSGk5paa2UL2OK321miocMFusgEsQLKjd40-xEgWywRwA75_WA59Q5DD1O4GcWEZ0WB8t4aRpYXEwmvQwRBGuRDAUNpVF2KYrIYUbv8_1tLAv&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=usdakj65wL9eDrhlUskq8A%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3774830087","job_description":"About the job\n            \n \nWe\u2019re looking for the special, unique and amazing YOU!@ KCS IT, we look for the ones that stands out, for those that always wants to be better and fight for it, and for those who has the same values that we do: dedication, energy, integrity, transparency, flexibility, trust, honesty, hard work, proactivity, team work.At KCS we stand for equality and value diversity. We create a safe, diverse environment where opportunities are equal for everyone! We do not discriminate based on age, ethnicity, sexual orientation, gender, disability or any factor other than merit. All applications with skills for the position are welcome!We are looking for an Amazing: Seniority: more than 3 yearsRequirements: Bachelor's degree in Computer Science, Information Technology, or a related field.Proven experience as an Application Developer with a focus on Databricks, Apache Spark, and SQL.Strong programming skills in languages such as Python, Scala, or Java.In-depth understanding of data processing concepts and distributed computing.Experience with data modeling, ETL processes, and performance tuning in SQL.Excellent problem-solving and analytical skills.Effective communication and collaboration abilities.\nThe amazing you, will have: Already living in PortugalGood level of English \u2013 Fluent\nWhy should you become part of our family? You can develop a career that fits you: your career development is personalized, taking in consideration your needs and goals from a short to long term;Interesting Challenges Ahead: you can work for several clients of different sectors of activityFree training programs: Our training and certification programs in languages, tech, soft skills and business will help you to reach your full potential faster;International projects in Benelux: you can gain international experience in Benelux and balance a new way of living with work;Type of projects (depending on the project you might find one of this types of projects):In hybrid Systems: Is important to balance work with socialization, that\u00b4s why a hybrid system works for us and for youTake care of your well-being: Enjoy our free nutrition, psychologist, general medicine appointments and our yoga and personal training days\u2026 all remote!\n Who are we? Founded in 2008 and based in Lisbon, KCS IT is a consulting company in the field of Information Technology and Services, focused on creating value for our clients through three main areas: Consulting, Outsourcing, Inovation and Training. Our commitment to talent development is unmistakable in the recent opening of the Porto and Azores hubs, which aims to develop technology for the national and international market. Since 2018 we have been elected one of the 10 major companies in the \u201cIndex of Excellence\u201d, an initiative that aims to reward organizations that invest most in the development and satisfaction of their employees."}
{"job_title":"Data Engineer","company_name":"iestro","location":"Deventer, Overijssel, Netherlands (Remote)","job_link":"\/jobs\/view\/3763804531\/?eBP=JOB_SEARCH_ORGANIC&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=%2FuY%2FNkvcI6YOiXLF%2BeM36Q%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3763804531","job_description":"About the job\n            \n \nBuscamos um Data Engineer para EdTech que tem a vis\u00e3o de democratizar o ensino de idiomas no Brasil e no mundo.A miss\u00e3o da equipe de engenharia de dados \u00e9 gerar valor para a experi\u00eancia de ensino e demais equipes atrav\u00e9s de dados, ajudando alunos e professores a alcan\u00e7arem seus objetivos, pessoais e profissionais. Para tal, acreditamos que colabora\u00e7\u00e3o, autonomia, boas pr\u00e1ticas e pragmatismo s\u00e3o elementos fundamentais no processo.Estar neste time significa integrar uma comunidade de pessoas que buscam compartilhar ideias, conhecimentos e solu\u00e7\u00f5es entre times. Todos esses pontos contribuem no desenvolvimento da melhor experi\u00eancia de aprendizado para alunos, professores e n\u00f3s mesmos :)Para n\u00f3s, \u00e9 muito importante que voc\u00ea se interesse pelo mundo da educa\u00e7\u00e3o e no impacto social gerado atrav\u00e9s de seus desdobramentos!Voc\u00ea Ser\u00e1 Respons\u00e1vel Por  Participar do desenvolvimento da plataforma de dados, construindo microservices em arquiteturas event-driven e pipelines de processamento de dados que alimentando dados ao data lake; Aplicar boas pr\u00e1ticas de c\u00f3digo, como clean code, arquitetura hexagonal, testes automatizados e princ\u00edpios de programa\u00e7\u00e3o funcional. Integrar um time multidisciplinar inspirados em cultural agile e continuous delivery; Liderar entregas end-to-end, desde sua modelagem at\u00e9 produ\u00e7\u00e3o (\u201cYou build it, you run it\u201d); Adotar conceitos de devops, como IaC (Infra as Code) na gest\u00e3o de infraestrutura, contribuir na constru\u00e7\u00e3o do ferramental de engenharia, buscando oportunidades de multiplicar tecnologias para todos os times.\nAlgumas tecnologias que ter\u00e1 contato: Python; FastAPI; AWS SQS, SNS, ECS e Lambda; PostgreSQL; Docker; Github Actions; Terraform; ELK;Conceitos utilizados (que esperamos que voc\u00ea conhe\u00e7a): Microservice, Event driven, Testes automatizados, Cultura \u00e1gil, Continuous delivery, Conceitos de functional programming, Infra as Code, DevOps, \u201cYou build it, you run it\u201d, Stack can\u00f4nica.Se as ideias acima fazem sentido para voc\u00ea ou s\u00e3o utilizadas no seu dia-a-dia, ficaremos felizes de conversar com voc\u00ea!  Recesso de 30 dias, pagamento adicional de 1\/3 sobre o recesso e 13\u00ba sal\u00e1rio. Vale Refei\u00e7\u00e3o (CAJU): em torno de R$500\/m\u00eas (vari\u00e1vel conforme dias \u00fateis) Vale Cultura de R$50,00 ao m\u00eas; Plano de Sa\u00fade Unimed Nacional (com coparticipa\u00e7\u00e3o de 30% e sem custo para o titular); Plano Odontol\u00f3gico Amil (sem coparticipa\u00e7\u00e3o e sem mensalidade para o titular). Escrit\u00f3rio Bil\u00edngue, onde voc\u00ea pode escolher um de nossos cursos de idiomas ou tecnologia para estudar gratuitamente; Day off no m\u00eas de anivers\u00e1rio."}
{"job_title":"Data Engineer Con Mongo DB","company_name":"FacTECH Servicios Inform\u00e1ticos","location":"Spain (Remote)","job_link":"\/jobs\/view\/3774151698\/?eBP=CwEAAAGMPHUb1Wo6TqGDnjYBp-s9O_Cvt9PO7Znn1QzjBSY133KN4sTarbvhHikum_LTMseV9Vr-Ck2g151cHIiOvoDky9hsn7o53BLpFOxk0LdqPzu7gJbuCD0cC55adYMdpPAGmA7nhOYWW0TMMeMj74FnWnXrobldCRW7C1o2FRTCALnLRniZOT3dV8HBo1Th8PMuj3F_mewO2JWfh4TCE9Qh7B6bYH0qX5PqufRH3GaVo8RcdzhRjRIM9AQ5i3AgK626U67VYUWYV-rXmBFdSAVYo4o-QWYOUUF9gDe0LUYq8oK0VmyLfDAfylBi4TATZXXU8dLSBjhQx-t4dwTJhwHEKSqp9azDtGE0gU7B-VTygSfCt5dQojt1MhRT-Q_I&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=jKn2SbIFXJz%2BdsJlD7C8Ow%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3774151698","job_description":"About the job\n            \n \nFactech es una empresa multinacional especializada en proporcionar a las grandes compa\u00f1\u00edas servicios de IT en las principales tecnolog\u00edas, contamos con m\u00e1s de 2500 profesionales al servicio de nuestros principales clientes. Nuestras sedes se reparten en Espa\u00f1a, Colombia y M\u00e9xico.Nos encontramos en constante b\u00fasqueda e incorporaci\u00f3n de talento, es por eso que seguimos ampliando nuestro equipo incorporando un Data Engineer con conocimientos en MongoDB.Se trata de un proyecto estable para trabajar con la Administraci\u00f3n P\u00fablica Catalana, aunque la posici\u00f3n se desarrolla fundamentalmente en modalidad remoto, la persona seleccionada debe tener disponibilidad para reuniones puntuales en Barcelona.Conocimientos imprescindibles:Experiencia de 3-4 a\u00f1os como Data Engineer.Experiencia trabajando con MongoDB.Disponibilidad para reuniones puntuales en Barcelona.\u00bfQu\u00e9 ofrecemos?Se trata de un proyecto que se desarrolla en modalidad 100% remotoContrato indefinidoInvertimos en su salud f\u00edsica y emocional (Seguro M\u00e9dico Privado)Salario entre 36K-40KIntentamos siempre trabajar con \u00faltimas tecnolog\u00edas y proyectos innovadores.\u00bfAceptas el desaf\u00edo? \u00a1Te esperamos con los brazos abiertos!En Factech fomentamos un entorno laboral basado en el respeto por nuestros profesionales, el desarrollo profesional y la promoci\u00f3n de la igualdad de oportunidades sin discriminaci\u00f3n alguna por cuesti\u00f3n de g\u00e9nero, es por eso que te invitamos a formar parte de nuestra gran familia Factech."}
{"job_title":"BI Developer - 380USD per day - Fully REMOTE - B2B Long term contract","company_name":"Conduco Talent","location":"European Union (Remote)","job_link":"\/jobs\/view\/3765459632\/?eBP=CwEAAAGMPHUb1WVWK-3KGR9Qjui-OZHTppfs8Wkre-atkeyC4tgerT7ixr8Fq85DJdtn_UpxPIfkZE36d_l5vEEU_XfjA3r2XBjsBCwREr9-eqYlPe4sQ3C-5udHvff7c7EfA5TgFrekhdk5D6FCOojI1IRzsnyOgpK4y5Mf84nrmXl5MaeXP4JYZcQoVj44WX1MwXwVT_eBHKCDeQ60jJkR_SJDH_E9-0_9LqGN1QCKpMLCxAqTdWjyM93U0TFtKswRToOHi7A7lEFQQj8KBr1DG1zC-zK2YfhYUOiTSr6AATp1EX2EsZhcpaAul8p3as39jyhkRleUCS8avhbONwGx1qHyWauqbrJ4OPMvtbe6nE2A5WwXHPNWjNYRe_ZdKvfid38&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=x9nA4V1IbA8bPO0ymugPjg%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3765459632","job_description":"About the job\n            \n \nBI Developer $380 per day Fully REMOTE from EUB2B Full time, long-term contractThe role: Design, develop, and implement Microsoft BI tools.Enhance Microsoft Analysis Services and Integration Services (ETL) packages.Create and maintain Power BI dashboards and reports.Conduct deep analysis using Power BI scripts.Provide technical support and consultation for BI tools.\nWhat you need: EU passport for securityEnglish language skills5+ years of experience in BI tools management and Microsoft BI Tools implementation including dashboard and report creation.Knowledge of Power BI application security layer models.Proficiency in MDX and DAX is desirable.Experience in Microsoft Integration Services (ETL) and agile development approaches desirable.Experience with frameworks like Microsoft TFS\/Azure DevOps desirable.\nConduco Talent is actively hiring for this vacancy, so submit your profile now for immediate consideration and a full job description."}
{"job_title":"Projektant\/programista baz danych SQL","company_name":"Innobo Sp. z o.o.","location":"Poland (Remote)","job_link":"\/jobs\/view\/3767990629\/?eBP=CwEAAAGMPHUb1Xk73yT3QDilhz7CBaLIQnGq5mxBmNZauaSPB3fbZpysGGzvJGsIG9r2Fcb-j8lTgCN7e43jMjfi2YTIGXmMNUhaXMNYYjhuSh34CebZrFpOqYT9hGW6iU2CeIfXBiEHfNvzIMqce0-xsPNR3NS4KQ7wOhZfN7IEgOm5b_ukv_-DGQVvbAuSinUEoC1lp5zk9D3lgwiQfZyrx_4sAJsuWNcWrb1MSDqBvIn4IF_0-ZSmIeSH_0zu5QVwKASaY6-sUjzndm0_8UWyas9MmxU3M7kDhhDCnVBMXOmT5QW7-MrUWRm5LG1if4_c7ukTAfoFRpa7v-bOp3fnzm_pFwcYLSbddD3pnkq_JDMbY0X2jf9sTimRyKUWPMzJ&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=6%2BhsKhRaVDmIpD8AQk6eZA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3767990629","job_description":"About the job\n            \n \nKlient: firma ubezpieczeniowaForma zatrudnienia: B2B\/UoPRodzaj pracy: zdalna z okazjonalnymi podr\u00f3\u017cami do biura (Warszawa)Stawka: do 100 z\u0142\/h netto (B2B) lub do 14 000\/mc brutto (umowa o prac\u0119)Dla naszego klienta, firmy z sektora ubezpieczeniowego, realizujemy proces rekrutacji na stanowisko projektanta\/programisty baz danych. Zakres obowi\u0105zk\u00f3w\u00b7 Tworzenie i rozw\u00f3j oprogramowania w oparciu o j\u0119zyk SQL\/TSQL\u00b7 Projektowanie, implementacja oraz utrzymanie proces\u00f3w ETL w SSIS\u00b7 Optymalizacja wydajno\u015bci proces\u00f3w, procedur i zapyta\u0144\u00b7 Analiza danych w MS SQL Server oraz opracowywanie raport\u00f3w - wsparcie os\u00f3b odpowiedzialnych za raportowanie w firmie\u00b7 Dostosowywanie i rozw\u00f3j system\u00f3w raportowych do nowych wymaga\u0144\u00b7 Nadzorowanie, wykrywanie i eliminowanie nieprawid\u0142owo\u015bci, usuwanie awarii\u00b7 Czynny udzia\u0142 w projektowaniu Hurtowni Danych i innych system\u00f3w analitycznych Wymagania\u00b7 Wykszta\u0142cenie wy\u017csze informatyczne lub pokrewne\u00b7 Bardzo dobra znajomo\u015b\u0107 SQL \/ procedur sk\u0142adowanych\u00b7 Do\u015bwiadczenie w projektowaniu i implementacji proces\u00f3w ETL\u00b7 Do\u015bwiadczenie w optymalizacji zapyta\u0144 SQL, indeks\u00f3w, statystyk oraz modelu danych\u00b7 Znajomo\u015b\u0107 j\u0119zyka angielskiego na poziomie umo\u017cliwiaj\u0105cym korzystanie z dokumentacji technicznej\u00b7 Znajomo\u015b\u0107 tematyki hurtowni danych\u00b7 Zdolno\u015bci analitycznego my\u015blenia i rozwi\u0105zywania problem\u00f3wMile widziane\u00b7 Do\u015bwiadczenia w administracji bazami danych\u00b7 Do\u015bwiadczenie w budowaniu raport\u00f3w Cognos, Tableau\u00b7 Praktyczna znajomo\u015b\u0107 programowania w Python\u00b7 Znajomo\u015b\u0107 technologii Big Data\u00b7 Znajomo\u015b\u0107 tematyki ubezpieczeniowej"}
{"job_title":"Quality Assurance Automation Engineer","company_name":"Cpl","location":"Warsaw, Mazowieckie, Poland (Remote)","job_link":"\/jobs\/view\/3770964424\/?eBP=CwEAAAGMPHUb1UlrJnIDYjnTVq6LYXAdvLynI1V-WHOfWrHo-NTQ93qey3Qjq8DW3N3dJuWZIpbwmlOTZSDwle87DAm5cTAUyt1rQ6XuwxMu-IcSEOOJFkf3GAtjGFIanKOam10rXCpQtUg7wj5HicQSqcQ1f92VgCM07qMTQVWEfAFvL4nK9W26wUVIwPmxNTe7-VfLACYM_1c3BYRP8zRo6-x8miz5KTjicQ5eZuiGL9mm7z0vy00Ntbj5SjpylbzsuC6iR6JWHbBRxfMeYUJA-QGj0h5aXSkO-TMH4BXRt72IkG_PnJgh1yKJpSmADXwhJa8zpi7ri_2KPvhrlepWoKqd-avESsoEr5xS5tXCk-7XdTavfzCOOjCd9PkBFUm-&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=3cpm5%2B0s2PD%2Bk%2FB9HBuiPA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3770964424","job_description":"About the job\n            \n \nTL;DR QA | Selenium | Cypress | Remote | B2B | 22-26KSenior Automation TesterKlient - Europejski Softwarehouse - Wieloletnie do\u015bwiadczenie w przemianach technologicznych z biurami w ponad 50 krajach.\ud83d\udcb0 Wynagrodzenie - Zale\u017cne od do\u015bwiadczenia - 22-26.000z\u0142\ud83d\udcbb Model Pracy - 100% Remote\ud83d\udcf0 Kontrakt \u2013 B2B \ud83d\udc69\u200d\ud83d\udcbb Technologie - Selenium, Cypress, WebdriverIO, BrowserStack, REST-assuredDay to Day:\u2714 Wspieranie techniczne zwinnego zespo\u0142u automatyzuj\u0105cego testy (UI i API);\u2714 Wsp\u00f3\u0142projektowanie architektury test\u00f3w i doradztwo technologiczne;\u2714 Konfigurowanie zestaw\u00f3w test\u00f3w automatycznych w \u015brodowisku continuous integration;\u2714 Wykonywanie test\u00f3w, analizowanie i raportowanie wynik\u00f3wNasze oczekiwania:\u2714 3-letnie do\u015bwiadczenie w tworzeniu system\u00f3w automatyzacji test\u00f3w frontend i\\lub backend\u2714 Znajomo\u015b\u0107 dobrych praktyk DevOps (Continuous Integration, Continuous Delivery);\u2714 Angielski B2Oferujemy:\u2714 Mo\u017cliwo\u015b\u0107 pracy 100% zdalnie lub z biura w Warszawie\u2714 Elastyczne godziny pracy\u2714 Jasna \u015bcie\u017cka kariery"}
{"job_title":"Big Data Developer - Spark Scala","company_name":"Claire Joster","location":"Spain (Remote)","job_link":"\/jobs\/view\/3778384421\/?eBP=CwEAAAGMPHUb1f8wf3DUf9g_TQ1rUwPZxqwrpQ3EtINm7DgYFrr4yvXVQt7CMofX2gbqvfUUfQxBUV9x01jTmzRRkGtM-ZygnP5OiaR4-2-dw_RbsDDlE9xm_9CN6FO1PKzvceSvj_F-UT_k49JDEs5mvHjLB3JhGCekeomSayDXfJ4DlcmdN3ANGcHPQZCp05gaB0rcxcnpB3wJOej3RSmd2GJI65wi9wxNxfevWQPRZdjUhqP-Qp4iW9bj-lzwWCsEcYc_OVDr46E4IAJq8_V7tVPHOAxNFQg1yqyfIap3ZEcXdfndJ79_y-YQMkeWseNcwlLGVzRmJKwXNNaxdvVg1S2jKUi6CdL0c5qO22zJmsKs_Jzq2CtMsqWOx91ZWSII&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=NBhQqzCu%2Fc4undyrERQ%2Bkg%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3778384421","job_description":"About the job\n            \n \nEn Claire Joster somos especialistas en la b\u00fasqueda y selecci\u00f3n de Perfiles cualificados de Mando Intermedio y Management en el \u00e1mbito tecnol\u00f3gico para las principales \u00e1reas funcionales y t\u00e9cnicas, con un valor a\u00f1adido fundamental: la captaci\u00f3n de talento, basada en valores y ajuste cultural de nuestros clientes y candidatos.Actualmente estamos buscando para una importante empresa multinacional de consultor\u00eda varios perfiles de Big Data Developer con experiencia en Spark Scala. Principales Funciones: Desarrollo y mantenimiento de procesos en Spark y Scala.Evoluci\u00f3n y mantenimiento de la plataforma Big Data.Desarrollo de software usando tecnolog\u00edas Big Data.Formar parte de equipos multidisciplinares.Participaci\u00f3n en proyectos para grandes clientes.\nRequisitos: Formaci\u00f3n acad\u00e9mica \u2013 Titulaci\u00f3n superior en carreras t\u00e9cnicas de Inform\u00e1tica o similar.+ 2 a\u00f1o de experiencia real en producci\u00f3n con tecnolog\u00edas Big Data (Spark, Scala, Hive, Kafka, Flink, etc.)Experiencia en alguna de las siguientes bases de datos NoSQL (MongoDB, HBase, ElasticSearch, Cassandra, etc.)Conocimientos en herramientas Agile (Jira, Jenkins, Bamboo, Git, Sonar, etc.)\nSe ofrece: Flexibilidad y teletrabajo.Contrato indefinido y proyecci\u00f3n de carrera.Buen ambiente de trabajo.Formaci\u00f3n.\nSi quieres trabajar en uno de los equipos de tecnolog\u00eda m\u00e1s fuertes del momento, con herramientas punteras y en un entorno muy innovador tecnol\u00f3gicamente, esta es tu oportunidad."}
{"job_title":"Data Quality Engineer","company_name":"Pagos Solutions","location":"Portugal (Remote)","job_link":"\/jobs\/view\/3761942997\/?eBP=JOB_SEARCH_ORGANIC&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=sqkKZqMr8xEngFVv%2BHng5g%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3761942997","job_description":"About the job\n            \n \nAbout UsAt Pagos, we\u2019re passionate about empowering businesses to take control of their payments stack and solve the puzzles standing between them and optimized growth. Our global platform provides developers, product teams,and payments leaders with both a deeper understanding of their payments data and access to new payments technology through user-friendly tools that are easy to implement. To succeed in this, we need creative thinkers who are willing to roll up their sleeves and start building alongside us.About The RoleData is core to everything we do at Pagos. As a Data Quality Engineer, you\u2019ll play a key part in ensuring the quality and consistency of our data.With a keen eye for detail and a collaborative approach, you\u2019ll partner and collaborate with our Engineering and Product teams. You\u2019ll focus on testing data pipelines, debugging rogue SQL queries, and tracking down data inconsistencies.As a Data Quality (DQ) Engineer, you will: Own data quality across the entire platformDesign scalable and reliable test plans to ensure consistent data deliveryFind, research, and track bugs Plan and coordinate testing activities across cross-functional teams \nWhat We\u2019re Looking ForWe\u2019re looking for someone with: 2-4 years in QA\/DQ engineering, data analysis, or equivalent professional experienceExcellent knowledge of data observability, data governance, data quality tools, data lineage, and data validation toolsExperience setting up continuous integration for test automationStrength in writing and enhancing test automation frameworkExcellent SQL knowledge, with experience writing and debugging complex queriesExperience with data quality test automation (e.g. Great Expectations, Apache Griffin, Deequ, DBT tests, custom Python scripts + Airflow, or similar tools)Experience programming in PythonA bias for action, where no task is too small Excellent communication skills\u2014both written and verbal while working with an asynchronous global team\nNice to haves: Experience in the fintech\/finance industryExperience with Data Build ToolComfort and\/or past experience working with big data testingComfort and\/or past experience working with ETL\nPagos does not accept unsolicited resumes from third-party recruiting agencies. All interested candidates are encouraged to apply directly."}
{"job_title":"Python Developer - 100% Remoto","company_name":"Walters People","location":"Barcelona, Catalonia, Spain (Remote)","job_link":"\/jobs\/view\/3766038231\/?eBP=CwEAAAGMPHUb1YMASo8mljbp9jiHt6mNDcrhjTLSqqwhO2QFcuWCUsMGgwz3xpucK0O3XF4_htTf_ob4PBTcDIX8cM7Mdzlfa3MNsmcgSzYWAw7ejGmkXdm03fDk0N_rLAL5NpucLJgaFa_0hoC7KaQhGXxrx_pkYz-_62DA_-f0iH0MeMwLPk5bPWoBJsfq9yGpq8JK53hr2LVyw3G_d9I2jgHEXXvkPuydzburZd6RdBvCmFkU0lpXRoPs-ITX34B6K6ZbMsaoCdqOjHPiH_4KX8ivoXsU54eW-NviKEMJ84IsFQjNlb-548N-p7pYFHr-81C07K-YMg45SOBUQarohSu1cMkkD-_-o0YMSaLq4fPHDIULDSprLCP-eyz7lOKT&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=Br8nZX279H1I%2F27Hq87Qkg%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3766038231","job_description":"About the job\n            \n \nDesde Walters People estamos en b\u00fasqueda de un Python Developer en Remoto con varios a\u00f1os de experiencia en desarrollo de Python y con nivel alto de SQLSi eres una persona motivada, que busca un proyecto retador en una empresa con tecnolog\u00eda puntera, con ganas de aprender y crecer mientras aportas tu valor a\u00f1adido al equipo. Est\u00e1 es tu oportunidad!Requisitos: 4-5 a\u00f1os de experiencia en PythonExperiencia en SQL y entornos CloudValorable: Experiencia en Computer Visi\u00f3n, NLP...\nOtras Habilidades: Conocimientos de metodologias AGILEPrincipios SOLIDIngl\u00e9s - Intermedio\nSe ofrece: Plan de carrera100% REMOTOSalario competitivo."}
{"job_title":"Cloud Engineer","company_name":"Annapurna","location":"European Union (Remote)","job_link":"\/jobs\/view\/3766843006\/?eBP=CwEAAAGMPHUb1a_jc4DbXcW_p3MQFY58v4C5mFX1eYAENQcsrzL3sc9-hP-l-NZ9lruXN4N9rrWAVF8zuspGyH6pxk6eNBMCJTzP0BKcvPCHGu43Iz-be7BgKSSw_0PEBpRKL3ck7tAB9mhF8NpPMz8Cs3chZMOVPjqb9T1QCxDUWRCK1c3psJGHRAYhnl6kTyU48XGrEabaW6lEB5_G68qoXn4H4s2V5XZPnIeVeKJ5iuFpxGsbYo_TD8Qy4ZviJDgIIGA_p4OS8lPSm3DjLg2b253FFw6EhNjeT5vtMIjtom6eNg2nszRzh-whdCouPnKe-KUeoJ8V9qV_wg_oN2VbchdANAjPYmPCxv-ZOmrdQaXumtgPBXXmRF6_5l0zhmC0&refId=bNZNqmFoY5hGB7OGHZSMJg%3D%3D&trackingId=%2F0YqwcMShE%2Fr1BlF6zhcXA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3766843006","job_description":"About the job\n            \n \n\u2728 Our client provides a Digital Transformation Platform for the most prestigious names in fashion, retail, footwear, luxury, outdoor and consumer goods. Their flagship Product Lifecycle Management (PLM) platform, delivers enterprise-class merchandise planning, product development, sourcing, quality, and collection management functionality tailored for fast-moving consumer industries. They provide innovative PLM technology and key industry learnings for emerging brands as well as offering a fully visual, transformative experience via large touchscreens and mobile devices, revolutionizing group decision making and creative collaboration while dramatically condensing time to market and product innovation.Reporting to the the Senior Director, Cloud Operations, you would be responsible for utilizing a diverse set of cloud technologies to support our client's customers and to help build and maintain a scalable, robust, highly available platform for their cloud application. \ud83d\udd0eResponsibilities;\u2714\ufe0fManage and maintain cloud infrastructure on platforms such as AWS, Azure, or Google Cloud.\u2714\ufe0fMonitor cloud resources to ensure availability and scalability.\u2714\ufe0fMonitor and optimize cloud resource utilization.\u2714\ufe0fRespond to and resolve time-critical customer issues in the public cloud.\u2714\ufe0fTroubleshoot cloud-related infrastructure incidents and issues.\u2714\ufe0fPerform customer deployments, migrations, and upgrades in the cloud environment.\u2714\ufe0fSupport automation projects, writing infrastructure as code (IaC) for provisioning and scaling resources.\u2714\ufe0fCollaborate with development, devOps and support teams to deploy and manage cloud-based applications and resolve issues.\u2714\ufe0fPropose and implement improvements to cloud operations processes.\ud83d\udd0eQualifications;\u2714\ufe0fBachelor\u2019s Degree Computer Science, MIS, or related technology field, or equivalent practical experience\u2714\ufe0fExperience in cloud operations and infrastructure management in AWS, Azure, or Google cloud\u2714\ufe0fExperience in incident response and major incident management\u2714\ufe0fAdvanced Linux and Windows experience\u2714\ufe0fCertification in AWS, Azure or Google Cloud is a plus.\u2714\ufe0fSolid understanding of Cloud networking and security\u2714\ufe0fProficiency in infrastructure as code (IaC) and configuration management tools. (e.g, Terraform, Ansible)\u2714\ufe0fExpert knowledge in containerization and orchestration technologies (e.g., Docker Kubernetes, Rancher)\u2714\ufe0fExperience with the following technologies: Virtualization, VPN, RDP, SSO, Kafka\u2714\ufe0fExperience working with Confluence\/Jira\ud83c\udf89Benefits include;\u2728 A multifaceted job with a high degree of responsibility and a broad spectrum of opportunities\u2728Opportunity to work remotely with a dedicated and motivated team\u2728A remote work environment built on collaboration, flexibility, and respect\u2728Varied and challenging work to help you grow your technical skillset.Interested? Send over your CV to o.olapade@annapurnarecruitment.com to find out more information about this exciting opportunity!"}
{"job_title":"Staff Data Modeling Engineer","company_name":"SentinelOne","location":"Slovakia (Remote)","job_link":"\/jobs\/view\/3765342409\/?eBP=CwEAAAGMPHlytfFOqAJiiSP5Df7JdkWsZwEsSFdUNcfVMAO7pAmE-XRXszOirT72FR63-IKbOU58c0_Uwxq1n-c6z7FXRfPiqA8juO0raYp1vfIuGMkZr6i8TN6_ydcL61ECrnfc9J1mda0TRDWuks73syzkhnsiltDKrFIg3Owu-fGsFMQ0EGFl7oJS24_doAHqbSkol7GmdvItyV65SUgfqSUs5d5HsGM0esfwddjV0OBcQZ4r1H-S-tksbwB-VXfb3MwCOufMqDHUUbcTayiNEOYgwBbZEgigzSMOC1hC7ZJdlbnBB4uNmChsaKY_1WF_KQ7oNct0SazXBE3Qaxh9ItYv6OWRd44DPEoWjk8j5ycXeRrXUhyyoQLwXT2zWw&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=0cfjbqAWSZ4qVSwwqR9sCA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3765342409","job_description":"About the job\n            \n \nAbout Us:SentinelOne is defining the future of cybersecurity through our XDR platform that automatically prevents, detects, and responds to threats in real-time. Singularity XDR ingests data and leverages our patented AI models to deliver autonomous protection. With SentinelOne, organizations gain full transparency into everything happening across the network at machine speed \u2013 to defeat every attack, at every stage of the threat lifecycle.We are a values-driven team where names are known, results are rewarded, and friendships are formed. Trust, accountability, relentlessness, ingenuity, and OneSentinel define the pillars of our collaborative and unified global culture. We're looking for people that will drive team success and collaboration across SentinelOne. If you\u2019re enthusiastic about innovative approaches to problem-solving, we would love to speak with you about joining our team!What are we looking for?SentinelOne is seeking a talented Staff\/Techlead-level data modeler to assist with designing and implementing data products. As a data modeler, you will work closely with architects, data engineers, data analysts and other data modellers to implement data modeling solutions to streamline and support stakeholder reporting and enterprise business intelligence use cases.To ensure success as a data modeler at SentinelOne, you should have in-depth knowledge of data warehousing, excellent communication skills, and an understanding of how to turn raw data from various sources into easily consumable data products using tools within the data ecysostem, and operate under a philosophy of writing code as a last resort. Ultimately, a top-notch data modeler should be able to design models that reduce data redundancy, streamline data movements, and improve enterprise information management and time to insight.What will you do? Analyzing and translating business needs into long-term solution data models.Regularly engage and consult stakeholders on solving business problems through data, guiding the conversation rather than simply taking orders.Perform data profiling\/analysis activities that help to establish, modify and maintain data models.Evaluating existing data systems.Working with the development team to create conceptual data models and data flows.Developing best practices for data coding to ensure consistency within the system.Reviewing modifications of existing systems for cross-compatibility.Implementing data strategies and developing physical data models.Updating and optimizing local and metadata models.Evaluating implemented data systems for variances, discrepancies, and efficiency.Troubleshooting and optimizing data systems.Ability to take on additional tasks and responsibilities as the organization needs.Mentoring less-senior colleagues and knowledge sharing with the broader Data, Analytics & Governance organisation.\nWhat skills & knowledge should you bring? Multiple years of hands-on experience with physical and relational data modeling.Must have - proven profficiency with Google Cloud Platform, BigQuery, and related technologies.Experience working with infrastructure as code (Terraform, Pulumi, etc.) Expert knowledge of metadata management and related tools.Experience designing and architecting data solutions.Expert SQL skills.Knowledge of mathematical foundations and statistical analysis.Strong interpersonal skills.Excellent communication and presentation skills - in both written and spoken English.Advanced troubleshooting skills.\nWhat We Offer YouSalary from 4500 EUR\/month.Yearly % bonus depending on the performance of the company, paid out in 2 installments. The final base salary component can be increased accordingly to individual skills and experience of the selected candidate.\nOn top of that you may look forward to: Flexible working hours & Full remote within Slovakia; optional membership in Regus co-working spaces; in Czechia we also have offices in Prague or BrnoGenerous employee stock plan in the form of RSUs (restricted stock units) not options; 4 years vesting with 1 year cliff and then quarterlyFlexible Time Off (on top of the standard 5 weeks of vacation)Flexible Paid Sick DaysFully Paid Short Term Sick\/Short Term Nursing LeaveGlobal gender-neutral Parental Leave (16 weeks, beyond the leave provided by the local laws) & Grandparent LeaveVolunteering paid day off & Additional paid Company holidays off (e.g. 4 days in 2022)Pension insurance contributionPremium Life Insurance covered by S1Global Employee Assistance Program (confidential counseling related to both personal and work life matters)High-end MacBook or Windows laptop, Home-office-setup gear & on top of that additional WFH AllowanceUdemy Business platform for Hard\/Soft skills Training, internal mentoring 'MentorOne' & Support for your further educational activities\/trainingsAbove-standard referral bonusYearly bonus depending on the performance of the companyOptional company events for those who like to meet outside of work too - mostly in Czechia expensed as business trip (sport, BBQ, charity etc.)DEI&B programs that promote employee resource groups like SentinelWIN (Women Inclusion Network), Blk@S1, Latinos@S1, Pan-Asian@S1, Out@S1 (LGBTQIA+) and Sentinels Who Served\nSentinelOne is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.SentinelOne participates in the E-Verify Program for all U.S. based roles."}
{"job_title":"Data Quality Engineer (M\/F\/D)","company_name":"TUI","location":"Lisbon, Lisbon, Portugal (Remote)","job_link":"\/jobs\/view\/3756221816\/?eBP=CwEAAAGMPHlytfyn3Aklrv8P5-hcbrdVI9WVUGNXRewSzs-TUrVgmsX1OSnnLWDMBl9rMMF-nOeFu0ZB1Va7BfRT4hyg5C-hu_6iKbO_RqOk575E_SgX_kjom64jWa5qq-DRtPZnqxtxIHMFPTpTUsgsw73qtFrZblj_BJ0usyVLkxEfVkQYKLIPdq2N-MLOZ1sNV3BIP2J_nyy2jsHCAmbyxy61JOCHnGcEaHwVedpl1nbO0tyDiHrsFzmipp6Q6k_ZIcjruz08TY9lGq4xeFNo178PKol9w8rXEZ9pdiFIZCuAhjeUUynUjaqEHQnxcd2RGl12RcUKPpj-wEAXoLbFvY6SzLd8R38fslMNVwn4veZl5RQVUu3o9eYr6lTuRA&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=3EKxuMvnEjlKz2FZJBxWQw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3756221816","job_description":"About the job\n            \n \nTUI Business:CIO Band:5 Location (s): Flexible\nPalma de Mallorca, ES, 07000Oporto, PT, 4050-345Lisbon, PT, 1050-220Hours per week:37,5-40 Type of contract:PermanentTUI Group is the world\u2019s number one integrated tourism business. Marketing, Sales and Common Analytics is a global team within TUI technology responsible for CX, Sales and Digital Analytics. We are a multi-disciplinary team of experts across Architecture, Engineering, DevOps and Agile Delivery providing services across the UK, Ireland, Sweden, Norway, Denmark, Finland, Germany, Belgium and The Netherlands. At TUI we\u2019re ambitious to become the leader in technology within the travel industry and to achieve this we are looking to build a capable, creative team who want to be a part of accomplishing that goal. We never stop looking ahead, seeking new ways to delight our customers and grow our business. We recognise the power of digital and the massive contribution this brings to creating a truly unique and differentiated customer experience.The Data Quality Engineer is a practitioner and an advocate of quality-focused delivery practices, ensuring high quality of data products and services with an appropriate toolkit of technologies and methods. Working in an agile environment and keeping up with the ever-evolving technical landscape the Data Quality Engineer is a lifelong learner and likes to think outside the box.About The Job As a Data Quality Engineer, you will be part of a cross-functional team that enables quality engineering skills and capabilities across a whole domain.Being an enthusiast in creating flawlessly working data products and solutions for our customers and thanks to your excellent collaboration skills you will work with your team in delivering the best answers to our customers\u2019 needs and in taking over full responsibility for the quality of our data products.You care diligently about the quality of your work, including proper documentation and security aspects.You will use your deep technical skills to work with your team on defining, executing and maintaining efficient, highly automated test setups over the whole testing pyramid, from functional testing, integration testing to performance and load testing. You are responsible for defining an appropriate testing strategy and ensuring the availability of suitable test scenarios.You will also help to realise efficient solution for assuring quality where automation comes up against its limitations.You will coach and support your colleagues with deep knowledge to improve expertise in ensuring the quality of the data products over the whole cycle of designing, building, testing and deploying products, automated tests and monitoring.You will help to continuously advance tooling, processes, and ways of working, always having our customers in mind, and thus embed all-team quality ownership.You will also work with Product Owners to ensure testable feature specifications and champion approaches like test-driven development or behaviour-driven development. Also Security is part of everyone\u2019s job. At TUI, we practise secure behaviours first in everything we do.You are able to verbalise your thoughts and ideas and take the initiative to translate ideas into outcomes.Together with the domain\u2019s Practice teams as well as the Group Enabler teams you also will research, evaluate and test new approaches, processes and tools and help teams to use them effectively.You are demonstrating active contribution to Communities of Practice, including collaboration in shared initiatives.You love to work in an international, multi-cultural team.You challenge constructively and have high expectations of yourself and others.You always drive for technical excellence, ownership and self-organisation at\u202fteam\u202fand personal level. You love to learn and acquire new skills and keep up to date with latest developments in your focus areas.\nAbout You Deep and practical knowledge of and expertise in quality assurance practices, tools and methods in an agile context and at scaleStrong technical prowess in all quality assurance areas including automation, functional, contract, integration, performance and load testing Hands on experience with modern data storage systems (e.g. S3, Snowflake)Feeling comfortable using AWS, Kubernetes, Docker and Airflow;Strong SQL and data profiling skills; hands-on ELT experience using tools like dbt and dbt testsAbility to understand and create test cases & strategiesStrong visualization skills (e.g. Tableau)Good experience with CI\/CD, preferably Gitlab CICustomer-centric, passionate about delivering great digital products and servicesDemonstrating a true data engineering craftsmanship mindsetPassionate about continuous improvement, collaboration and great teamsStrong problem-solving skills coupled with good communication skillsOpen-minded, inquisitive, life-long learnerComfortable with ambiguity, highly autonomous\nAbout Our Offer Working in the leading global tourism group: We stand for intercultural cooperation and offer the opportunity to work in international projects and teams.Fantastic holiday benefits including discounts, special offersMobile working, flexible working hours and working from abroad: We believe that work is something you do, not where you go. Our offer: TUI Way of Working Health and Wellbeing support in five key areas \u2013 Health, Social, Community, Career and FinancialDevelopment and career opportunities: We offer a wide range of digital training and international career opportunities.Additional benefits relevant to the local market that you'll be based in\nAt TUI, we know people are as diverse as the destinations we send our customers to. We love to see your uniqueness shine through and inspire the future of travel. If you would like to read more about what Diversity & Inclusion means to us simply visit our Smile page Click hereIf you have any questions, please contact the Recruiter for this role via the contact information included in the advert.Please Note: These vacancies will be managed by an International Recruitment Team and therefore your application may be viewed by TUI colleagues outside your home country."}
{"job_title":"Technology Consulting - Big Data Engineer","company_name":"EY","location":"Patras, Western Greece, Greece (Remote)","job_link":"\/jobs\/view\/3511235938\/?eBP=CwEAAAGMPHlytYjU3vJvsRqSvdD1YZpbx3t8_XAVYvJrrSATqZYh5IsQI77GCeWdcNyslAlImuVZ3S8yI3O48rfEShWAqo5yJLB80H3L8ZvfLG05RvhH6Be76LKLdeWzGoyib4ltKTwi3PjDc3K8Svvy2DYLyAMufEFnX-m7zgeNcjlAHKIUviKNpNHfpdTx7i2SBKMp5gLtJ2SY40vtcT0a8RSFOo_Pm-UvCvvWlJHrENrK7u1HmvNGlIIsSGqmUZ2SRMsGDwfwyoe0lB0dzz1ettMkIYRYKT9i7-9dfinD9nWyjdegugLU5QYEVmhR0si7_nXjwrqhCRXyuc401GjnTAJtWMEh1Zv_ndIuRT_3r6aiHAHMGW3KaG4ZmRuOmkqr&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=B17mqk7qC%2F0d7DuzMepB%2Fw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3511235938","job_description":"About the job\n            \n \nAt EY, you\u2019ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we\u2019re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.The OpportunityAs part of our Data and Analytics team of Advisory practice you will work with multi-disciplinary teams to support clients in a wide range of big data initiatives aiming to generate and present new, useful and actionable insights. You will have the opportunity to work and take responsibilities in challenging engagements, gaining exposure to clients in various sectors both in Greece and abroad.Your Key Responsibilities Participation in large-scale client engagements.Contribution towards, or even leading delivery of innovative and engaging big data solutions.Understanding of business and technical requirements, provision of subject matter expertise, and implementation of big data engineering techniques.Conducting of data discovery activities, performing root cause analysis, and making recommendations for the remediation of data quality issues.Putting into practice good organizational and time management skills, with the ability to prioritize and complete multiple complex projects under tight deadlines.\nTo qualify for the role you must have A Bachelor\u2019s or Master\u2019s degree in Computer Science, Engineering or other related fields.Minimum 1-2 years of experience in two (2) or more of the below areas: Programming with at least one language and related technologies (Java, Scala, Python, C#, C++, etc)Big data concepts, tools and platforms available (Cloudera, Hortonworks, MapR, etc)Development life cycle (design, develop, test, deploy, etc)Any of the following tools \/ technologies for: Data Management (SQL, HiveQL, SparkQL, KSQL, etc)Data Ingestion (Kafka, Flume, Sqoop, StreamSets, NiFi etc)Data Storing (HDFS, NoSQL, HBase, MongoDB, ElasticSearch, etc)Workflow \/ Scheduling (Oozie, Ampari etc)\n\n\nIdeally, you will also have at least one of the following Design and implementation of data models in physical form in one or more of the leading RDBMS platforms such as SQL Server, Oracle, IBM DB2 \/ Netezza, Teradata, etcData modeling (ER models) techniques.Experience with Business Intelligence or statistical analysis tools and techniques.Experience with investigating and handling data quality issues.\nWhat We Look For Strong analytical, problem solving and critical thinking skills.Desire to investigate and try-out new tools and technologies as they are released.Ability to work under tight timelines, in cases for multiple project deliveries.Good interpersonal skills and ability to work effectively within high-performing teams.Confidence to convey technical advice and guidance to clients.Advanced technical writing skills in Greek and English (additional languages a plus).Evidence of self-motivation for continuous development.\nWhat We Offer We offer a competitive compensation package where you\u2019ll be rewarded based on your performance and recognized for the value you bring to our business. Plus, we offer: Continuous learning: You\u2019ll develop the mindset and skills to navigate whatever comes next. Success as defined by you: We\u2019ll provide the tools and flexibility, so you can make a meaningful impact, your way. Transformative leadership: We\u2019ll give you the insights, coaching and confidence to be the leader the world needs. Diverse and inclusive culture: You\u2019ll be embraced for who you are and empowered to use your voice to help others find theirs. \nIf you can demonstrate that you meet the criteria above, please contact us as soon as possible.The Exceptional EY Experience. It\u2019s Yours To Build.EY | Building a better working worldEY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today."}
{"job_title":"Bold Azure Data Engineer- Relocation to Spain","company_name":"Bluetab, an IBM Company","location":"Czechia (Remote)","job_link":"\/jobs\/view\/3622249557\/?eBP=CwEAAAGMPHlytWHUmwLm5NWnkPXO2VJTKbX0yu1RS_RDbhlqdIqXvJu9kT4cGTYc4gm-6bXTjT3ss6Qu6dQAn-zKz0MRI5A9lLmE_74tFH1gbCdDYSI7ju3ZaViGdDl8CwNhGPzXXDJvQr94tjuMUJUX44l7oLBRJPZBPqSVLisc4kGoShtY0imYOX3G8KiLvRHUOHRTWZ3iva_6gRBqz36DfnDcopvbGle7h81JhkVnBQznuW-5pvNF1_MuGm9ziAVYaMcnq6pDIL4EKjcrSBZLkxJ51p2-2ruYOToM41gzZj1_FHLsFQ5jB62-HvXxt0fLzCwZ6J-ZCuj1MVNW6i0NbSvrmtz5U5-mDW-oUDTSNxq9ySE26a8YyaVTMctOOlY1&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=mAVU5b08DTIPLSihSZKl9w%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3622249557","job_description":"About the job\n            \n \nZdrav\u00edm v\u0161echny polsk\u00e9 datov\u00e9 in\u017een\u00fdryAre you ready to take your next professional step?Bluetab an IBM Company, in Spain is calling! \ud83d\udcdeLet us introduce ourselves:We are a techie\ud83d\udc68\u200d\ud83d\udcbb\ud83d\udc69\u200d\ud83d\udcbb\ud83d\ude80 company which led us to be by 2021, IBM\u2019s powerful arm in Data, Cloud, ML & AI. We help key companies in multiple industries to accelerate and optimize their strategies in data and cloud platforms, taking full advantage of their architecture and development environments.We offer the opportunity to work in high levels of technical expertise environments within the Data & Cloud world; where you will be able to develop yourself personally and professionally: learn, train and share technological experiences in a culture fostered by teamwork and collaboration.We are bluetabers: we love technology, challenges and most of all people. We are restless, non-conformists, eager to learn and passionate about new technological challenges in all shapes and forms, which boost fantastic teams of professionals.We are \u00a1Great Place to Work & Best Work to Place!, known for being one of the best companies to work for in Spain.Have a look at the life in our company here:https:\/\/t.ly\/TLDqWhat we are looking for?Data & Cloud passionate professionals who want and have the necessary documentation to work in Europe and relocate to Spain.By working in Spain (Barcelona, Alicante, Bilbao, Madrid), you could have your cake and eat it; amazing Data and Cloud EMEA (International) projects and a fantastic sunny mediterranean lifestyle.\u2600\ud83c\udf0aFor these, we ask for the following requirements: At least 3 years of experience in Data ProjectsExperience programming with ScalaBig data management using Spark frameworkExperience in Big Data developments in Azure Cloud environment.(Azure Functions, Blobstorage, Event Hub\u2026)Orchestration using DataFactory.Data transformation and preparation with DatabricksCI\/CD deployments of infrastructure services (IaC) using Terraform and\/or ARMDeployment with Azure DevOpsHigh level of English (C1\/C2) required.Be able to have a conversation in Spanish (B1\/B2)\nImportant: Applicants must have a valid EU work permit and must be willing to relocate to Spain\nAnd now for the Good bit: Being a Bluetaber\u2026 What can we offer? Permanent contract and competitive salary according to position and experience.\n\u00b7 Moving to Spain? \u00a1Yes please! We will help you with your relocation and administrative formalities throughout the process. Can relocate to Spain from EU. The sixty four million dollar question in the room. \u00bfWorking from home? \u201cFlexible telework Company\u201d. Once in Spain, you will have access to our offices located in the center of Madrid, Bilbao, Barcelona and Alicante with great transport links.Flexible timetable start and finish, to suit your personal needs and reduced timetable on Fridays and during the summer (July and August)23 days holiday + 2 bluetab days (Christmas Eve and New year\u2019s eve)Luncheon vouchers (11 euros per working per 8 hour working day) as a benefit over and above salary.Medical Insurance and dental policy with extensive coverage as a benefit over and above salaryEntitlement to tax free transport and kindergarten care.On going training plan based on platform gamification with rewards, up to 800 courses and official certificationsIn addition, you will have Access to our Career Coach programme, designed to shadow you through your development and growth within Bluetab, with ongoing assessment and feedback.\u00a1You will be in charge of your own growth!Birthday gift card valued at 50 euros to spend in more than twenty shops online like Amazon, Decathlon, PlayStation, XBox, Mango,H&M, ToysrUS and a lot more to make that day extra special.\nAt Bluetab, we belive that diversity is enriching and as such, we wish to safegard both inclusi\u00f3n and equal opportunities, for this reason Bluetab has an Equality Plan and Ethical Code which includes the above principals in order to guarantee non discrimination of our employees for questions of race, colour, nationality, social background, age, sex, marital status, sexual orientation, ideology, political leaning, religi\u00f3n or anyother personal aspect whether it be physical or social.If you are mad about technology and be part of an innovative environment, 100% techie, then Bluetab is for you.What are you waiting for?#wearehiring #bluetabanibmcompany #bluetabers"}
{"job_title":"Senior Data Engineer","company_name":"Emnos Analytics GmbH","location":"Greater P\u00f3voa de Varzim Area (Remote)","job_link":"\/jobs\/view\/3724212375\/?eBP=JOB_SEARCH_ORGANIC&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=AN1dJTm4TG1w4qJxAZj%2FUQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3724212375","job_description":"About the job\n            \n \nin Portugal or GermanyAbout Emnos Analytics: Emnos Analytics is a market-leading provider of analytical, AI-based B2B platforms tailored for retailers and their suppliers. We are at the forefront of innovation in the e-commerce and retail sector, dedicated to empowering our clients with data-driven insights to enhance their decision-making processes. With offices in Porto and Munich, we are a diverse and dynamic team working together to shape the future of retail analytics.Mission statement: You are responsible for the data, powering the emnos platform. You efficiently turn raw data into valuable insights for our customers.Position Overview: As a Senior Data Engineer at Emnos Analytics, you will play a pivotal role in shaping the future of our data-driven retail solutions. You will be responsible for efficiently transforming raw data into valuable and actionable insights on our cutting-edge platform. If you are passionate about leveraging cloud technologies, data engineering tools, data quality and analytics to drive business success, we want to hear from you.Key Responsibilities:  Utilize your expertise in Google Cloud Platform (GCP) to design, implement, and maintain scalable data pipelines. Ensure high data quality by implementing data pipeline testing and monitoring. Collaborate with the team to build and optimize data transformation processes using Dataform, Airflow, and other GCP data engineering tools. Write clean, efficient Python code for data extraction, transformation, and loading (ETL). Harness the power of SQL to query and manipulate data. Working with BI tools to create insightful data visualizations and dashboards. Work closely with our international team. \nYour Experience\/Skills:  Proven experience as a Data Engineer or similar role. Strong proficiency in GCP, Dataform \/dbt, Airflow, and other data engineering tools. Solid programming skills in Python and SQL. Knowledge of programming languages such as Java and Scala is an advantage, but not mandatory. Experience with a BI Tool such as PowerBI, Tableau, Looker or Yellowfin. English language proficiency for effective communication within our international team. If you are proficient in German, it's a plus. Bachelor's degree or higher in a relevant field (Computer Science, Data Engineering, etc.). An innovative mindset, problem-solving abilities, and a passion for transforming data into actionable insights. Previous experience in the retail or e-commerce sector would be a valuable asset. \nJoin us at Emnos Analytics and be part of a dynamic team that is revolutionizing retail through the power of data. If you are passionate about data engineering, have a knack for turning raw data into valuable insights, and want to shape the future of retail analytics, we want to hear from you."}
{"job_title":"Python QA Automation engineer","company_name":"Luxoft","location":"Romania (Remote)","job_link":"\/jobs\/view\/3772553902\/?eBP=CwEAAAGMPHlytbPUmSubBhdlh_7LD_3fHFYTYv7kUNVrf1iWaI8NBIC5DWFXUmFAqPqNsF1hWQjpxH09LHfzpEfg0ixJgV3TbO4wdnmmgzVxdwXGd1Tnrd_QA-h-gkM7N6DxXWBbWP6MUYv2iyZD_v5qzhJoaYct0n9s0uLk5RhQ4wBGp02tkAgQYfL8AgC2RUZ_ptrJItkpoiNrl4Gxf7PmxyIKrc8r-wJ-6X3sLlYA1bVRwYvVZ22kVtdNag3kqogK3OzSBycFnePhHVHezSFvoMZJ6gOLXf-Bd2cIl82L9mUbkpzVgBxXAMwoUWoiulw66KUAgpq5d3S0MFuXjn2Rn6G--NhOgBQ7t-8Ww9mXuYeoo2h7Px6-G_aZPn9iHw&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=POdIT9907pmu5%2BqTLkUvAA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3772553902","job_description":"About the job\n            \n \nProject DescriptionYou will be part of a multi-national team responsible with the development of the next generation SDN (Software-Defined Networking) solution for Data Center networking.The solution targets Data Centers of large organizations, including private\/hybrid\/public cloud environments. It is addressing the needs of users requiring an easier option than switch-by-switch, CLI-based approaches and can automate time consuming tasks such as configuration of L2-L3 network devices.The controller uses microservice architecture, the components will communicate via REST APIs and will also provide a user-friendly web-based user interface on the front-end.We are looking for a QA engineer to contribute to the test automation process for a web application that monitors various network performance statistics and provides extensive visibility into the traffic flows.Responsibilities * Develop automated test cases in Python, using public test framework pyATS* Create libraries for new features and maintain the existing ones* Prepare Test plan, Test cases and Test scripts for product enhancements and bug fixes* Document test results, identify exceptions and communicate results to the team* Manage Defect lifecycle\nSkillsMust have \u2022 2+ years of experience in automation testing with a computer science bachelor's degree or equivalent\u2022 Working knowledge of REST APIs\u2022 Programming and scripting skills in Python\u2022 Understanding of OOP conceptsSoft Skills\u25cf Very good written and spoken English\u25cf Ability to work, and thrive in a distributed team\u25cf Self-starter, self-learner capabilities, takes initiative, identifies and completes tasks\u25cf Professional with the ability to properly handle confidential information\u25cf Strong problem solving and analytical skills\u25cf Strong written and spoken communication skills\nNice to have \u25cf Basic networking knowledge\u25cf Knowledge of using Postman\/ similar tool\u25cf ISTQB Certification is a plus\u25cf Hands-on experience testing switches, routers, docker\/container networking and SDN controller is a plus\u25cf Working knowledge of VMWare, vSphere, Jenkins\u25cf Experience with a versioning system (preferably Git)\nLanguagesEnglish: B2 Upper IntermediateRomanian: C2 ProficientSeniorityRegular"}
{"job_title":"OMOP - Data Engineer (Homebased)","company_name":"IQVIA Spain","location":"Spain (Remote)","job_link":"\/jobs\/view\/3771946066\/?eBP=CwEAAAGMPHlyta72QovGIvwrXYkxtP912__vEH263k3Dzp4WoYOdYgkMDE1Cf45VUqszSJadliakNyCNuRQHBkKJTi0T9S0FVBFqnAZ1UXaJOvYwQyOXxVyBj8UMxg_TbscRlgtEF98pj0PHlwt6AXAR2n0_B0clpM4SQIHgtNF5uHHJRanwP_oJNEGDXZ1xMzG1ULzevNKipYZ176PBF_vS7hYKdgc5SYQEwBSHZV1ry2AWCRsZ8LSymAlfpvQ3VVI9wUSZIUQTHFkkccNDSof90oaF2gnbS1thzuSglKgIUZ3dht-G-wcs2UN75FgWlz30MVWiwhKUb8XUkGOpbQ4Iayqucgc_xEOkEHPHceVEeBTk4ig3LV3lVcTFMsxAKO_A&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=mrPtcZ5wJZ0ES5PAWpdiQQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3771946066","job_description":"About the job\n            \n \nJoin us on our exciting journey!We are looking for an OMOP Data Engineer ,this could be your chance to start a new adventure in a company with the best background in human data Science.IQVIA is a leading global provider of advanced analytics, technology solutions and clinical research services to the life sciences industry. We believe in driving healthcare forward by pushing the boundaries of human science and data science. Our passion, innovation, collaboration and growth help our customers create a healthier world.We are a team of 88,000 in more than 100 countries around the globe. Our people are entrepreneurial spirits with a connected intelligence, unafraid of challenges and driven by the desire to do good.If you want to play a key role in a diverse, dynamic, and committed fun team this could be the role for you!Main Responsabilities:- Responsible for creating and maintaining internal data pipelines to convert data into the OMOP CDM using the IQVIA OMOP Converter.- Supporting the internal use of the OMOP converter and influencing it\u2019s roadmap and development.- Working within a supportive and positive team with great plans and strategy for growth in the coming years, making this a strong career growth opportunityKEY EXPERIENCE REQUIRED:- Recent experience working within ETL and Data Integration- Strong experience within Data Integration and common challenges faced with diverse data sets and data quality- Desire to learn more and become an expert within the OMOP community- Medical and pharmaceutical patient level data experienceSKILLS REQUIRED:\u2022 Excellent communication and writing skills\u2022 Ability to facilitate meetings\u2022 Ability to gather requirements\/business rules\u2022 Ability to work with both business stakeholders and development team\u2022 SQL & RDBMS knowledge\u2022 Knowledge of ETL processes\u2022 Ability to mentor others\u2022 Ability to participate and balance multiple projects\u2022 Flexible; able to adjust to a constantly changing environmentNice to Have :\u2022 OMOP knowledge\u2022 Knowledge of OHDSI tool suite; Rabbit In a Hat, Atlas, Athena\u2022 experience of Agile Scrum\/Kanban and collaboration tools; Jira and ConfluenceQualifications :\u2022 Bachelors degree or higher in a science, medical or mathematics discipline. \u2022 \u2022 Biomedical science or informatics ideal.#ESPH-3463"}
{"job_title":"Junior Data Backend Engineer (Clickstream Analytics) (Remote - Ireland)","company_name":"Yelp","location":"Ireland (Remote)","job_link":"\/jobs\/view\/3778946113\/?eBP=CwEAAAGMPHlytXs1HoQr66AOkMqGu6L4iqihNlwxIysl7-O-LPUzBegvEey4qLvL7D322mVqk50RlKIoqG8p9GZvKP8fvuAreiV-8wD_aL_v0bu5ZJxtjIYvjS6FwpUX86353LFdA9o1NrmdRXFxa3QbAutr3hSwxHsqevQ2Cs6hyEwUShhkGuv9pkLRTR9n6rdcaBICVC0jCJjN9qNe7MDe1DcUy_a_IOO9pcChprvN0wXPMOi5LzwKf094-7VvDtAzj7G1yFtNSybI1lmoOWP-i2dLwPnnCVWREpqJE_TUrXIMHexwIrRH7YNhoFex8DWXSsLVSpFSmYIGHhSua3LMAzTG78HCwd6Xv5dvxyLt58r83PLkaV2djWkV0Dfu0Hzs&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=5lOxqphwpFmlIBn3op2tvQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3778946113","job_description":"About the job\n            \n \nSummaryInterested in exploring data and finding innovative ways to collect it, curate it, and make it easily accessible for others to use? How about doing that at an enormous scale? Yelp\u2019s datasets contain billions of interactions between users and local businesses around the globe. If working with our vast amount of data sounds exciting, come and join us!The Clickstream Analytics team is responsible for creating, managing, governing, and monitoring some key user journey metrics to support our product teams and also support offline analysis that aids in making long term company decisions. We also build tools that help us to better understand our data quality, and we strive to uncover data issues before they impact our consumers.As a Data Backend Engineer on this team, you will be responsible for building elegant and scalable data products that serve critical, up-to-date, structured information to support different types of analytics within Yelp. As a core contributor to our growing data modeling and data warehousing engineering efforts, you will help design and own mission-critical data flow pipelines and datastores to enable decisions including effective A\/B testing and company investments.Yelp engineering culture is driven by our values: we\u2019re a cooperative team that values individual authenticity and encourages creative solutions to problems. All new engineers deploy working code their first week, and we strive to broaden individual impact with support from managers, mentors, and teams. At the end of the day, we\u2019re all about helping our users, growing as engineers, and having fun in a collaborative environment.This opportunity requires you to be located in the Republic of Ireland. We\u2019d love to have you apply, even if you don\u2019t feel you meet every single requirement in this posting. At Yelp, we\u2019re looking for great people, not just those who simply check off all the boxes.What You'll Do Build systems that can effectively store and crunch terabytes of data.Design and develop data models for efficient data storage, retrieval, and reporting.Create and maintain conceptual, logical, and physical data models using industry-standard modeling tools.Collaborate with cross-functional teams, including engineers, data analysts, business analysts, and data scientists, to understand data requirements and translate them into effective data models.Participate in data integration efforts, including ETL processes and data migration.Stay up-to-date with industry best practices, emerging technologies, and trends related to data warehousing.Support on-call rotations as needed to operate the team.\nWhat It Takes To Succeed Understanding of high performing and scalable data systems.Experience in building and orchestrating ETL pipelines.Experience with Data Lake or Data Warehouse landscape.A hunger for tracking down root causes and fixing them in systematic ways.Ability to communicate effectively to technical and non-technical cohorts alike.Exposure to some of the following technologies: Python, AWS Redshift, AWS Athena \/ Apache Presto, Big Data technologies (e.g S3, Hadoop, Hive, Spark, Flink, Kafka etc), DBT.\nWhat You'll Get Full responsibility for projects from day one, a collaborative team, and a dynamic work environment.Competitive salary, a pension scheme, and an optional employee stock purchase plan.25 days paid holiday (rising to 29 with service), plus one floating holiday.\u20ac150 monthly reimbursement to help cover remote working expenses.\u20ac95 caregiver reimbursement to support dependent care for families.Private health insurance, including dental and vision.Flexible working hours and meeting-free Wednesdays.Regular 3-day Hackathons, bi-weekly learning groups, and productivity spending to support and encourage your career growth. Opportunities to participate in digital events and conferences.\u20ac95 per month to use toward qualifying wellness expenses. Quarterly team offsites.\nClosingYelp values diversity. We\u2019re proud to be an equal opportunity employer and consider qualified applicants without regard to race, color, religion, sex, national origin, ancestry, age, genetic information, sexual orientation, gender identity, marital or family status, veteran status, medical condition, disability, or any other protected status.Note: Yelp does not accept agency resumes. Please do not forward resumes to any recruiting alias or employee. Yelp is not responsible for any fees related to unsolicited resumes.Recruiting and Applicant Privacy Notice"}
{"job_title":"Senior Data Engineer","company_name":"LastPass","location":"Ireland (Remote)","job_link":"\/jobs\/view\/3778221469\/?eBP=CwEAAAGMPHlytdLYscxOIkd2i3__xywHrt0eELnKDYZ7JRswU3N7kWD9paArQyakw-oNf7KLzLVOUXx5Rk-PYcvRrV6GrzfV10h6D0ozt6q_5mQc0TBaG8jlADT_Dzltpg_CIPyUoOfnexhmVhYM_rWHcjAiHrTYXmdBIUVgyX4njub1TG4Yhz5cuSx1lLK71v_JdrkgesN0lusjKpxNyC8oP4GnogsbXn_Jg50gryDn5szeaRDjW-lWyBLO0sKpegVP7yvtS5nxJUHsTFLbjcVv9VmJOSjgYA7Mzx4bi6BMt4VlbubROhm75SPT96kVq1eElExIrlLzmZ0x96mIVJ2tn0DLljkQZVHXfaqJ-cUu9xFfysdQ4W4PK-BwdGTWcRWU&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=8K6lYaSswIKGC%2FUdOI4R1A%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3778221469","job_description":"About the job\n            \n \nLastPass, the #1 password leader, provides password and identity management solutions that are convenient, easy to manage, and effortless to use, helping more than 32 million users and 100,000 businesses organize and protect their online lives. As a pioneer in cloud security technology, LastPass provides award-winning password and identity management solutions that are convenient, effortless, and easy to manage. LastPass values users\u2019 privacy and security, so your sensitive information is always hidden \u2013 even from us.We welcome new ideas, support your growth, and recognize your value, if this aligns with what you are looking for in your next career move, Join UsLastPass is looking for a Senior Data Engineer:We are currently looking for an exceptionally talented Senior Data Engineer to join our Data Engineering (\"Big Data\") team. Our Data team is tasked with the responsibility of developing and maintaining a cutting-edge, highly scalable Data platform. You will engage with Data Scientists, Product Managers, Executives, and other key stakeholders in Budapest and the United States of America as a Software Engineer. In this role, you will apply your extensive knowledge, abilities, and experiences to decipher data needs and develop the systems and platform that enable insights to be unleashed. You will directly influence the insights utilized to create deliciously intelligent, tailored, and ground-breaking client experiences.If you are passionate about complex problem solving and motivated by scale, then this is the role for you!What are some of the exciting challenges you will be working on? Utilize your extensive knowledge of technology options, technology platforms, design processes, and approaches throughout all phases of the data warehouse lifecycle to create an integrated, high-quality solution that meets objectivesEnsure completeness and compatibility of the technical infrastructure required to support system performance, availability, and architecture requirementsDesign and plan for the integration for all data warehouse technical componentsProvide input and recommendations on technical issues to the teamResponsible for data design, data extracts and transformsDevelop implementation and operation support plansLead architecture design and implementation of next generation BI solutionBuild robust and scalable data integration (ETL) pipelines using AWS Services, Python and SparkMentor and develop other Junior Data EngineersBuild and deliver high quality data architecture to support Business Analysts, Data Scientists, and customer reporting needsInterface with other technology teams to extract, transform, and load data from a wide variety of data sourcesContinually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers\nWhat does it take to work at LastPass? Bachelor's degree in Computer Science required;Preferred 3+ years of relevant experience in one of the following areas: Big Data Engineering, Datawarehouse, Business Intelligence or Business AnalyticsHands-on experience in writing complex, highly optimized SQL queries across large data setsPrior experience working in a DataBricks environment is a plusDemonstrated strength in data modelling, ETL development, and Data WarehousingExperience with AWS services including S3, EMR, Kinesis and RDSExperience with big data stack of technologies, including Hadoop, HDFS, Hive, SparkExperience with delivering end-to-end projects independentlyKnowledge of distributed systems as it pertains to data storage and computingExceptional Problem solving and analytical skillsKnowledge of software engineering best practices across the development lifecycle; including, Agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations\nWhy LastPass? Market-leading password managerHigh-growth, collaborative environment with inclusive teamsRemote first cultureCompetitive compensationPrivate health insurance, dependents included. Monthly self-care days (12 extra paid days off annually), volunteering days, pet leaveHome office setup supportLastPass families free account up to 5 members Continuous learning and development opportunities \nIf this piques your interest, apply today and chat with our recruitment team further.We\u2019re building an inclusive community that reflects the people of all races, genders, sexual orientations, national origins, backgrounds, and perspectives who share our world.For all US based jobs please review our Applicant Privacy NoticeFor all EU based jobs please review our Candidate Privacy NoticePlease review our CCPA Notice"}
{"job_title":"Big Data Engineer (Scala & Spark) \u2013 Data Lake (Openbank)","company_name":"Openbank","location":"Spain (Remote)","job_link":"\/jobs\/view\/3766618250\/?eBP=CwEAAAGMPHlytSgoS8DjdSXewzHN9jLnizMQzeEw8S77rsu6lW7SbMkTYKFOH0__eD7L1z5Dh2K-HM4tN3dMBhCWpBzmavffVlj1fng3cAcQZCIe-26odjRlskQowCW3P0bNxt_iLZ-a8-6rSydKZAL7H3ckiPlpGnzhbNYRfiKpuHovYUgbeihf9kijjZyuJLaMMBWzXyy6Oa3xmuaWFDdOrve9DqcQ4oAH0Et9dyRXqcWd7f4N-oRvLNgWp7RyamvNUP5kkrQlnibBArg4s6AC_0WTiMc0KQ7zpiK6a6LR4cK8j2EonozYGSJLDea4golSHm4mN6-NizZOy4bVrvvhfwDg5LCBTtzFDy104egCGfoW-KMFXLbbA4ZTlYr8LCaL&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=wOo3gYUV77kleRChqpp%2FGw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3766618250","job_description":"About the job\n            \n \nOpenbank is in the middle of a digital transformation, working in startup format and innovating in core banking product development from within. We want to convey a whole new digital experience to our customers and for that reason we need the most skilled professionals to come and join us. Currently we are looking for Big Data Developers to make the team even stronger.Responsibilities: Design and implement production big data environments using modern technologies.Build, validate, and optimize large-scale, big data solutions in heterogeneous data environments.Develop and manage ETLs in batch (Spark and Scala) and streaming (Apache flink)\nTo be successful in the role you must have: 3+ years of experience working with Scala, Spark, software design patterns, and TDD.Experience working with big data - Spark is a must - Hadoop, Hive, and\/or Kafka would be a plus.Experience with different database structures, including SQL (Postgres, MySQL), and NOSQL (DynamoDB, DocumentDB, Redis, Elasticsearch).Experience and expertise across data integration and data management with high data volumes.Experience with Cloud ecosystems, AWS ecosystem (EMR, EC2, IAM, GLUE, ATHENA, S3,CloudFormation, LakeFormation, Redshift, DynamoDB, RDS, ECS & ECR) would be a great plus!Experience working in agile continuous integration\/DevOps paradigm and tool set (Git, Jenkins,Sonar, Nexus, Jira, and Splunk).Bachelor\u2019s Degree in Computer Science, Information Systems, Mathematics, or other STEM, and related fields, or equivalent work experience.Professional working proficiency in English.\nNice to have: Experience with data warehousing, apache iceberg, and visualisation tools.Experience with NRT applications: Apache Flink, spark streaming.\nWhat do we offer? Joining a dynamic and agile environment, with plenty of opportunities to grow, and have impact!We are a flexible and fast adapting team currently working remotely most of the time using all kinds of communication tools!Working in a start-up mode with the support of Santander Group in a growing and expansion project.Competitive remuneration and attractive benefits package.Collaboration in international projects with peers from all around the globe.Excellent work environment, social clubs, and frequent events.\nWe are the 100% digital bank of the Santander Group, and we are currently undergoing a technological transformation and international expansion process. In 2017, we kicked off our relaunch plans and have been continuously expanding and growing ever since, especially when it comes to technology. We work in a start-up format, using agile methodologies to take our customers' experience to the next level. In 2019, we launched in the Netherlands, Germany, and Portugal, recently followed by Argentina, with other countries currently in the pipeline.Our culture sets us apart from the rest; social and diversity clubs are part of our essence and day-to-day culture.Openbank is an equal opportunity employer. All applicants will be considered as equal without paying attention to gender identity, sexual orientation, ethnicity, religion, age, political orientation, union membership nor disability status. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify and build.If you\u00b4re not currently living in Madrid or Valencia and you are open to relocate yourself, we would still love to consider your application"}
{"job_title":"Data Engineer","company_name":"Randstad Sourceright","location":"Warsaw, Mazowieckie, Poland (Remote)","job_link":"\/jobs\/view\/3703082062\/?eBP=JOB_SEARCH_ORGANIC&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=orvSWic61JVk7LI7P%2F0TLg%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3703082062","job_description":"About the job\n            \n \nNess Digital Engineering, a global software company is now expanding in EMEA. We are looking for experienced Data Engineer to join our Scrum team.What we are looking for? Experience running ETL process for data manipulation \/ Pentaho Data IntegrationProficiency in using Unix tools (SFTP, crontab, etc)Proficient in SQL, MySQLData-manipulation experienceMetabase\/Tableau experienceGood communication skills will help you to succeed \u2013 part of the job is to collaborate cross-functionally\nHow do we work? If you join our team, you will be working alongside a group of talented software developers and testers. We are fortunate enough to work with creative UI\/UX designers, expert DevOps Engineers, Cloud enthusiasts, well trained Scrum Masters and great Product Owners.Agile is the way \u2013 and we wouldn't do it any other way. We understand the advantages of Scrum\/SAFE principles and we like to keep things effective and flexible.Would you like to know more? Contact us and we can make it happen.\nWhat we offer? work in a experienced Scrum team100% remote workcompensation 17k - 20k on B2B"}
{"job_title":"Junior Java Developer","company_name":"Luxoft Romania","location":"Cluj-Napoca Metropolitan Area (Remote)","job_link":"\/jobs\/view\/3771908519\/?eBP=CwEAAAGMPHlytVB5wuBak4lcuNifT3n2dxqu5kq19I8RNvVg9k_1wXOX-VeQd-kLHaLj-wPqh4ImTht7eMn90_m9mp31KRXLBb3yfLGLLxvg77APu-iK5eta_t9kukH-q3nLI_S5_H49TyyoYixSH8mgokOABxoYegL1JQ0eqb-dHOjuVUzUYmha-p1yFHAX8vX1oSwIZHuPd2VyzpgqquIpN-84ILfyZO9Tn5HazRowdNu5OobOCuK5zLuc52d9Ot7OP8dCRkTUNmGwlvWeQ5l14Zz_nVc0mRtV6LkZJuzJZ8qKQIva4ncwlZMeS30g3kQt87UnlboXSXmpzsUNDQBx7HDfj7AXxeZDAoHLBa0B7IZi0P5w4LU6dYRcw1Avhnv5&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=ynY4ZyuJNApeA0PSPl2wZQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3771908519","job_description":"About the job\n            \n \nProject Description:The project is a rapidly growing engagement with a solid leader in the FinTech industry developing software solutions for trading, risk management and data processing. Join our Development Center in Luxoft Romania and become a member of our open minded, progressive and professional team. The software development is based on SAFe\/Scrum methodology and uses Continuous Integration\/Continuous Deployment processes supported by the adoption of DevOps, best engineering principles and XP practices like TDD and BDD. You will have a chance to grow your technical and soft skills, grow professionally and build a thorough expertise of the industry of our client. On top of attractive salary and benefits package, Luxoft will invest into your professional training including business domain knowledge, and allow you to grow your professional career.Our client software platform is used by the world's leading investment banks, asset managers, hedge funds, commodity houses and corporations to price, analyze and manage their derivative exposures for foreign exchange, interest rate, equity, commodity, inflation and credit derivatives.How we work: - The development processes are completely Agile. We are implementing SAFe, the most widely used scaling agile framework- You will be deeply involved in controlling the development workflow by defining, planning, building, testing and deploying the new solution functionalities- Once every 10 weeks the new business requirements are provided by the clients and development teams clarify, estimate and plan the work needed for the next period- Our strong focus is on building high quality software by investing in Continuous Integration, Continuous Deployment, multi-tier testing, code quality, Non Functional Requirements etc.- The results of your work will be used by the most important organizations in the Investment Banking industry- Every 4 Sprints you will have the chance to work on completely innovative ideas using any cutting edge technologies or frameworks for a whole Sprint- We are investing constantly in your professional, business domain and personal development by offering career path guidance and access to a wide variety of trainings.- You will be supported by our technical mentors, agile coaches, pair working with your colleagues and will benefit on a friendly atmosphere and a dedicated space for games and relaxationResponsibilities:The candidate will work in development team closely with the Paris and Bucharest consultancy teams to develop new functionality, rapidly solve problems and enhance existing aspects of the application.The main purpose is to develop applications in order to integrate with external financial providers and platforms and to model the functional flows involved in the communication between the Client's solution and these external systems.There might be cases when the candidate might go to Paris to work on-site or for training for 1-2 weeks period.Mandatory Skills Description:- Mandatory Computer Science Faculty \/ Cybernetics \/ Mathematics \/ Informatics graduated- Min 1 Years working hands on experience in Java- Java 8- Dependency Injection\/ Inversion of Control (Spring or JBoss)- Unit and Mock Testing (JUnit, Mockito, Arquillian, Cucumber)- Java Message Service (JMS)- Web Services (JAX-RS, JAX-WS)- Strong understanding of Design and Architectural Patterns- Apache Maven- Continuous Integration tools (Jenkins or similar)- Linux operating system- Stash: GIT Repository Management- Spoken English language is a mustLanguages:\u2022 English: B2 Upper Intermediate"}
{"job_title":"Java Software Engineer","company_name":"Capgemini","location":"Spain (Remote)","job_link":"\/jobs\/view\/3765754815\/?eBP=CwEAAAGMPHlytXAu4StMop5MhV9NYeRzUeNXzlaY1PHWVT9XPfTaJWVYCW-zmGHfWxa56Xm41O1MTBM00yqe0qO8A2RZO4nvTVrRn-f6TKwn4364ykm8hEVfN9K1-N9HU330HeTENA00gBQcqu8fIgjITeQry23atfKdMi-PVV3Duq6yda2tKCR9dwgMdeNUAOnMDGI0wuAoDTq3ZA08lW0T6D1nSv_HZf6ZkbvTE3ZvWe3DHzgm4HAB_FqsHpsk3yinp4Lj0SVsQw5EaKgnjBopgg803yAMmgv5U-pxqSwVE-xYj0OuHiUraeNePzM9EO-_KSkZIaCgF7c668ENyKtfep83kjoxRjBOekvo_0tDzeZordkHGuai6xkHyp2dYWPW&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=ZTk3pvAu1aOSm4c%2FoWcBDQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3765754815","job_description":"About the job\n            \n \n\u00a1Hola! Somos CAPGEMINITenemos la gran suerte de trabajar en un sector que lidera la evoluci\u00f3n hacia un futuro sostenible e inclusivo. La TECNOLOG\u00cdA. El catalizador de tantas soluciones que necesitamos ahora m\u00e1s que nunca.Somos 350.000 PERSONAS en todo el mundo unidas por una misma pasi\u00f3n.No importa d\u00f3nde estemos, podemos estar en casa, en la oficina, a mil quil\u00f3metros de distancia unxs de otrxs, pero somos conscientes de que NUESTRO TRABAJO CUENTA.No importa en qu\u00e9 momento vital estemos, somos DIVERSOS en edad, g\u00e9nero, ascendencia, familia... \u00a1nos hemos certificado en Diversidad y como empresa \u00c9TICA m\u00e1s de 9 a\u00f1os seguidos!No importa si tu fase es de crecimiento, APRENDIENDO y FORM\u00c1NDOTE a todas horas o si necesitas consolidarte y aprecias la FLEXIBILIDAD, la CONCILIACION y los BENEFICIOS fiscales y sociales para compaginar tu vida personal y profesional. Lo que importa es que puedes sentir que est\u00e1s DONDE DEBES ESTAR para conseguir el futuro que deseas.Buscamos un\/a profesional con m\u00e1s de 4 a\u00f1os de experiencia en Java y dominio del framework Spring y Spring Batch.Consideramos la responsabilidad, el compromiso y el trabajo en equipo.Conocimientos en: JavaSpring BatchSpringSQLOracle\nValoramos experiencia en: Automatizaci\u00f3n de pruebas y calidad del c\u00f3digo Definici\u00f3n y ejecuci\u00f3n de pruebas para garantizar la calidad del software Entendimiento de los procesos de la aplicaci\u00f3n estimaci\u00f3n del desarrollo evolutivo Optimizaci\u00f3n de procesos y consultasMetodolog\u00edas \u00c1giles, Scrum o SAFE\nLa colaboraci\u00f3n es clave en el desarrollo de nuevas ideas, de nuevas soluciones, del crecimiento profesional y personal y por eso para nosotrxs es vital el equipo y el buen clima. Trabajamos y potenciamos nuestras COMUNIDADES dentro de la compa\u00f1\u00eda.Tenemos un CATALOGO DE MEDIDAS de desarrollo y conciliaci\u00f3n muy completo (ayudas familiares, seguros y tickets, d\u00edas festivos adicionales de tiempo para ti y lxs tuyxs, etc...) \u00bfNos vemos y te lo contamos?Ma\u00f1ana saldr\u00e1n otros proyectos porque as\u00ed trabajamos, generando, junto a nuestros partners, las soluciones a medida que nuestros clientes necesitan. \u00bfTe unes a nuestro equipo?"}
{"job_title":"Linux Cloud DevOps Engineer","company_name":"HCLTech","location":"Romania (Remote)","job_link":"\/jobs\/view\/3774168015\/?eBP=CwEAAAGMPHlytRhUJVE2a8TXjshXEWzyvo4_0Nqi_x9mFERse3nxSBY_hP-9C0gRIl3hPTbRM0FuscEFHL7cGwRgr_Se_guBqfAUyqeLAyH816HkiqOuesqaj9WD7G_AZuWaE3s3dez9AKtCyLRX0mxERmDtOLIgyssqGFWF2e3-FdCXuajDMK2l_M_v8abpY5Hm_4zum_mS6sc0CF_jCu22Obv_xjN5AnQLMH_6pboEzmDIdpObLsEqlo4nvbbcCvUB5psvV5L2oP4Zo3gexttjwOON79qEeMGOYifBi0REI5rZ6LZVjrjA-3DlNTDHGC8Y-Ot5bgzPzVRrVLhCY32PDrjRNq6T7T27Fh6HKaPJQ7ANP9tRV-jZENz6WtHxYqsn&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=UzD2nNJUGc%2BjLnpTAEB1GA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3774168015","job_description":"About the job\n            \n \nWe are HCLTech, one of the fastest-growing large tech companies in the world and home to 225,000+ people across 60 countries, supercharging progress through industry-leading capabilities centered around Digital, Engineering and Cloud. The driving force behind that work, our people, are diverse, creative, and passionate, raising the bar for excellence on a regular basis. We, in turn, work hard to bring out the best in them as we strive to help them find their spark and become the best version of themselves that they can be.The ideal candidate will have experience in Azure, Linux, Ansible, Terraform, Python, and container solutions such as Kubernetes.This person should be security minded, have experience with CI\/CD toolset, possess good analytical and problem-solving skills, and be able to work in a fast-paced and ever-changing environment. Additionally, this person should have experience with Agile development, SCRUM or SRE concepts, and be willing to work standby duty.Responsibilities:- Collaborate with development, security, and infrastructure teams to ensure smooth integration and delivery of products;- Create and maintain automated pipelines for software releases using CI\/CD tools such as Jenkins and GitHub Actions;- Develop and maintain infrastructure as code using Terraform, Ansible, and Python automation tools;- Manage and maintain container solutions such as Kubernetes and Openshift;- Ensure compliance with security protocols and standards;- Provide technical guidance and mentorship to junior team members;- Keep up to date with emerging trends and technologies in DevOps, and make recommendations for improvement.Qualifications:- Azure Associate certification or equivalent knowledge level;- Linux (RHEL and\/or SLES) and Ansible certification;- Experience with Terraform, Python, and Ansible Automation Platform is mandatory;- Experience with at least one of the following; Prometheus, Redhat IPA, and Openshift\/Kubernetes or other Container solutions;- Experience in leadership;- Understanding of CI\/CD concepts and toolset (i.e., Jenkins, GitHub Actions);- Adaptable to work in a varied, fast-paced, ever-changing environment;- Good analytical and problem-solving skills to resolve technical issues;- Eager to learn and adapt to a constantly changing environment;- Understanding of Agile development, SCRUM, or SRE concepts is a plus;- Willing to run standby duty;- Able to function autonomously while adding to a collaborative team-spirit.What we can offer:- Global careers and mobility;- A flexible (remote) working environment with work-life balance';- Great opportunities to make the role your own, upskill yourself and get involved with exciting projects.Besides all above, we offer support, a great team to work with and massive exposure to career growth and new technologies!HCLTech is committed to protecting and securing the privacy and confidentiality of the Personal Data which it collects directly or indirectly from you when applying for a job at HCLTech either directly or through a third-party human resources agency. This notice (the \u201cNotice\u201d) outlines and explains how HCL Technologies Limited including its subsidiaries, local employing entities, associates, and affiliated companies [collectively referred to as \u201cHCLTech\u201d, \u201cus,\u201d \u201cour\u201d, or \u201cwe\u201d] will process your Personal Data in accordance with applicable privacy legislation(s).https:\/\/www.hcltech.com\/candidate-privacy-notice"}
{"job_title":"Cloud Operations Engineer","company_name":"Annapurna","location":"European Union (Remote)","job_link":"\/jobs\/view\/3766685975\/?eBP=CwEAAAGMPHlytdF_goujeG2QHWFRKS6OWQ0lr0423Svdm0N4qC9G-ht43QeQpXxKKtBhNUkfjgwjM1tecijLvDFj5KIPYMUHwR3ZkxnVtXG95En_OEsJYQAREILnc0lDVxnr4bAb9EhIRDiSQF0wt2uumO1Fl39iz80dSRRHaL_UBzEjzT8peJAynl_sj7U0BuAtcijkVp-WnHtZnGyBVMMxF_6vPkf-IolKmphhz6p6sAAAhABR093EcM2hqlW0RfI6aobxhI3o6YQzJJZvFJCwi7aQe78RiKz6X0nQb5FtxSPbeNQ2ncV6RjTm01xkIWVl6OdGz9ZXLZfcfMQGF3rQRqfaBdQ6N-M3ge9kLyPyR_Agk_n_9-WsMGdW52b26KdSZWY&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=IhzsHi0aqWrGzanX4nAiwA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3766685975","job_description":"About the job\n            \n \nPosition Title: Cloud Operations EngineerEmployment Type: Full-Time, RemoteCompany Overview:Our organization specializes in providing innovative Digital solutions for various industries, including fashion, retail, footwear, luxury, outdoor, and consumer goods.Job Summary:We are seeking an experienced Cloud Operations Engineer to contribute to the ongoing success of our cloud-based applications. In this role, you will work remotely, supporting our customers and ensuring the robustness and scalability of our cloud platform. Reporting to the Senior Director, you will play a crucial part in maintaining a highly available infrastructure for our flagship product on our cloud application.This is not a pure engineering role but instead a strategic position which enables you to work in a cross-functional environment, have a hands-on impact on the direction of our cloud services and work with a global team in an innovative, fast-paced environment. Location: Remote, European Union Responsibilities: Oversee and maintain cloud infrastructure on diverse platforms such as AWS, Azure, or Google Cloud.Monitor cloud resources for availability and scalability, optimizing resource utilization.Respond to and resolve time-sensitive customer issues in the public cloud.Troubleshoot incidents and issues related to cloud infrastructure.Execute customer deployments, migrations, and upgrades within the cloud environment.Support automation initiatives, employing infrastructure as code (IaC) for resource provisioning and scaling.Ensure adherence to security best practices and implement measures to secure customer data.Conduct database operations, including backup and restores.Collaborate with development, devops, and support teams for deploying and managing cloud-based applications.Create and update documentation for cloud infrastructure and processes.Stay informed about cloud technology trends and best practices.Propose and implement improvements to cloud operations processes.\nQualifications: Bachelor\u2019s Degree in Computer Science, MIS, or a related technology field, or equivalent practical experience.8+ years of experience in cloud operations and infrastructure management across AWS, Azure, or Google Cloud.5+ years in incident response and major incident management.Proficient in Linux and Windows environments.Certification in AWS, Azure, or Google Cloud is advantageous.Solid understanding of Cloud networking and security.Strong scripting and automation skills (e.g., Python, Powershell).Proficiency in infrastructure as code (IaC) and configuration management tools (e.g., Terraform, Ansible).Expertise in containerization and orchestration technologies (e.g., Docker, Kubernetes, Rancher).Experience with version control, CI, and automation tools (e.g., Github\/Bitbucket, Github Actions, Jenkins, Rundeck).Deployment and troubleshooting experience with Java-based applications and microservices.Deployment, configuration, and troubleshooting experience with Database technologies like MSSQL, PostgreSQL, and MongoDB.Familiarity with monitoring and logging tools (e.g., Nagios, Prometheus, ELK stack).Experience with technologies such as Virtualization, VPN, RDP, SSO, Kafka.Familiarity with Confluence\/Jira.\nWhat We Offer: Competitive salary and benefits.A high degree of responsibility and a broad spectrum of opportunities.Remote work opportunities with a dedicated and motivated team.A collaborative, flexible, and respectful remote work environment.Varied and challenging work to help you grow your technical skillset.\nPlease get in touch to find out more!"}
{"job_title":"Desarrollador PL\/SQL","company_name":"C\u00edvica","location":"Madrid, Community of Madrid, Spain (Remote)","job_link":"\/jobs\/view\/3779439540\/?eBP=CwEAAAGMPHlytSuBOBfxAPoDTuJ4aUS5WREGVKHzHYbJtCaHuoUu_ukhL-7lftDlK4qjYlXQhFGHzFQBcW6MCMvezjlDm4W_rBz-qX77UyR_D9vxWZkNcDGYYf-ebFM3YRSrIug84PJAFc8hOeAaQfwVsXiFCnRrzRAf-3KAs9ZIzYaeoabVpK1yX1BLEh3TiYhl1WoIbKrTRd2-w4rLR_RBeP6qJU-6sRivELsXLRUIOWnDOxvdyjM2c9p1Q39yR9Gc1MP6wMhIjI1QSXxTUUc115JMuKQRnS0rSYf_deIi3tQqVpVeC5JgG02bXDeNe6uiT2GP0kgI3xVuHEHF7t2Po9cJzbUYeOgu1CWtZMF1XQGGM18Cdi2ZDpHELKvBJjpS&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=J7LqhQ%2BPeltnPhsyPOgTfw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3779439540","job_description":"About the job\n            \n \n\u00bfEres desarrollador?En C\u00edvica seguimos creciendo y para afrontarlo necesitamos contar con profesionales como t\u00fa en nuestro equipo.Podr\u00e1s encontrar una empresa comprometida con el desarrollo y crecimiento profesional, apostando por la formaci\u00f3n, el seguimiento y acompa\u00f1amiento continuo.Actualmente estamos buscando varios perfiles. Echa un vistazo a este:\u00bfQu\u00e9 buscamos?\u27a4 Experiencia m\u00ednima 2 a\u00f1os en programaci\u00f3n con PL\/SQL.\u27a4 Buenas dotes de comunicaci\u00f3n. Interlocuci\u00f3n con cliente.\u00bfQu\u00e9 ofrecemos?\u27a4 Teletrabajo 3 d\u00edas + Presencial 2 d\u00edas.\u27a4 Granada o Madrid (zona norte).\u27a4 Buen ambiente laboral.\u27a4 Vacaciones de 23 a 30 d\u00edas laborables (seg\u00fan antig\u00fcedad).\u27a4 Tendr\u00e1s un amplio cat\u00e1logo formativo a tu disposici\u00f3n, as\u00ed como descuentos para empleados.\u27a4 Disfrutar\u00e1s de diferentes eventos y actividades.\u27a4 Plan de retribuci\u00f3n flexible.\u27a4 Te facilitaremos todo el equipo de trabajo para que puedas trabajar c\u00f3modamente (equipo, perif\u00e9ricos, silla, etc);REQUISITOS M\u00cdNIMOS:Experiencia m\u00ednima 2 a\u00f1os en programaci\u00f3n con PL\/SQL."}
{"job_title":"Crypto Data Engineer Intern (Hungary-Remote)","company_name":"Token Metrics","location":"Budapest, Budapest, Hungary (Remote)","job_link":"\/jobs\/view\/3744909569\/?eBP=JOB_SEARCH_ORGANIC&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=VaOQA8XH6TUPS8b5DAEJYg%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3744909569","job_description":"About the job\n            \n \nToken Metrics is seeking a multi-talented Big Data Engineer intern to facilitate the operations of our Data Scientists and Engineering team. The Big Data Engineer intern will be responsible to employ various tools and techniques to construct frameworks that prepare information using SQL, Python, R, Java, and C++. The Big Data Engineer intern will be responsible for employing machine learning techniques to create and sustain structures that allow for the analysis of data while remaining familiar with dominant programming and deployment strategies in the field. During various aspects of this process, you should collaborate with coworkers to ensure that your approach meets the needs of each project.The duration of the Token Metrics internship program is 3 months. It is an evaluative unpaid internship with the possibility of return offers, depending on the company's needs.Responsibilities Compile and analyze data, processes, and codes to troubleshoot problems and identify areas for improvementCollaborating with the front-end developers and other team members to establish objectives and design more functional, cohesive codes to enhance the user experienceDeveloping ideas for new programs, products, or features by monitoring industry developments and trendsRecording data and reporting it to proper parties, such as clients or leadershipParticipating in continuing education and training to remain current on best practices, learn new programming languages, and better assist other team membersTaking lead on projects, as needed\nRequirements Bachelor\u2019s degree in computer programming, computer science, or a related fieldMore education or experience may be requiredFluency or understanding of specific languages, such as Java, PHP, or Python, and operating systems may be requiredStrong understanding of the web development cycle and programming techniques and toolsFocus on efficiency, user experience, and process improvementExcellent project and time management skillsStrong problem solving and verbal and written communication skillsAbility to work independently or with a group\nAbout Token MetricsToken Metrics helps crypto investors build profitable portfolios using artificial intelligence-based crypto indices, rankings, and price predictions.Token Metrics has a diverse set of customers, from retail investors and traders to crypto fund managers, in more than 50 countries."}
{"job_title":"Consultor Cloud","company_name":"Aderen","location":"Spain (Remote)","job_link":"\/jobs\/view\/3770642883\/?eBP=CwEAAAGMPHlytdNxptkHWe2N3c7-3dbGXhfpMhWuYGueMTFloGmp45YUT0F57EItvzUBsZhBo-JgKKO2CSUgtw8UHu7A36N0W6ZRsNghrd0APpEHKQNCVpXFSiD2WqpEzLCItdAGvhdi7fC7SKkxDBLv3y74WWKzN-aNrUm2U9gT1vFhRAdG6P-YkJYn92xjU7BvAKdJPk1V1s47vn0nX1eP6JwCpiVeWBdOghgxXiUqmdRI7gm5TLka5u-vSJgKOUIwAPc6aDtMAImgGD29IPDJWZBxE_EN3n-uA4hUSDfy5G4CO9brNGkMfK_ybdW7CCAdU_oA_dwQWMZoD73m9cJBX8WckJ6fO0RPbEz9AxlWsBn7GIHkTKO7YUw0goyNGr9p&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=rwwQt4zZSl5uG0UHfepurA%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3770642883","job_description":"About the job\n            \n \nSeleccionamos Consultor Cloud para participar en proyectos de transformaci\u00f3n en cliente l\u00edderDescripci\u00f3n General del Puesto: Se incorporar\u00e1 a un Centro de Excelencia Cloud realizando funciones relacionadas principalmente con el track de arquitectura.Objetivo del Rol: Asistir en el dise\u00f1o, implementaci\u00f3n y gesti\u00f3n de soluciones en la nube, asegurando que cumplan con las necesidades del cliente y los est\u00e1ndares de seguridad y eficiencia, desde un punto de vista tecnol\u00f3gico pero a nivel arquitectura, no ingenier\u00eda, no se realizar\u00e1n en general implementaciones.\nConocimientos y Habilidades T\u00e9cnicas: Fundamentos de la Nube: Comprensi\u00f3n de servicios en la nube, preferiblemente en plataformas como Azure, GCP y OCI.Infraestructura y Servicios: Conocimiento de infraestructura como servicio (IaaS), plataforma como servicio (PaaS) y software como servicio (SaaS).Arquitectura de Soluciones: Capacidad para colaborar en el dise\u00f1o de arquitecturas de soluciones en la nube, teniendo en cuenta la escalabilidad, la disponibilidad y la seguridad.Automatizaci\u00f3n y Orquestaci\u00f3n: Familiaridad con herramientas de automatizaci\u00f3n y orquestaci\u00f3n para despliegues eficientes y gesti\u00f3n de infraestructura.\nHabilidades Generales y Competencias: Habilidades Anal\u00edticas: Capacidad para analizar requerimientos y proponer soluciones efectivas.Comunicaci\u00f3n: Habilidades para comunicarse efectivamente con otros miembros del equipo y stakeholders.Aprendizaje Continuo: Disposici\u00f3n para aprender y adaptarse a nuevas tecnolog\u00edas y tendencias en la nube.Trabajo en Equipo: Colaboraci\u00f3n efectiva en un entorno de equipo.\nOfrecemos: Contrato en modalidad Freelance Full timeTarifa: 240-260\u20ac jornada + IVA en funci\u00f3n de experiencia aportadaProyecto de Larga Duraci\u00f3n. Recurrencia en ProyectosLocalizaci\u00f3n: RemotoIncorporaci\u00f3n: ASAP"}
{"job_title":"Software Engineer","company_name":"Noir","location":"Munich, Bavaria, Germany (Remote)","job_link":"\/jobs\/view\/3778541918\/?eBP=CwEAAAGMPHlytaV_Zw1aiFekLxkw-lrQ_A7Lzj7eclhJuEe00OalQIlvyGu78doQAFJmpaJ4Om1mY2UAoyRzsB9KBb8VSZyjl6s-TBKlYtRQLf79fYPtA0Vs7I1ITmOnHVpvdReLZsrLK0AThtmaTsX1NGYvPkWntMkoKJX8zXXrsyrDD35IiHDqECLx4Pxw5wKw9CPngbVvh0KmIi_eSaMUq_fYsEyfbDXW_vIJyq4pFEnBaUVphhAAI1J8dpbEtAQ-mL6xI4MHqI8sIbV4V0IzecIRdG6eEpjjKC2HasUz5UICGCXi4zdhqhUQZNo2dOsayd9wPFraoUhp7NgCulPwR-VU6iACW_Po0CBuVKmW-2n5Uf0b4bmIEZt-Oi7PSl65&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=rGsbOcAUfrc3DdHOYLeQKg%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3778541918","job_description":"About the job\n            \n \n.NET Software Engineer \u2013 .NET 7, C#, Blazor, Azure \u2013 Munich, Germany(Tech stack: .NET Software Engineer, .NET 7, C#, Blazor, Azure, JavaScript, HTML5, CSS3, Agile, Programmer, Full Stack Developer, Architect, Softwareentwickler, Entwickler, .NET Software Engineer)Our client is a crowd funded social advertising technology platform that sells services to Facebook advertisers to grow their marketing ROI. They were recently named one of 12 Facebook Strategic Preferred Marketing Developers (PMD); the highest distinction of excellence Facebook has ever offered their marketing partners. They have already grown by 100% in the past 6 months and have ambitions to quadruple headcount over the next 2 years.We are seeking multiple gifted .NET Software Engineer who have a genuine passion for developing revolutionary software solutions. .NET Software Engineer applicants should have a skill set that includes: .NET, .NET Core \/ ASP.NET MVC, C# and SQL Server. Full training will be provided into: .NET 7, Blazor, EF Core, Azure, JavaScript, HTML5, CSS3, Agile, TDD, BDD, Azure SQL and SQL Server 2022.This is an amazing opportunity to join a firm that has revolutionized its industry and to work on groundbreaking software development projects!Location: Munich, Germany \/ Remote WorkingSalary: \u20ac55.000 - \u20ac75.000 + Bonus + BenefitsNoir continues to be the leading Microsoft recruitment agency; we can help you make the right career decisions!NOIRGERMANYRECNOIREUROPERECNC\/BK\/MUN5575"}
{"job_title":"Senior Java Software Engineer","company_name":"Capgemini Engineering","location":"Romania (Remote)","job_link":"\/jobs\/view\/3774191051\/?eBP=CwEAAAGMPHlytaLG6BS7DcmG1m6VhjmZnpdMLgLJG_JW54gHI_5MuxLk1QeD7tFLGqV9crrUeHjQmykLtT6snYmQ4ntOdBsgXrHTMm3b9ETZaRRFPgGMisTzw9gp_sMzVUHDtmvqgFsVABi9EZGzfC1SFzuUq1_WCA6SBHMvfwJM_aUqrarXWiA8wW06jf6g1jxWqX9yfFUhFRtPNuba557CA0IZ4D8MLlE43fBGex9X1CP7mbvRRMbhKVNSuPscSGnshkfGZOZ_UiwgS27kXIzKs1ynBQ9XkQkxWVd0_UKgUIzkSGqsOrO4KDAUw-Vs9Sk37L6jw9fcFmLNePaiIEhJJ-LqgqHnsr654dZtRWU5SrwD5CqFqtAUSWTdOseRE73W&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=Yw5cTuHHLA6pkx5Lhx11Iw%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3774191051","job_description":"About the job\n            \n \nOur client is a multinational manufacturing corporation with a core activity in the production, distribution and sale of trucks(one of the largest manufacturers of heavy-duty trucks in the world), buses, cars and construction equipment, they also supply marine and industrial drive systems and financial services. They are growing and are looking for a strong Senior Engineer to join our Romania team on the following project:Data enablement is a proactive approach to managing data that utilizes defined and enforced policies to ensure data accuracy and accessibility. This approach utilizes real-time automation for data validation, classification, and management, providing complete visibility into data lineage and associated metadata. The implementation of a comprehensive and searchable data catalog, which is updated in real-time, enables self-service data access and discovery. The current project aims to optimize data accessibility by reading data from a legacy system, storing it in a database, and caching it for faster user access.Requirements (required)\u2022 5+ years developing with Java 8 or later\u2022 Good understanding and hands-on experience with microservice architecture\u2022 Spring\u2022 Experience with message queues (Kafka, RabbitMQ or similar)\u2022 SQL\\NoSQL Databases (MySQL, MongoDB, Tablestorage, etc)\u2022 Research, evaluate, estimate, and implement technical solutions for business requirements\u2022 Suggest technical and functional improvements to add value to the product\u2022 Participate in architecture and design sessions on a regular basis\u2022 Good communication skills\u2022 Self-driven, self-organizedRequirements (optional)\u2022 Experience in work with data of people\/human resources\u2022 Experience in the automotive domain"}
{"job_title":"Software Development Engineer","company_name":"Yahoo","location":"Ireland (Remote)","job_link":"\/jobs\/view\/3779505571\/?eBP=CwEAAAGMPHlytRr3YlQv2psW7ql7Piwc-mT3NzNTkiFFNsWwpmafgNk1sruvWzwyhGXczqH9VLLUP_fy0zjCX0xWhab55UncirX-RG3o9NvBZFS8aTOtzt74e9QBbdtgQBl04GhW-Cvw12y6w0OD6bQnqmIwag9HwG_jrKXaZ_tR1DhDJqEcmEZkFGw7rieSMVsBxG0CF21v4vKJjBwVzWALcMm3GPCNNcthYXb5fHNsGZSUgM35Nhu7XFfrlQb8OVdhpNfrAWvEfjC7EQKjvPp7zQ62pIE2JJQE4ZcrcF-MQgZp6owmmZjkklsCskiJTOY9gtrUCDtjIf-pttq5NEMSliiGboXipJfaLtY6dqSt7eG3ajF4-qLIdbmnojDGfU_s&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=%2FLTvND%2FVk66bzWik%2FNfWlQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3779505571","job_description":"About the job\n            \n \nIt takes powerful technology to connect our brands and partners with an audience of nearly 900 million. Whether you\u2019re looking to write mobile app code, engineer the servers behind our massive ad tech stacks, or develop algorithms to help us process trillions of data points a day, what you do here will have a huge impact on our business\u2014and the world. Want in?A Little About UsYahoo is a global media and tech company that connects people to their passions. We reach nearly 900M people around the world, bringing them closer to what they love\u2014from finance and sports, to shopping, gaming and news\u2014with the trusted products, content and tech that fuel their day. For partners, we provide a full-stack platform for businesses to amplify growth and drive more meaningful connections across advertising, search and media.At Yahoo News, we are laser-focused on making discovery delightful and becoming the world\u2019s best curator for our 35 million daily users and expanding our distribution to more platforms to meet millions more users where they are. Building the best guide to the Internet (and the world) requires building the best team.Who You Are You excel at explaining technical concepts to anyone and everyone. People enjoy collaborating with you.You have a bias for action. When you see problems, you solve them.You are extremely curious. You are constantly interested in how the software you interact with works \u201cunder the hood.\u201dYou are customer-focused \u2013 regardless of whether the customer is an external user or an internal team.You know that writing code isn\u2019t the end of the process, and you delight in understanding how that code is running in production, looking at metrics, and planning improvements\nResponsibilities Hands-on development of next-generation features for Yahoo! News.Help to scope, plan, and implement best-in-class software practices, procedures, and delivery.Contribute to implementation guidelines and execution strategy for your team\u2019s goals.Collaborate with your peers, product managers, and engineering leaders on new features and enhancements.\nQualifications BS, MS, PhD in Computer Science or a related major, or equivalent experience4+ years of real-world experience with a focus on front-end web and middle-tier service developmentGood knowledge of Web standards and modern full-stack web frameworks, like NextJS, Nuxt, SvelteKit or similar technologiesKnowledge of modern CI\/CD systems and methodologies Predisposition towards testing, instrumentation, and documentation.Experience looking at web performance fundamentals, like First Contentful Paint or Cumulative Layout Shift, and optimising to make the best experience possible for users regardless of browser or internet speed\nYahoo is proud to be an equal opportunity workplace. All qualified applicants will receive consideration for employment without regard to, and will not be discriminated against based on age, race, gender, color, religion, national origin, sexual orientation, gender identity, veteran status, disability or any other protected category. Yahoo is dedicated to providing an accessible environment for all candidates during the application process and for employees during their employment. If you need accessibility assistance and\/or a reasonable accommodation due to a disability, please submit a request via the Accommodation Request Form (www.yahooinc.com\/careers\/contact-us.html) or call 408-336-1409. Requests and calls received for non-disability related issues, such as following up on an application, will not receive a response.Yahoo has a high degree of flexibility around employee location and hybrid working. In fact, our flexible-hybrid approach to work is one of the things our employees rave about. Most roles don\u2019t require specific regular patterns of in-person office attendance. If you join Yahoo, you may be asked to attend (or travel to attend) on-site work sessions, team-building, or other in-person events. When these occur, you\u2019ll be given notice to make arrangements.If you\u2019re curious about how this factors into this role, please discuss with the recruiter.Currently work for Yahoo? Please apply on our internal career site."}
{"job_title":"Programador\/a Java Freelance","company_name":"Hays","location":"Spain (Remote)","job_link":"\/jobs\/view\/3778564904\/?eBP=CwEAAAGMPHlytUJ0ww8EmdjI9AYPyim7oGwnSg5HBHFyVPSL5FA5GkJga8DO2caqDIGPvXLW4DT-G-kzIuDjf_qf70Tkis3PgJnQpKguy37fo64IQm6bQGQL43IPUljt08x3rhXFift4EET_pKS53-6Wub1jU9Yy4jdXTV09yhWHYjglLSXmMdfEDw7spKCPkIbmS6o2eyebQLVyvF8JowsNPCTYQTeq9pcanYgooqaIJ21vB7pVrucHak47knIO9ImtBQdfkRQpuzttu83wX0DiPivIGcsHaBGXIHHhl5uwFRd5zg4JVuVlRMDbicbNyJgDdjDeLi-F9DtJ27dSYYyQcW8b2kuV3t-U5HKWqfQPHA1pAFD5tAjSpleXQ0KgnSIh&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=V0yjhx0YTRm8QwWgtqVeeQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3778564904","job_description":"About the job\n            \n \nEn Hays estamos colaborando con una compa\u00f1\u00eda que necesita llevar el desarrollo evolutivo y mantenimiento de una aplicaci\u00f3n para una empresa de lavander\u00eda a domicilio. El cliente est\u00e1 ubicado en Estados Unidos por lo que necesita un nivel suficiente de ingl\u00e9s como para mantener reuniones de seguimiento y mantener las comunicaciones escritas.Actualmente buscamos un\/a Programador\/a JAVA Freelance para colaborar con su departamento de ingenier\u00eda.\u00bfCu\u00e1les ser\u00e1n tus funciones? Participar en el dise\u00f1o, desarrollo, implementaci\u00f3n y mantenimiento evolutivo de la aplicaci\u00f3n.Colaborar con los equipos de desarrollo y negocio para comprender y analizar los requisitos del sistema. Identificar y proponer soluciones t\u00e9cnicas eficientes que satisfagan las necesidades del cliente.Escribir c\u00f3digo limpio y de alta calidad, utilizando las mejores pr\u00e1cticas de desarrollo. Depurar y solucionar problemas t\u00e9cnicos para garantizar el rendimiento y la eficiencia de las aplicaciones. Realizar pruebas unitarias y de integraci\u00f3n para verificar la funcionalidad y calidad del software desarrollado. Identificar y corregir errores o fallas, asegurando que las aplicaciones cumplan con los est\u00e1ndares de calidad establecidos.Realizar tareas de mantenimiento continuo y mejoras en las aplicaciones existentes, identificando y solucionando problemas que surjan con la aplicaci\u00f3n actual.Crear y mantener documentaci\u00f3n t\u00e9cnica precisa y actualizada, incluyendo manuales de usuario, especificaciones t\u00e9cnicas y diagramas de flujo, cuando as\u00ed se requiera.Trabajar\u00eda con nuestro equipo, bajo la supervisi\u00f3n de uno de nuestros referentes (dailies y reporting); pero su backlog lo puede sacar en el horario que quiera (e incluso es preferible que sea por la tarde ya que si le surgen dudas podr\u00e1 resolverlas con el cliente por la tarde que est\u00e1 en EEUU).\n\u00bfCu\u00e1les son los requisitos? Java 8Struts 2\n\u00bfQu\u00e9 ofrecemos?  Proyecto de 3 meses.Incorporaci\u00f3n: 14 de diciembreModalidad de trabajo: 100% remotoJornada parcial compatible con la continuidad de otros proyectos por parte del freelance.Tarifa de 25\u20ac\/h a 30\u20ac\/hContrataci\u00f3n a trav\u00e9s de Hays (Freelance).\nEstamos esperando perfiles como el tuyo, apasionados con la tecnolog\u00eda y que quiera enfrentarse a un nuevo reto. Si es tu caso, inscr\u00edbete en la oferta para que podamos contarte m\u00e1s!"}
{"job_title":"Big Data Engineer","company_name":"Plain Concepts","location":"Spain (Remote)","job_link":"\/jobs\/view\/3739541320\/?eBP=JOB_SEARCH_ORGANIC&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=BGFUwalTYd9BSL%2FJL1qjOQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3739541320","job_description":"About the job\n            \n \nEstamos ampliando nuestros equipos de Data & Analytics, no nos importa mucho el t\u00edtulo, pero a este rol lo llamamos Big Data Engineer, y la clave es la experiencia en Cloud y constantes ganas de seguir aprendiendo.Nuestra visi\u00f3n es construir equipos multidisciplinares, los cuales autogestionan directamente de forma AGILE los proyectos, para encontrar y realizar las mejores soluciones\ud83d\ude0a\u00bfQu\u00e9 har\u00e1s? Desarrollar\u00e1s proyectos desde cero bajo supervisi\u00f3n m\u00ednima y con la colaboraci\u00f3n del equipoParticipar\u00e1s en el dise\u00f1o de arquitecturas y toma de decisiones en un entorno constructivo y con din\u00e1mica de cocreaci\u00f3nSer\u00e1s pieza clave en el desarrollo de buenas pr\u00e1cticas, c\u00f3digo limpio y reusableDesarrollar\u00e1s ETLs con Spark (Python \/ Scala)Desarrollar\u00e1s proyectos en cloud (Azure \/ AWS)Construir\u00e1s pipelines escalables con diferentes tecnolog\u00edas: airflow, data factory,..\nRequirements\u00bfQu\u00e9 buscamos? Al menos 3 a\u00f1os de experiencia en ingenier\u00eda de software \/ datosS\u00f3lida experiencia en Python o Scala y Spark procesando grandes vol\u00famenes de datosS\u00f3lida experiencia en Cloud (Azure o AWS)Experiencia en la creaci\u00f3n de data pipelines (CI\/CD)Conocimiento en bases de datos SQL y NoSQLExperiencia con Databricks, Data Factory, Synapse, Apache Airflow, etcExperiencia o conocimiento en Power BIEnglish it\u00b4s a mustTeam player\nBenefits\u00bfQu\u00e9 ofrecemos? Salario acorde al mercado y tu experiencia \ud83e\udd11 Horario flexible 35 horas \/ semana (sin reducci\u00f3n de salario) \ud83d\ude0e Trabajo remoto 100% (opcional) \ud83c\udf0dRetribuci\u00f3n flexible (restaurante, transporte y guarder\u00eda) \u270c Seguro m\u00e9dico y dental (totalmente gratuito para el empleado) \ud83d\ude91 Presupuesto individual para formaci\u00f3n y certificaciones de Microsoft gratuitas \ud83d\udcda Clases de ingl\u00e9s (1 hora a la semana) \ud83d\uddfd D\u00eda libre por tu cumplea\u00f1os \ud83c\udf34\ud83e\udd73 Bonus mensual en concepto de electricidad e internet en casa \ud83d\udcbb Descuento en plan de gimnasio y actividades deportivas \ud83d\udd1d Plain Camp (evento anual de team building) \ud83c\udfaa \n\u2795 El gusto de trabajar siempre con las \u00faltimas herramientas tecnol\u00f3gicas.Con toda esta info ya conoces mucho de nosotros, \u00bfnos dejas que conozcamos m\u00e1s de ti?\u00bfEl proceso de selecci\u00f3n? \u2013 Sencillo, 3 pasos: una llamada y 2 entrevistas con el equipo \ud83e\udd18Y te preguntar\u00e1s\u2026 \u00bfQui\u00e9n es Plain Concepts? Plain Concepts somos m\u00e1s de 400 personas apasionadas por la tecnolog\u00eda, movidas por el cambio hacia la b\u00fasqueda de las mejores soluciones para nuestros clientes y proyectos.A lo largo de estos a\u00f1os, la empresa ha crecido gracias al gran potencial t\u00e9cnico que tenemos dentro y apoy\u00e1ndonos siempre en nuestras ideas m\u00e1s locas e innovadoras. Contamos con m\u00e1s de 14 oficinas en 6 pa\u00edses diferentes. Nuestro objetivo principal es seguir creciendo como equipo, realizando los mejores y m\u00e1s avanzados proyectos en el mercado.Realmente creemos en la importancia de reunir personas de diferentes \u00e1mbitos y pa\u00edses para formar el mejor equipo, con una cultura plural e inclusiva.\u00bfQu\u00e9 hacemos en Plain?Nos caracterizamos por tener un ADN 100% t\u00e9cnico. Desarrollamos proyectos a medida desde 0, consultor\u00edas t\u00e9cnicas y formaciones. No hacemos bodyshopping ni outsorcing Nuestros equipos son multidisciplinares y la estructura de organizaci\u00f3n es plana y horizontal Muy comprometidos con los valores AGILE Vivir es compartir, nos ayudamos, apoyamos y animamos mutuamente para ampliar nuestros conocimientos internamente y tambi\u00e9n de cara a la comunidad (con conferencias, eventos, charlas..) Siempre buscamos la creatividad e innovaci\u00f3n, incluso cuando la idea es una locura para otros La transparencia, clave para cualquier relaci\u00f3n. \nHacemos realidad las ideas y soluciones de nuestros clientes con un alto grado de excelencia t\u00e9cnica, para m\u00e1s informaci\u00f3n visita nuestra web:\u27a1 https:\/\/www.plainconcepts.com\/es\/casos-estudio\/En Plain Concepts, sin duda, buscamos ofrecer igualdad de oportunidades. Queremos solicitantes con diversidad sin importar la raza, color, g\u00e9nero, religi\u00f3n, nacionalidad, ciudadan\u00eda, discapacidad, edad, orientaci\u00f3n sexual o cualquier otra caracter\u00edstica protegida por la ley."}
{"job_title":"Java Developer","company_name":"Explore Group Europe","location":"European Union (Remote)","job_link":"\/jobs\/view\/3766614254\/?eBP=CwEAAAGMPHlytd5Gh9Art2vv5oWY4zejcioRHSQCoDfuZom86RWB1o-0e4JmZ_FoSKrIzlYlbzNUo4crc1Bmmbj-jDgtJFkdgC9M7COcqfww5at7jl5scfQM-UwrR773Uf9TFVGwxeqnnqqbhu1d_2yqI9R7a98t2AoHSepqL_tGLtSNJub6PCeT_548XQz8IaUpmiAy_blIkm55NYO4QsWfS_6kg6ELYZm8mK7Kz0SRmwHWivxSxmudzzQQs6VK1AcJt0oz1Ws8S3_LXZCDJojlXf6BidiCETZfybhIDq6iLuDTigu8E-_5JWl8bax2-2P50GyVVlFcDvPWQAlu0bQquu_HQOYvvPR0QJRzWqP1X9VrpbYehQm5t0P1ZfFm4g&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=ymyZjrDKkSp%2B6qnMKzbOhQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3766614254","job_description":"About the job\n            \n \nJava Developer - Fully Remote - Poznan\/Szczecin - Permanent I am actively looking for a Java Developer for a new and exciting project with a Leading Software Development client based in Poland. They are searching for an experienced Java Developer who is actively searching for a new and exciting position.Candidates must be based in Poland Responsibilities:  Build and manage corporate Java applications and based on Spring Boot frameworks.Work together with the development team to define and put technical fixes into place.Uphold code quality, and guarantee the scalability of the programme.\nQualifications:  Minimum of 4+ years of experience using JavaExperience on using Angular 9Good experience using Spring, Hibernate and REST API's\nOf interest please reach out to me directly via emailGeorge.white@exploreltd.com"}
{"job_title":"Lead Frontend Engineer","company_name":"Albert Bow","location":"Spain (Remote)","job_link":"\/jobs\/view\/3778501768\/?eBP=CwEAAAGMPHlytXiulrjWUY2gtd83WXq_nHkIQWsa0x7z16iuvbGv_vlSdhll3HRxcjQoiCaat0p_uHDx7KOu4M0RR8aCpj6oNKpmCKIVIVxjHd86_h9W66HcESUTICHUPCSBMrnksTv30vRlGWIl_DGFesxLVbC9NjDVViQdBBtT7QYClKfEJ45VeOFCxQ1HEeG0CtTh74DfYL6o7OpPoWxVUResm7Q7Onc3yYEMF7kFEazf1ECIBcvkzcSbrFtp2FJxlMF0FmsrFEFinKPReerRX53FoC9B7s9lSjFBwnX7c35IL5DveYYZ7BfFQ_37HCDqyLAlVoO-M1JiVQvNy17f2gj-D4QO07v509l-zdfBrQHOoLCFzy8uOWOSfXz3VCKi&refId=1na6iZvk6bkavLMmFLz%2BJA%3D%3D&trackingId=rCOmG%2BlqwjxwkXzblVE7dQ%3D%3D&trk=flagship3_search_srp_jobs","job_id":"3778501768","job_description":"About the job\n            \n \nLead Frontend Engineer | Blockchain\/Web.3 | Remote Spain | \u20ac100,000 to \u20ac120,000Albert Bow has just partnered with an extremely exciting and very well-funded Blockchain\/DeFi company. They are bridging the gap between traditional finance and crypto.They allow people to securely borrow and lend both fiat and crypto without an tax implications whilst also earning APY.Responsibilities:  Lead all aspect of frontend engineering from a technical perspective Mentor and line manage the frontend team Work closely with designers and be able to give input Be able to communicate technical aspects of the product to non-technical members of staff \nRequirements: Proven experience working with React\/TypescriptExperience in a leadership roleExperience working with different protocols and have a deep understanding of DeFi Very strong communication skills (English)Experience working in a fasted-paced environment\nIf this sounds like something you would be interested in apply with an up-to-date CV. Thanks,Chloe"}
